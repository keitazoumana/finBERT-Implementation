{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "checked-wellington",
   "metadata": {},
   "source": [
    "# Financial Text Classification Using FinBERT With Pytorch\n",
    "@Author: Zoumana Keita  \n",
    "The code of this notebook is highly inspired of this course on coursera:   \n",
    "https://www.coursera.org/projects/sentiment-analysis-bert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-utilization",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "selective-magnet",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To install a library, run the following command: \n",
    "!pip install library_name\n",
    "\"\"\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # to avoid warnings\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"\n",
    "Sklearn Libraries\n",
    "\"\"\"\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\"\"\"\n",
    "Transformer Libraries\n",
    "\"\"\"\n",
    "from transformers import BertTokenizer,  AutoModelForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "\"\"\"\n",
    "Pytorch Libraries\n",
    "\"\"\"\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "expired-potential",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_headline_distribution(sequence_lengths, figsize = (15,8)):\n",
    "    \n",
    "    # Get the percentage of reviews with length > 512\n",
    "    len_512_plus = [rev_len for rev_len in sequence_lengths if rev_len > 512]\n",
    "    percent = (len(len_512_plus)/len(sequence_lengths))*100\n",
    "    \n",
    "    print(\"Maximum Sequence Length is {}\".format(max(sequence_lengths)))\n",
    "    \n",
    "    # Configure the plot size\n",
    "    plt.figure(figsize = figsize)\n",
    "\n",
    "    sns.set(style='darkgrid')\n",
    "    \n",
    "    # Increase information on the figure\n",
    "    sns.set(font_scale=1.3)\n",
    "    \n",
    "    # Plot the result\n",
    "    sns.distplot(sequence_lengths, kde = False, rug = False)\n",
    "    plt.title('Headlines Lengths Distribution')\n",
    "    plt.xlabel('Headlines Length')\n",
    "    plt.ylabel('Number of Headlines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-classic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fossil-monthly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\"\"\"\n",
    "Link to dataset\n",
    "https://www.kaggle.com/shivamburnwal/text-classification-financial-news/data\n",
    "Download it and rename it FinancialNewsHeadline.csv\n",
    "\"\"\"\n",
    "financial_data = pd.read_csv(\"./data/FinancialNewsHeadline.csv\", \n",
    "                             encoding='latin-1', \n",
    "                             names=['sentiment', 'NewsHeadline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sized-homework",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>NewsHeadline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                       NewsHeadline\n",
       "0   neutral  According to Gran , the company has no plans t...\n",
       "1   neutral  Technopolis plans to develop in stages an area...\n",
       "2  negative  The international electronic industry company ...\n",
       "3  positive  With the new production plant the company woul...\n",
       "4  positive  According to the company 's updated strategy f..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "based-anime",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4846, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "wrong-assembly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     2879\n",
       "positive    1363\n",
       "negative     604\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_data.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "introductory-polish",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_headlines(total_number, df):\n",
    "    \n",
    "    # Get the random number of reviews\n",
    "    n_reviews = df.sample(total_number)\n",
    "    \n",
    "    # Print each one of the reviews\n",
    "    for val in list(n_reviews.index):\n",
    "        print(\"Reviews #°{}\".format(val))\n",
    "        print(\" - Sentiment: {}\".format(df.iloc[val][\"sentiment\"]))\n",
    "        print(\" - News Headline: {}\".format(df.iloc[val][\"NewsHeadline\"]))\n",
    "        print(\"\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "saved-chocolate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews #°3902\n",
      " - Sentiment: neutral\n",
      " - News Headline: The segments through which the company operates are Frozen Food business , Seafoods , Vegetable Oil business , Grain Trading and Other business operations .\n",
      "\n",
      "Reviews #°821\n",
      " - Sentiment: positive\n",
      " - News Headline: All of Raisio 's divisions recorded an operating profit .\n",
      "\n",
      "Reviews #°4337\n",
      " - Sentiment: neutral\n",
      " - News Headline: The company operates a U.S. division in Lisle , Ill. .\n",
      "\n",
      "Reviews #°1944\n",
      " - Sentiment: positive\n",
      " - News Headline: Finnish OKO bank has signed a cooperation agreement with Raiffeisen concerning Finnish companies ' investments in Russia .\n",
      "\n",
      "Reviews #°4785\n",
      " - Sentiment: negative\n",
      " - News Headline: The announcement pushed Freenet shares down 6.3 % , or EUR0 .71 , in Frankfurt trade to EUR10 .65 as investors gave up hope United Internet AG and Drillisch would pursue their own takeover and breakup of Freenet .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show 3 random headlines\n",
    "show_random_headlines(5, financial_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "social-sharp",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Number of News')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Configure the plot size\n",
    "plt.figure(figsize = (15,8))\n",
    "\n",
    "sns.set(style='darkgrid')\n",
    "    \n",
    "# Increase information on the figure\n",
    "sns.set(font_scale=1.3)\n",
    "sns.countplot(x='sentiment', data = financial_data)\n",
    "plt.title('News Sentiment Distribution')\n",
    "plt.xlabel('News Polarity')\n",
    "plt.ylabel('Number of News')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-disposition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fancy-enclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_headlines_len(df):\n",
    "    \n",
    "    headlines_sequence_lengths = []\n",
    "    \n",
    "    print(\"Encoding in progress...\")\n",
    "    for headline in tqdm(df.NewsHeadline):\n",
    "        encoded_headline = finbert_tokenizer.encode(headline, \n",
    "                                         add_special_tokens = True)\n",
    "        \n",
    "        # record the length of the encoded review\n",
    "        headlines_sequence_lengths.append(len(encoded_headline))\n",
    "    print(\"End of Task.\")\n",
    "    \n",
    "    return headlines_sequence_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-anthropology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "positive-butler",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "turkish-plaza",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentiments_values(df):\n",
    "    \n",
    "    possible_sentiments = df.sentiment.unique()\n",
    "    sentiment_dict = {}\n",
    "    \n",
    "    for index, possible_sentiment in enumerate(possible_sentiments):\n",
    "        sentiment_dict[possible_sentiment] = index\n",
    "    \n",
    "    # Encode all the sentiment values\n",
    "    df['label'] = df.sentiment.replace(sentiment_dict)\n",
    "    \n",
    "    return df, sentiment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "entitled-smith",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>NewsHeadline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                       NewsHeadline\n",
       "0   neutral  According to Gran , the company has no plans t...\n",
       "1   neutral  Technopolis plans to develop in stages an area...\n",
       "2  negative  The international electronic industry company ...\n",
       "3  positive  With the new production plant the company woul...\n",
       "4  positive  According to the company 's updated strategy f..."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "olympic-maria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>NewsHeadline</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                       NewsHeadline  label  \\\n",
       "0   neutral  According to Gran , the company has no plans t...      0   \n",
       "1   neutral  Technopolis plans to develop in stages an area...      0   \n",
       "2  negative  The international electronic industry company ...      1   \n",
       "3  positive  With the new production plant the company woul...      2   \n",
       "4  positive  According to the company 's updated strategy f...      2   \n",
       "\n",
       "  data_type  \n",
       "0     train  \n",
       "1     train  \n",
       "2     train  \n",
       "3     train  \n",
       "4     train  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode the sentiment column\n",
    "financial_data, sentiment_dict = encode_sentiments_values(financial_data)\n",
    "\n",
    "financial_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "unlimited-population",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(financial_data.index.values, \n",
    "                                                  financial_data.label.values, \n",
    "                                                  test_size = 0.15, \n",
    "                                                  random_state = 2022, \n",
    "                                                  stratify = financial_data.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "optical-senegal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>NewsHeadline</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">negative</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">neutral</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>2447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">positive</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>1159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           NewsHeadline\n",
       "sentiment label data_type              \n",
       "negative  1     train               513\n",
       "                val                  91\n",
       "neutral   0     train              2447\n",
       "                val                 432\n",
       "positive  2     train              1159\n",
       "                val                 204"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the data type columns\n",
    "financial_data.loc[X_train, 'data_type'] = 'train'\n",
    "financial_data.loc[X_val, 'data_type'] = 'val'\n",
    "\n",
    "# Vizualiez the number of sentiment occurence on each type of data\n",
    "financial_data.groupby(['sentiment', 'label', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fatal-knitting",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "# Get the FinBERT Tokenizer\n",
    "finbert_tokenizer = BertTokenizer.from_pretrained(\"ProsusAI/finbert\", \n",
    "                                          do_lower_case=True)\n",
    "\n",
    "# Encode the Training and Validation Data\n",
    "encoded_data_train = finbert_tokenizer.batch_encode_plus(\n",
    "    financial_data[financial_data.data_type=='train'].NewsHeadline.values, \n",
    "    return_tensors='pt',\n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=150 # the maximum lenght observed in the headlines\n",
    ")\n",
    "\n",
    "encoded_data_val = finbert_tokenizer.batch_encode_plus(\n",
    "    financial_data[financial_data.data_type=='val'].NewsHeadline.values, \n",
    "    return_tensors='pt',\n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=150 # the maximum lenght observed in the headlines\n",
    ")\n",
    "\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(financial_data[financial_data.data_type=='train'].label.values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "sentiments_val = torch.tensor(financial_data[financial_data.data_type=='val'].label.values)\n",
    "\n",
    "\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, sentiments_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "applied-grounds",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentiment_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "irish-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\",\n",
    "                                                          num_labels=len(sentiment_dict),\n",
    "                                                          output_attentions=False,\n",
    "                                                          output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-family",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "closing-production",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding in progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4846/4846 [00:02<00:00, 1638.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of Task.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "headlines_sequence_lengths = get_headlines_len(financial_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "extraordinary-browse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Sequence Length is 150\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "# Show the reviews distribution \n",
    "The overall implementation of this function is in my notebook at end of the article\n",
    "'''\n",
    "show_headline_distribution(headlines_sequence_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "british-inspection",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              sampler=RandomSampler(dataset_train), \n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                                   sampler=SequentialSampler(dataset_val), \n",
    "                                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "hazardous-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5, \n",
    "                  eps=1e-8)\n",
    "\n",
    "epochs = 3\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "opponent-exclusive",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')\n",
    "\n",
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in sentiment_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "premier-costa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Epoch 1:   0%|          | 0/824 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:   0%|          | 0/824 [00:06<?, ?it/s, training_loss=1.019]\u001b[A\n",
      "Epoch 1:   0%|          | 1/824 [00:06<1:25:57,  6.27s/it, training_loss=1.019]\u001b[A\n",
      "Epoch 1:   0%|          | 1/824 [00:11<1:25:57,  6.27s/it, training_loss=0.803]\u001b[A\n",
      "Epoch 1:   0%|          | 2/824 [00:11<1:20:44,  5.89s/it, training_loss=0.803]\u001b[A\n",
      "Epoch 1:   0%|          | 2/824 [00:17<1:20:44,  5.89s/it, training_loss=0.530]\u001b[A\n",
      "Epoch 1:   0%|          | 3/824 [00:17<1:18:11,  5.71s/it, training_loss=0.530]\u001b[A\n",
      "Epoch 1:   0%|          | 3/824 [00:30<1:18:11,  5.71s/it, training_loss=0.441]\u001b[A\n",
      "Epoch 1:   0%|          | 4/824 [00:30<1:55:23,  8.44s/it, training_loss=0.441]\u001b[A\n",
      "Epoch 1:   0%|          | 4/824 [00:57<1:55:23,  8.44s/it, training_loss=0.391]\u001b[A\n",
      "Epoch 1:   1%|          | 5/824 [00:57<3:30:14, 15.40s/it, training_loss=0.391]\u001b[A\n",
      "Epoch 1:   1%|          | 5/824 [01:21<3:30:14, 15.40s/it, training_loss=0.836]\u001b[A\n",
      "Epoch 1:   1%|          | 6/824 [01:21<4:09:56, 18.33s/it, training_loss=0.836]\u001b[A\n",
      "Epoch 1:   1%|          | 6/824 [01:27<4:09:56, 18.33s/it, training_loss=0.435]\u001b[A\n",
      "Epoch 1:   1%|          | 7/824 [01:27<3:11:28, 14.06s/it, training_loss=0.435]\u001b[A\n",
      "Epoch 1:   1%|          | 7/824 [01:32<3:11:28, 14.06s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:   1%|          | 8/824 [01:32<2:32:55, 11.24s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:   1%|          | 8/824 [01:37<2:32:55, 11.24s/it, training_loss=0.403]\u001b[A\n",
      "Epoch 1:   1%|          | 9/824 [01:37<2:07:06,  9.36s/it, training_loss=0.403]\u001b[A\n",
      "Epoch 1:   1%|          | 9/824 [01:42<2:07:06,  9.36s/it, training_loss=0.367]\u001b[A\n",
      "Epoch 1:   1%|          | 10/824 [01:42<1:49:36,  8.08s/it, training_loss=0.367]\u001b[A\n",
      "Epoch 1:   1%|          | 10/824 [01:47<1:49:36,  8.08s/it, training_loss=0.332]\u001b[A\n",
      "Epoch 1:   1%|▏         | 11/824 [01:47<1:37:27,  7.19s/it, training_loss=0.332]\u001b[A\n",
      "Epoch 1:   1%|▏         | 11/824 [01:53<1:37:27,  7.19s/it, training_loss=0.232]\u001b[A\n",
      "Epoch 1:   1%|▏         | 12/824 [01:53<1:29:02,  6.58s/it, training_loss=0.232]\u001b[A\n",
      "Epoch 1:   1%|▏         | 12/824 [01:58<1:29:02,  6.58s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 1:   2%|▏         | 13/824 [01:58<1:23:04,  6.15s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 1:   2%|▏         | 13/824 [02:03<1:23:04,  6.15s/it, training_loss=0.146]\u001b[A\n",
      "Epoch 1:   2%|▏         | 14/824 [02:03<1:18:53,  5.84s/it, training_loss=0.146]\u001b[A\n",
      "Epoch 1:   2%|▏         | 14/824 [02:08<1:18:53,  5.84s/it, training_loss=0.554]\u001b[A\n",
      "Epoch 1:   2%|▏         | 15/824 [02:08<1:15:53,  5.63s/it, training_loss=0.554]\u001b[A\n",
      "Epoch 1:   2%|▏         | 15/824 [02:13<1:15:53,  5.63s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:   2%|▏         | 16/824 [02:13<1:13:54,  5.49s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:   2%|▏         | 16/824 [02:18<1:13:54,  5.49s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:   2%|▏         | 17/824 [02:18<1:12:37,  5.40s/it, training_loss=0.259]\u001b[A\n",
      "Epoch 1:   2%|▏         | 17/824 [02:23<1:12:37,  5.40s/it, training_loss=0.514]\u001b[A\n",
      "Epoch 1:   2%|▏         | 18/824 [02:23<1:11:32,  5.33s/it, training_loss=0.514]\u001b[A\n",
      "Epoch 1:   2%|▏         | 18/824 [02:29<1:11:32,  5.33s/it, training_loss=0.599]\u001b[A\n",
      "Epoch 1:   2%|▏         | 19/824 [02:29<1:10:40,  5.27s/it, training_loss=0.599]\u001b[A\n",
      "Epoch 1:   2%|▏         | 19/824 [02:34<1:10:40,  5.27s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:   2%|▏         | 20/824 [02:34<1:10:45,  5.28s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:   2%|▏         | 20/824 [02:39<1:10:45,  5.28s/it, training_loss=0.343]\u001b[A\n",
      "Epoch 1:   3%|▎         | 21/824 [02:39<1:10:11,  5.24s/it, training_loss=0.343]\u001b[A\n",
      "Epoch 1:   3%|▎         | 21/824 [02:44<1:10:11,  5.24s/it, training_loss=0.585]\u001b[A\n",
      "Epoch 1:   3%|▎         | 22/824 [02:44<1:09:50,  5.22s/it, training_loss=0.585]\u001b[A\n",
      "Epoch 1:   3%|▎         | 22/824 [02:50<1:09:50,  5.22s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:   3%|▎         | 23/824 [02:50<1:10:18,  5.27s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 1:   3%|▎         | 23/824 [02:55<1:10:18,  5.27s/it, training_loss=0.036]\u001b[A\n",
      "Epoch 1:   3%|▎         | 24/824 [02:55<1:10:13,  5.27s/it, training_loss=0.036]\u001b[A\n",
      "Epoch 1:   3%|▎         | 24/824 [03:00<1:10:13,  5.27s/it, training_loss=0.219]\u001b[A\n",
      "Epoch 1:   3%|▎         | 25/824 [03:00<1:09:53,  5.25s/it, training_loss=0.219]\u001b[A\n",
      "Epoch 1:   3%|▎         | 25/824 [03:05<1:09:53,  5.25s/it, training_loss=0.640]\u001b[A\n",
      "Epoch 1:   3%|▎         | 26/824 [03:05<1:10:10,  5.28s/it, training_loss=0.640]\u001b[A\n",
      "Epoch 1:   3%|▎         | 26/824 [03:11<1:10:10,  5.28s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 1:   3%|▎         | 27/824 [03:11<1:10:55,  5.34s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 1:   3%|▎         | 27/824 [03:17<1:10:55,  5.34s/it, training_loss=0.060]\u001b[A\n",
      "Epoch 1:   3%|▎         | 28/824 [03:17<1:14:17,  5.60s/it, training_loss=0.060]\u001b[A\n",
      "Epoch 1:   3%|▎         | 28/824 [03:23<1:14:17,  5.60s/it, training_loss=0.625]\u001b[A\n",
      "Epoch 1:   4%|▎         | 29/824 [03:23<1:17:06,  5.82s/it, training_loss=0.625]\u001b[A\n",
      "Epoch 1:   4%|▎         | 29/824 [03:29<1:17:06,  5.82s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 1:   4%|▎         | 30/824 [03:29<1:16:34,  5.79s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 1:   4%|▎         | 30/824 [03:35<1:16:34,  5.79s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 1:   4%|▍         | 31/824 [03:35<1:15:02,  5.68s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 1:   4%|▍         | 31/824 [03:40<1:15:02,  5.68s/it, training_loss=0.212]\u001b[A\n",
      "Epoch 1:   4%|▍         | 32/824 [03:40<1:13:40,  5.58s/it, training_loss=0.212]\u001b[A\n",
      "Epoch 1:   4%|▍         | 32/824 [03:46<1:13:40,  5.58s/it, training_loss=0.200]\u001b[A\n",
      "Epoch 1:   4%|▍         | 33/824 [03:46<1:14:41,  5.67s/it, training_loss=0.200]\u001b[A\n",
      "Epoch 1:   4%|▍         | 33/824 [03:52<1:14:41,  5.67s/it, training_loss=0.180]\u001b[A\n",
      "Epoch 1:   4%|▍         | 34/824 [03:52<1:15:38,  5.75s/it, training_loss=0.180]\u001b[A\n",
      "Epoch 1:   4%|▍         | 34/824 [03:57<1:15:38,  5.75s/it, training_loss=0.523]\u001b[A\n",
      "Epoch 1:   4%|▍         | 35/824 [03:57<1:15:06,  5.71s/it, training_loss=0.523]\u001b[A\n",
      "Epoch 1:   4%|▍         | 35/824 [04:03<1:15:06,  5.71s/it, training_loss=0.212]\u001b[A\n",
      "Epoch 1:   4%|▍         | 36/824 [04:03<1:13:59,  5.63s/it, training_loss=0.212]\u001b[A\n",
      "Epoch 1:   4%|▍         | 36/824 [04:08<1:13:59,  5.63s/it, training_loss=0.063]\u001b[A\n",
      "Epoch 1:   4%|▍         | 37/824 [04:08<1:13:46,  5.62s/it, training_loss=0.063]\u001b[A\n",
      "Epoch 1:   4%|▍         | 37/824 [04:14<1:13:46,  5.62s/it, training_loss=0.381]\u001b[A\n",
      "Epoch 1:   5%|▍         | 38/824 [04:14<1:13:17,  5.60s/it, training_loss=0.381]\u001b[A\n",
      "Epoch 1:   5%|▍         | 38/824 [04:19<1:13:17,  5.60s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 1:   5%|▍         | 39/824 [04:19<1:12:21,  5.53s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 1:   5%|▍         | 39/824 [04:25<1:12:21,  5.53s/it, training_loss=0.495]\u001b[A\n",
      "Epoch 1:   5%|▍         | 40/824 [04:25<1:13:33,  5.63s/it, training_loss=0.495]\u001b[A\n",
      "Epoch 1:   5%|▍         | 40/824 [04:31<1:13:33,  5.63s/it, training_loss=0.549]\u001b[A\n",
      "Epoch 1:   5%|▍         | 41/824 [04:31<1:12:29,  5.55s/it, training_loss=0.549]\u001b[A\n",
      "Epoch 1:   5%|▍         | 41/824 [04:36<1:12:29,  5.55s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:   5%|▌         | 42/824 [04:36<1:11:25,  5.48s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 1:   5%|▌         | 42/824 [04:42<1:11:25,  5.48s/it, training_loss=0.506]\u001b[A\n",
      "Epoch 1:   5%|▌         | 43/824 [04:42<1:13:33,  5.65s/it, training_loss=0.506]\u001b[A\n",
      "Epoch 1:   5%|▌         | 43/824 [04:48<1:13:33,  5.65s/it, training_loss=0.050]\u001b[A\n",
      "Epoch 1:   5%|▌         | 44/824 [04:48<1:14:49,  5.76s/it, training_loss=0.050]\u001b[A\n",
      "Epoch 1:   5%|▌         | 44/824 [04:54<1:14:49,  5.76s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:   5%|▌         | 45/824 [04:54<1:14:19,  5.72s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 1:   5%|▌         | 45/824 [05:00<1:14:19,  5.72s/it, training_loss=0.184]\u001b[A\n",
      "Epoch 1:   6%|▌         | 46/824 [05:00<1:16:04,  5.87s/it, training_loss=0.184]\u001b[A\n",
      "Epoch 1:   6%|▌         | 46/824 [05:07<1:16:04,  5.87s/it, training_loss=0.074]\u001b[A\n",
      "Epoch 1:   6%|▌         | 47/824 [05:07<1:20:49,  6.24s/it, training_loss=0.074]\u001b[A\n",
      "Epoch 1:   6%|▌         | 47/824 [05:14<1:20:49,  6.24s/it, training_loss=0.210]\u001b[A\n",
      "Epoch 1:   6%|▌         | 48/824 [05:14<1:24:36,  6.54s/it, training_loss=0.210]\u001b[A\n",
      "Epoch 1:   6%|▌         | 48/824 [05:24<1:24:36,  6.54s/it, training_loss=0.432]\u001b[A\n",
      "Epoch 1:   6%|▌         | 49/824 [05:24<1:38:16,  7.61s/it, training_loss=0.432]\u001b[A\n",
      "Epoch 1:   6%|▌         | 49/824 [05:35<1:38:16,  7.61s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:   6%|▌         | 50/824 [05:35<1:51:19,  8.63s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:   6%|▌         | 50/824 [05:44<1:51:19,  8.63s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:   6%|▌         | 51/824 [05:44<1:53:24,  8.80s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 1:   6%|▌         | 51/824 [05:53<1:53:24,  8.80s/it, training_loss=0.199]\u001b[A\n",
      "Epoch 1:   6%|▋         | 52/824 [05:53<1:52:02,  8.71s/it, training_loss=0.199]\u001b[A\n",
      "Epoch 1:   6%|▋         | 52/824 [06:00<1:52:02,  8.71s/it, training_loss=0.119]\u001b[A\n",
      "Epoch 1:   6%|▋         | 53/824 [06:00<1:44:50,  8.16s/it, training_loss=0.119]\u001b[A\n",
      "Epoch 1:   6%|▋         | 53/824 [06:06<1:44:50,  8.16s/it, training_loss=0.084]\u001b[A\n",
      "Epoch 1:   7%|▋         | 54/824 [06:06<1:35:56,  7.48s/it, training_loss=0.084]\u001b[A\n",
      "Epoch 1:   7%|▋         | 54/824 [06:11<1:35:56,  7.48s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 1:   7%|▋         | 55/824 [06:11<1:27:59,  6.87s/it, training_loss=0.234]\u001b[A\n",
      "Epoch 1:   7%|▋         | 55/824 [06:16<1:27:59,  6.87s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:   7%|▋         | 56/824 [06:16<1:21:56,  6.40s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:   7%|▋         | 56/824 [06:22<1:21:56,  6.40s/it, training_loss=0.158]\u001b[A\n",
      "Epoch 1:   7%|▋         | 57/824 [06:22<1:17:32,  6.07s/it, training_loss=0.158]\u001b[A\n",
      "Epoch 1:   7%|▋         | 57/824 [06:27<1:17:32,  6.07s/it, training_loss=0.213]\u001b[A\n",
      "Epoch 1:   7%|▋         | 58/824 [06:27<1:16:07,  5.96s/it, training_loss=0.213]\u001b[A\n",
      "Epoch 1:   7%|▋         | 58/824 [06:33<1:16:07,  5.96s/it, training_loss=0.145]\u001b[A\n",
      "Epoch 1:   7%|▋         | 59/824 [06:33<1:14:20,  5.83s/it, training_loss=0.145]\u001b[A\n",
      "Epoch 1:   7%|▋         | 59/824 [06:38<1:14:20,  5.83s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:   7%|▋         | 60/824 [06:38<1:12:13,  5.67s/it, training_loss=0.269]\u001b[A\n",
      "Epoch 1:   7%|▋         | 60/824 [06:44<1:12:13,  5.67s/it, training_loss=0.158]\u001b[A\n",
      "Epoch 1:   7%|▋         | 61/824 [06:44<1:10:37,  5.55s/it, training_loss=0.158]\u001b[A\n",
      "Epoch 1:   7%|▋         | 61/824 [06:49<1:10:37,  5.55s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:   8%|▊         | 62/824 [06:49<1:09:23,  5.46s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:   8%|▊         | 62/824 [06:54<1:09:23,  5.46s/it, training_loss=0.203]\u001b[A\n",
      "Epoch 1:   8%|▊         | 63/824 [06:54<1:08:23,  5.39s/it, training_loss=0.203]\u001b[A\n",
      "Epoch 1:   8%|▊         | 63/824 [06:59<1:08:23,  5.39s/it, training_loss=0.118]\u001b[A\n",
      "Epoch 1:   8%|▊         | 64/824 [06:59<1:07:23,  5.32s/it, training_loss=0.118]\u001b[A\n",
      "Epoch 1:   8%|▊         | 64/824 [07:04<1:07:23,  5.32s/it, training_loss=0.400]\u001b[A\n",
      "Epoch 1:   8%|▊         | 65/824 [07:04<1:07:00,  5.30s/it, training_loss=0.400]\u001b[A\n",
      "Epoch 1:   8%|▊         | 65/824 [07:10<1:07:00,  5.30s/it, training_loss=0.154]\u001b[A\n",
      "Epoch 1:   8%|▊         | 66/824 [07:10<1:06:43,  5.28s/it, training_loss=0.154]\u001b[A\n",
      "Epoch 1:   8%|▊         | 66/824 [07:15<1:06:43,  5.28s/it, training_loss=0.235]\u001b[A\n",
      "Epoch 1:   8%|▊         | 67/824 [07:15<1:06:36,  5.28s/it, training_loss=0.235]\u001b[A\n",
      "Epoch 1:   8%|▊         | 67/824 [07:20<1:06:36,  5.28s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:   8%|▊         | 68/824 [07:20<1:06:19,  5.26s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:   8%|▊         | 68/824 [07:25<1:06:19,  5.26s/it, training_loss=0.098]\u001b[A\n",
      "Epoch 1:   8%|▊         | 69/824 [07:25<1:06:03,  5.25s/it, training_loss=0.098]\u001b[A\n",
      "Epoch 1:   8%|▊         | 69/824 [07:31<1:06:03,  5.25s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:   8%|▊         | 70/824 [07:31<1:05:53,  5.24s/it, training_loss=0.284]\u001b[A\n",
      "Epoch 1:   8%|▊         | 70/824 [07:36<1:05:53,  5.24s/it, training_loss=0.379]\u001b[A\n",
      "Epoch 1:   9%|▊         | 71/824 [07:36<1:05:45,  5.24s/it, training_loss=0.379]\u001b[A\n",
      "Epoch 1:   9%|▊         | 71/824 [07:41<1:05:45,  5.24s/it, training_loss=0.128]\u001b[A\n",
      "Epoch 1:   9%|▊         | 72/824 [07:41<1:05:44,  5.25s/it, training_loss=0.128]\u001b[A\n",
      "Epoch 1:   9%|▊         | 72/824 [07:46<1:05:44,  5.25s/it, training_loss=0.121]\u001b[A\n",
      "Epoch 1:   9%|▉         | 73/824 [07:46<1:05:44,  5.25s/it, training_loss=0.121]\u001b[A\n",
      "Epoch 1:   9%|▉         | 73/824 [07:52<1:05:44,  5.25s/it, training_loss=0.178]\u001b[A\n",
      "Epoch 1:   9%|▉         | 74/824 [07:52<1:05:41,  5.26s/it, training_loss=0.178]\u001b[A\n",
      "Epoch 1:   9%|▉         | 74/824 [07:57<1:05:41,  5.26s/it, training_loss=0.171]\u001b[A\n",
      "Epoch 1:   9%|▉         | 75/824 [07:57<1:05:27,  5.24s/it, training_loss=0.171]\u001b[A\n",
      "Epoch 1:   9%|▉         | 75/824 [08:02<1:05:27,  5.24s/it, training_loss=0.069]\u001b[A\n",
      "Epoch 1:   9%|▉         | 76/824 [08:02<1:05:18,  5.24s/it, training_loss=0.069]\u001b[A\n",
      "Epoch 1:   9%|▉         | 76/824 [08:07<1:05:18,  5.24s/it, training_loss=0.160]\u001b[A\n",
      "Epoch 1:   9%|▉         | 77/824 [08:07<1:05:11,  5.24s/it, training_loss=0.160]\u001b[A\n",
      "Epoch 1:   9%|▉         | 77/824 [08:13<1:05:11,  5.24s/it, training_loss=0.150]\u001b[A\n",
      "Epoch 1:   9%|▉         | 78/824 [08:13<1:05:07,  5.24s/it, training_loss=0.150]\u001b[A\n",
      "Epoch 1:   9%|▉         | 78/824 [08:18<1:05:07,  5.24s/it, training_loss=0.155]\u001b[A\n",
      "Epoch 1:  10%|▉         | 79/824 [08:18<1:05:32,  5.28s/it, training_loss=0.155]\u001b[A\n",
      "Epoch 1:  10%|▉         | 79/824 [08:24<1:05:32,  5.28s/it, training_loss=0.215]\u001b[A\n",
      "Epoch 1:  10%|▉         | 80/824 [08:24<1:07:05,  5.41s/it, training_loss=0.215]\u001b[A\n",
      "Epoch 1:  10%|▉         | 80/824 [08:29<1:07:05,  5.41s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  10%|▉         | 81/824 [08:29<1:06:50,  5.40s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  10%|▉         | 81/824 [08:35<1:06:50,  5.40s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  10%|▉         | 82/824 [08:35<1:08:33,  5.54s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  10%|▉         | 82/824 [08:41<1:08:33,  5.54s/it, training_loss=0.239]\u001b[A\n",
      "Epoch 1:  10%|█         | 83/824 [08:41<1:09:02,  5.59s/it, training_loss=0.239]\u001b[A\n",
      "Epoch 1:  10%|█         | 83/824 [08:46<1:09:02,  5.59s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  10%|█         | 84/824 [08:46<1:09:02,  5.60s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 1:  10%|█         | 84/824 [08:52<1:09:02,  5.60s/it, training_loss=0.481]\u001b[A\n",
      "Epoch 1:  10%|█         | 85/824 [08:52<1:08:55,  5.60s/it, training_loss=0.481]\u001b[A\n",
      "Epoch 1:  10%|█         | 85/824 [08:57<1:08:55,  5.60s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 1:  10%|█         | 86/824 [08:57<1:08:22,  5.56s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 1:  10%|█         | 86/824 [09:03<1:08:22,  5.56s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  11%|█         | 87/824 [09:03<1:08:52,  5.61s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  11%|█         | 87/824 [09:08<1:08:52,  5.61s/it, training_loss=0.342]\u001b[A\n",
      "Epoch 1:  11%|█         | 88/824 [09:08<1:07:44,  5.52s/it, training_loss=0.342]\u001b[A\n",
      "Epoch 1:  11%|█         | 88/824 [09:14<1:07:44,  5.52s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 1:  11%|█         | 89/824 [09:14<1:07:04,  5.48s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 1:  11%|█         | 89/824 [09:19<1:07:04,  5.48s/it, training_loss=0.159]\u001b[A\n",
      "Epoch 1:  11%|█         | 90/824 [09:19<1:06:46,  5.46s/it, training_loss=0.159]\u001b[A\n",
      "Epoch 1:  11%|█         | 90/824 [09:25<1:06:46,  5.46s/it, training_loss=0.114]\u001b[A\n",
      "Epoch 1:  11%|█         | 91/824 [09:25<1:06:38,  5.45s/it, training_loss=0.114]\u001b[A\n",
      "Epoch 1:  11%|█         | 91/824 [09:30<1:06:38,  5.45s/it, training_loss=0.124]\u001b[A\n",
      "Epoch 1:  11%|█         | 92/824 [09:30<1:06:51,  5.48s/it, training_loss=0.124]\u001b[A\n",
      "Epoch 1:  11%|█         | 92/824 [09:36<1:06:51,  5.48s/it, training_loss=0.086]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 93/824 [09:36<1:07:48,  5.57s/it, training_loss=0.086]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 93/824 [09:42<1:07:48,  5.57s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 94/824 [09:42<1:07:53,  5.58s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 94/824 [09:47<1:07:53,  5.58s/it, training_loss=0.149]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 95/824 [09:47<1:07:53,  5.59s/it, training_loss=0.149]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 95/824 [09:53<1:07:53,  5.59s/it, training_loss=0.184]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 96/824 [09:53<1:07:26,  5.56s/it, training_loss=0.184]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 96/824 [09:58<1:07:26,  5.56s/it, training_loss=0.124]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  12%|█▏        | 97/824 [09:58<1:07:46,  5.59s/it, training_loss=0.124]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 97/824 [10:04<1:07:46,  5.59s/it, training_loss=0.195]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 98/824 [10:04<1:07:16,  5.56s/it, training_loss=0.195]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 98/824 [10:09<1:07:16,  5.56s/it, training_loss=0.142]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 99/824 [10:09<1:06:59,  5.54s/it, training_loss=0.142]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 99/824 [10:15<1:06:59,  5.54s/it, training_loss=0.120]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 100/824 [10:15<1:07:12,  5.57s/it, training_loss=0.120]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 100/824 [10:21<1:07:12,  5.57s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 101/824 [10:21<1:08:25,  5.68s/it, training_loss=0.256]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 101/824 [10:26<1:08:25,  5.68s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 102/824 [10:26<1:07:53,  5.64s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 102/824 [10:32<1:07:53,  5.64s/it, training_loss=0.220]\u001b[A\n",
      "Epoch 1:  12%|█▎        | 103/824 [10:32<1:08:41,  5.72s/it, training_loss=0.220]\u001b[A\n",
      "Epoch 1:  12%|█▎        | 103/824 [10:38<1:08:41,  5.72s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 104/824 [10:38<1:09:59,  5.83s/it, training_loss=0.231]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 104/824 [10:44<1:09:59,  5.83s/it, training_loss=0.205]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 105/824 [10:44<1:09:27,  5.80s/it, training_loss=0.205]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 105/824 [10:50<1:09:27,  5.80s/it, training_loss=0.170]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 106/824 [10:50<1:09:13,  5.78s/it, training_loss=0.170]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 106/824 [10:56<1:09:13,  5.78s/it, training_loss=0.174]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 107/824 [10:56<1:08:44,  5.75s/it, training_loss=0.174]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 107/824 [11:01<1:08:44,  5.75s/it, training_loss=0.186]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 108/824 [11:01<1:09:08,  5.79s/it, training_loss=0.186]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 108/824 [11:08<1:09:08,  5.79s/it, training_loss=0.177]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 109/824 [11:08<1:10:24,  5.91s/it, training_loss=0.177]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 109/824 [11:13<1:10:24,  5.91s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 110/824 [11:13<1:10:11,  5.90s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 110/824 [11:19<1:10:11,  5.90s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 111/824 [11:19<1:09:31,  5.85s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 111/824 [11:25<1:09:31,  5.85s/it, training_loss=0.131]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 112/824 [11:25<1:09:13,  5.83s/it, training_loss=0.131]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 112/824 [11:31<1:09:13,  5.83s/it, training_loss=0.168]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 113/824 [11:31<1:09:15,  5.84s/it, training_loss=0.168]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 113/824 [11:37<1:09:15,  5.84s/it, training_loss=0.432]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 114/824 [11:37<1:08:53,  5.82s/it, training_loss=0.432]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 114/824 [11:42<1:08:53,  5.82s/it, training_loss=0.109]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 115/824 [11:42<1:08:07,  5.76s/it, training_loss=0.109]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 115/824 [11:48<1:08:07,  5.76s/it, training_loss=0.147]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 116/824 [11:48<1:07:33,  5.72s/it, training_loss=0.147]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 116/824 [11:53<1:07:33,  5.72s/it, training_loss=0.148]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 117/824 [11:53<1:06:45,  5.67s/it, training_loss=0.148]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 117/824 [11:59<1:06:45,  5.67s/it, training_loss=0.162]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 118/824 [11:59<1:05:53,  5.60s/it, training_loss=0.162]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 118/824 [12:04<1:05:53,  5.60s/it, training_loss=0.098]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 119/824 [12:04<1:05:12,  5.55s/it, training_loss=0.098]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 119/824 [12:10<1:05:12,  5.55s/it, training_loss=0.428]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 120/824 [12:10<1:04:35,  5.50s/it, training_loss=0.428]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 120/824 [12:15<1:04:35,  5.50s/it, training_loss=0.156]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 121/824 [12:15<1:04:14,  5.48s/it, training_loss=0.156]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 121/824 [12:21<1:04:14,  5.48s/it, training_loss=0.147]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 122/824 [12:21<1:04:10,  5.49s/it, training_loss=0.147]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 122/824 [12:26<1:04:10,  5.49s/it, training_loss=0.156]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 123/824 [12:26<1:04:09,  5.49s/it, training_loss=0.156]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 123/824 [12:32<1:04:09,  5.49s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 124/824 [12:32<1:03:45,  5.47s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 124/824 [12:37<1:03:45,  5.47s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 125/824 [12:37<1:03:28,  5.45s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 125/824 [12:42<1:03:28,  5.45s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 126/824 [12:42<1:03:25,  5.45s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 126/824 [12:48<1:03:25,  5.45s/it, training_loss=0.147]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 127/824 [12:48<1:03:12,  5.44s/it, training_loss=0.147]\u001b[A\n",
      "Epoch 1:  15%|█▌        | 127/824 [12:53<1:03:12,  5.44s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 128/824 [12:53<1:03:03,  5.44s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 128/824 [12:59<1:03:03,  5.44s/it, training_loss=0.171]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 129/824 [12:59<1:02:52,  5.43s/it, training_loss=0.171]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 129/824 [13:04<1:02:52,  5.43s/it, training_loss=0.054]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 130/824 [13:04<1:02:43,  5.42s/it, training_loss=0.054]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 130/824 [13:09<1:02:43,  5.42s/it, training_loss=0.383]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 131/824 [13:09<1:02:34,  5.42s/it, training_loss=0.383]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 131/824 [13:15<1:02:34,  5.42s/it, training_loss=0.113]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 132/824 [13:15<1:02:31,  5.42s/it, training_loss=0.113]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 132/824 [13:20<1:02:31,  5.42s/it, training_loss=0.143]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 133/824 [13:20<1:02:24,  5.42s/it, training_loss=0.143]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 133/824 [13:26<1:02:24,  5.42s/it, training_loss=0.335]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 134/824 [13:26<1:02:20,  5.42s/it, training_loss=0.335]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 134/824 [13:31<1:02:20,  5.42s/it, training_loss=0.211]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 135/824 [13:31<1:02:15,  5.42s/it, training_loss=0.211]\u001b[A\n",
      "Epoch 1:  16%|█▋        | 135/824 [13:37<1:02:15,  5.42s/it, training_loss=0.075]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 136/824 [13:37<1:02:40,  5.47s/it, training_loss=0.075]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 136/824 [13:42<1:02:40,  5.47s/it, training_loss=0.144]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 137/824 [13:42<1:02:33,  5.46s/it, training_loss=0.144]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 137/824 [13:48<1:02:33,  5.46s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 138/824 [13:48<1:02:20,  5.45s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 138/824 [13:53<1:02:20,  5.45s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 139/824 [13:53<1:01:50,  5.42s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 139/824 [13:59<1:01:50,  5.42s/it, training_loss=0.150]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 140/824 [13:59<1:02:16,  5.46s/it, training_loss=0.150]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 140/824 [14:04<1:02:16,  5.46s/it, training_loss=0.467]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 141/824 [14:04<1:02:31,  5.49s/it, training_loss=0.467]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 141/824 [14:10<1:02:31,  5.49s/it, training_loss=0.045]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 142/824 [14:10<1:02:57,  5.54s/it, training_loss=0.045]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 142/824 [14:15<1:02:57,  5.54s/it, training_loss=0.207]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 143/824 [14:15<1:03:17,  5.58s/it, training_loss=0.207]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 143/824 [14:21<1:03:17,  5.58s/it, training_loss=0.162]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 144/824 [14:21<1:02:05,  5.48s/it, training_loss=0.162]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 144/824 [14:26<1:02:05,  5.48s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 145/824 [14:26<1:02:45,  5.55s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 145/824 [14:31<1:02:45,  5.55s/it, training_loss=0.117]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 146/824 [14:32<1:01:17,  5.42s/it, training_loss=0.117]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 146/824 [14:37<1:01:17,  5.42s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 147/824 [14:37<1:01:07,  5.42s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 147/824 [14:42<1:01:07,  5.42s/it, training_loss=0.071]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 148/824 [14:42<1:01:12,  5.43s/it, training_loss=0.071]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 148/824 [14:48<1:01:12,  5.43s/it, training_loss=0.138]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 149/824 [14:48<1:00:44,  5.40s/it, training_loss=0.138]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 149/824 [14:53<1:00:44,  5.40s/it, training_loss=0.063]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 150/824 [14:53<59:50,  5.33s/it, training_loss=0.063]  \u001b[A\n",
      "Epoch 1:  18%|█▊        | 150/824 [14:58<59:50,  5.33s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 151/824 [14:58<1:00:00,  5.35s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 151/824 [15:04<1:00:00,  5.35s/it, training_loss=0.359]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 152/824 [15:04<59:47,  5.34s/it, training_loss=0.359]  \u001b[A\n",
      "Epoch 1:  18%|█▊        | 152/824 [15:09<59:47,  5.34s/it, training_loss=0.099]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 153/824 [15:09<1:00:25,  5.40s/it, training_loss=0.099]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 153/824 [15:15<1:00:25,  5.40s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 154/824 [15:15<1:00:23,  5.41s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 1:  19%|█▊        | 154/824 [15:20<1:00:23,  5.41s/it, training_loss=0.171]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 155/824 [15:20<1:00:24,  5.42s/it, training_loss=0.171]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 155/824 [15:25<1:00:24,  5.42s/it, training_loss=0.100]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 156/824 [15:25<1:00:25,  5.43s/it, training_loss=0.100]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 156/824 [15:31<1:00:25,  5.43s/it, training_loss=0.359]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 157/824 [15:31<1:00:12,  5.42s/it, training_loss=0.359]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 157/824 [15:36<1:00:12,  5.42s/it, training_loss=0.176]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 158/824 [15:36<59:24,  5.35s/it, training_loss=0.176]  \u001b[A\n",
      "Epoch 1:  19%|█▉        | 158/824 [15:41<59:24,  5.35s/it, training_loss=0.167]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 159/824 [15:41<58:54,  5.31s/it, training_loss=0.167]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 159/824 [15:47<58:54,  5.31s/it, training_loss=0.135]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 160/824 [15:47<59:09,  5.35s/it, training_loss=0.135]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 160/824 [15:52<59:09,  5.35s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 161/824 [15:52<59:43,  5.40s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 161/824 [15:57<59:43,  5.40s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 162/824 [15:57<59:05,  5.36s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 162/824 [16:03<59:05,  5.36s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 163/824 [16:03<59:22,  5.39s/it, training_loss=0.230]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 163/824 [16:08<59:22,  5.39s/it, training_loss=0.078]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 164/824 [16:08<58:36,  5.33s/it, training_loss=0.078]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 164/824 [16:13<58:36,  5.33s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 1:  20%|██        | 165/824 [16:13<57:59,  5.28s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 1:  20%|██        | 165/824 [16:19<57:59,  5.28s/it, training_loss=0.158]\u001b[A\n",
      "Epoch 1:  20%|██        | 166/824 [16:19<58:04,  5.30s/it, training_loss=0.158]\u001b[A\n",
      "Epoch 1:  20%|██        | 166/824 [16:24<58:04,  5.30s/it, training_loss=0.187]\u001b[A\n",
      "Epoch 1:  20%|██        | 167/824 [16:24<57:54,  5.29s/it, training_loss=0.187]\u001b[A\n",
      "Epoch 1:  20%|██        | 167/824 [16:29<57:54,  5.29s/it, training_loss=0.221]\u001b[A\n",
      "Epoch 1:  20%|██        | 168/824 [16:29<58:11,  5.32s/it, training_loss=0.221]\u001b[A\n",
      "Epoch 1:  20%|██        | 168/824 [16:34<58:11,  5.32s/it, training_loss=0.137]\u001b[A\n",
      "Epoch 1:  21%|██        | 169/824 [16:34<57:31,  5.27s/it, training_loss=0.137]\u001b[A\n",
      "Epoch 1:  21%|██        | 169/824 [16:40<57:31,  5.27s/it, training_loss=0.127]\u001b[A\n",
      "Epoch 1:  21%|██        | 170/824 [16:40<56:56,  5.22s/it, training_loss=0.127]\u001b[A\n",
      "Epoch 1:  21%|██        | 170/824 [16:45<56:56,  5.22s/it, training_loss=0.100]\u001b[A\n",
      "Epoch 1:  21%|██        | 171/824 [16:45<56:38,  5.20s/it, training_loss=0.100]\u001b[A\n",
      "Epoch 1:  21%|██        | 171/824 [16:50<56:38,  5.20s/it, training_loss=0.132]\u001b[A\n",
      "Epoch 1:  21%|██        | 172/824 [16:50<56:24,  5.19s/it, training_loss=0.132]\u001b[A\n",
      "Epoch 1:  21%|██        | 172/824 [16:55<56:24,  5.19s/it, training_loss=0.083]\u001b[A\n",
      "Epoch 1:  21%|██        | 173/824 [16:55<56:07,  5.17s/it, training_loss=0.083]\u001b[A\n",
      "Epoch 1:  21%|██        | 173/824 [17:00<56:07,  5.17s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  21%|██        | 174/824 [17:00<56:17,  5.20s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  21%|██        | 174/824 [17:06<56:17,  5.20s/it, training_loss=0.117]\u001b[A\n",
      "Epoch 1:  21%|██        | 175/824 [17:06<56:56,  5.26s/it, training_loss=0.117]\u001b[A\n",
      "Epoch 1:  21%|██        | 175/824 [17:11<56:56,  5.26s/it, training_loss=0.036]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 176/824 [17:11<56:33,  5.24s/it, training_loss=0.036]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 176/824 [17:16<56:33,  5.24s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 177/824 [17:16<56:19,  5.22s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  21%|██▏       | 177/824 [17:21<56:19,  5.22s/it, training_loss=0.142]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 178/824 [17:21<57:01,  5.30s/it, training_loss=0.142]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 178/824 [17:27<57:01,  5.30s/it, training_loss=0.162]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 179/824 [17:27<58:08,  5.41s/it, training_loss=0.162]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 179/824 [17:33<58:08,  5.41s/it, training_loss=0.060]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 180/824 [17:33<58:32,  5.45s/it, training_loss=0.060]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 180/824 [17:38<58:32,  5.45s/it, training_loss=0.151]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 181/824 [17:38<57:54,  5.40s/it, training_loss=0.151]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 181/824 [17:43<57:54,  5.40s/it, training_loss=0.119]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 182/824 [17:43<57:19,  5.36s/it, training_loss=0.119]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 182/824 [17:48<57:19,  5.36s/it, training_loss=0.449]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 183/824 [17:48<56:34,  5.29s/it, training_loss=0.449]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 183/824 [17:54<56:34,  5.29s/it, training_loss=0.141]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 184/824 [17:54<56:47,  5.32s/it, training_loss=0.141]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 184/824 [17:59<56:47,  5.32s/it, training_loss=0.205]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 185/824 [17:59<57:25,  5.39s/it, training_loss=0.205]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 185/824 [18:05<57:25,  5.39s/it, training_loss=0.171]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 186/824 [18:05<57:01,  5.36s/it, training_loss=0.171]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 186/824 [18:10<57:01,  5.36s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 187/824 [18:10<57:18,  5.40s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 187/824 [18:16<57:18,  5.40s/it, training_loss=0.154]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 188/824 [18:16<57:30,  5.43s/it, training_loss=0.154]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 188/824 [18:21<57:30,  5.43s/it, training_loss=0.161]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 189/824 [18:21<56:34,  5.35s/it, training_loss=0.161]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 189/824 [18:26<56:34,  5.35s/it, training_loss=0.079]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 190/824 [18:26<56:01,  5.30s/it, training_loss=0.079]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 190/824 [18:31<56:01,  5.30s/it, training_loss=0.119]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 191/824 [18:31<55:30,  5.26s/it, training_loss=0.119]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 191/824 [18:36<55:30,  5.26s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 192/824 [18:36<55:01,  5.22s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 192/824 [18:41<55:01,  5.22s/it, training_loss=0.129]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 193/824 [18:41<54:46,  5.21s/it, training_loss=0.129]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 193/824 [18:47<54:46,  5.21s/it, training_loss=0.100]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  24%|██▎       | 194/824 [18:47<54:30,  5.19s/it, training_loss=0.100]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 194/824 [18:52<54:30,  5.19s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 195/824 [18:52<54:39,  5.21s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 195/824 [18:57<54:39,  5.21s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 196/824 [18:57<54:01,  5.16s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 196/824 [19:02<54:01,  5.16s/it, training_loss=0.077]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 197/824 [19:02<54:24,  5.21s/it, training_loss=0.077]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 197/824 [19:08<54:24,  5.21s/it, training_loss=0.110]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 198/824 [19:08<54:46,  5.25s/it, training_loss=0.110]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 198/824 [19:13<54:46,  5.25s/it, training_loss=0.034]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 199/824 [19:13<55:17,  5.31s/it, training_loss=0.034]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 199/824 [19:18<55:17,  5.31s/it, training_loss=0.117]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 200/824 [19:18<54:47,  5.27s/it, training_loss=0.117]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 200/824 [19:24<54:47,  5.27s/it, training_loss=0.208]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 201/824 [19:24<54:53,  5.29s/it, training_loss=0.208]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 201/824 [19:29<54:53,  5.29s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 202/824 [19:29<55:03,  5.31s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 202/824 [19:34<55:03,  5.31s/it, training_loss=0.053]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 203/824 [19:34<55:18,  5.34s/it, training_loss=0.053]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 203/824 [19:40<55:18,  5.34s/it, training_loss=0.167]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 204/824 [19:40<55:03,  5.33s/it, training_loss=0.167]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 204/824 [19:45<55:03,  5.33s/it, training_loss=0.086]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 205/824 [19:45<55:24,  5.37s/it, training_loss=0.086]\u001b[A\n",
      "Epoch 1:  25%|██▍       | 205/824 [19:50<55:24,  5.37s/it, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 206/824 [19:50<55:04,  5.35s/it, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 206/824 [19:56<55:04,  5.35s/it, training_loss=0.202]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 207/824 [19:56<54:32,  5.30s/it, training_loss=0.202]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 207/824 [20:01<54:32,  5.30s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 208/824 [20:01<54:33,  5.31s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 208/824 [20:06<54:33,  5.31s/it, training_loss=0.069]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 209/824 [20:06<54:27,  5.31s/it, training_loss=0.069]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 209/824 [20:12<54:27,  5.31s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 210/824 [20:12<54:42,  5.35s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 210/824 [20:17<54:42,  5.35s/it, training_loss=0.100]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 211/824 [20:17<54:02,  5.29s/it, training_loss=0.100]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 211/824 [20:22<54:02,  5.29s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 212/824 [20:22<53:22,  5.23s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 212/824 [20:27<53:22,  5.23s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 213/824 [20:27<53:08,  5.22s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 213/824 [20:32<53:08,  5.22s/it, training_loss=0.069]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 214/824 [20:32<53:18,  5.24s/it, training_loss=0.069]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 214/824 [20:38<53:18,  5.24s/it, training_loss=0.151]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 215/824 [20:38<53:26,  5.27s/it, training_loss=0.151]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 215/824 [20:43<53:26,  5.27s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 216/824 [20:43<53:24,  5.27s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 216/824 [20:48<53:24,  5.27s/it, training_loss=0.067]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 217/824 [20:48<54:00,  5.34s/it, training_loss=0.067]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 217/824 [20:54<54:00,  5.34s/it, training_loss=0.152]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 218/824 [20:54<54:18,  5.38s/it, training_loss=0.152]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 218/824 [21:00<54:18,  5.38s/it, training_loss=0.071]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 219/824 [21:00<54:45,  5.43s/it, training_loss=0.071]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 219/824 [21:05<54:45,  5.43s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 220/824 [21:05<53:55,  5.36s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 220/824 [21:10<53:55,  5.36s/it, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 221/824 [21:10<53:53,  5.36s/it, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 221/824 [21:15<53:53,  5.36s/it, training_loss=0.114]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 222/824 [21:15<53:35,  5.34s/it, training_loss=0.114]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 222/824 [21:21<53:35,  5.34s/it, training_loss=0.119]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 223/824 [21:21<54:08,  5.40s/it, training_loss=0.119]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 223/824 [21:26<54:08,  5.40s/it, training_loss=0.428]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 224/824 [21:26<54:10,  5.42s/it, training_loss=0.428]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 224/824 [21:32<54:10,  5.42s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 225/824 [21:32<54:48,  5.49s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 225/824 [21:37<54:48,  5.49s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 226/824 [21:37<54:25,  5.46s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 226/824 [21:43<54:25,  5.46s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 227/824 [21:43<53:59,  5.43s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 227/824 [21:48<53:59,  5.43s/it, training_loss=0.180]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 228/824 [21:48<54:06,  5.45s/it, training_loss=0.180]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 228/824 [21:54<54:06,  5.45s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 229/824 [21:54<53:49,  5.43s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 229/824 [21:59<53:49,  5.43s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 230/824 [21:59<53:04,  5.36s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 230/824 [22:04<53:04,  5.36s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 231/824 [22:04<52:51,  5.35s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 231/824 [22:10<52:51,  5.35s/it, training_loss=0.157]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 232/824 [22:10<53:00,  5.37s/it, training_loss=0.157]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 232/824 [22:15<53:00,  5.37s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 233/824 [22:15<52:24,  5.32s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 233/824 [22:20<52:24,  5.32s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 234/824 [22:20<51:45,  5.26s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 234/824 [22:25<51:45,  5.26s/it, training_loss=0.120]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 235/824 [22:25<51:39,  5.26s/it, training_loss=0.120]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 235/824 [22:31<51:39,  5.26s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 236/824 [22:31<51:48,  5.29s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 1:  29%|██▊       | 236/824 [22:36<51:48,  5.29s/it, training_loss=0.067]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 237/824 [22:36<52:03,  5.32s/it, training_loss=0.067]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 237/824 [22:41<52:03,  5.32s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 238/824 [22:41<52:05,  5.33s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 238/824 [22:56<52:05,  5.33s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 239/824 [22:56<1:18:22,  8.04s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 239/824 [23:09<1:18:22,  8.04s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 240/824 [23:09<1:33:55,  9.65s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 240/824 [23:14<1:33:55,  9.65s/it, training_loss=0.055]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 241/824 [23:14<1:20:55,  8.33s/it, training_loss=0.055]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 241/824 [23:20<1:20:55,  8.33s/it, training_loss=0.463]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 242/824 [23:20<1:12:00,  7.42s/it, training_loss=0.463]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 242/824 [23:25<1:12:00,  7.42s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 243/824 [23:25<1:05:44,  6.79s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 243/824 [23:30<1:05:44,  6.79s/it, training_loss=0.162]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 244/824 [23:30<1:01:03,  6.32s/it, training_loss=0.162]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 244/824 [23:35<1:01:03,  6.32s/it, training_loss=0.117]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 245/824 [23:35<57:42,  5.98s/it, training_loss=0.117]  \u001b[A\n",
      "Epoch 1:  30%|██▉       | 245/824 [23:41<57:42,  5.98s/it, training_loss=0.031]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 246/824 [23:41<55:56,  5.81s/it, training_loss=0.031]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 246/824 [23:46<55:56,  5.81s/it, training_loss=0.058]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 247/824 [23:46<55:07,  5.73s/it, training_loss=0.058]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 247/824 [23:52<55:07,  5.73s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 1:  30%|███       | 248/824 [23:52<54:18,  5.66s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 1:  30%|███       | 248/824 [23:57<54:18,  5.66s/it, training_loss=0.152]\u001b[A\n",
      "Epoch 1:  30%|███       | 249/824 [23:57<53:45,  5.61s/it, training_loss=0.152]\u001b[A\n",
      "Epoch 1:  30%|███       | 249/824 [24:02<53:45,  5.61s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 1:  30%|███       | 250/824 [24:02<52:30,  5.49s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 1:  30%|███       | 250/824 [24:08<52:30,  5.49s/it, training_loss=0.100]\u001b[A\n",
      "Epoch 1:  30%|███       | 251/824 [24:08<51:48,  5.42s/it, training_loss=0.100]\u001b[A\n",
      "Epoch 1:  30%|███       | 251/824 [24:13<51:48,  5.42s/it, training_loss=0.232]\u001b[A\n",
      "Epoch 1:  31%|███       | 252/824 [24:13<51:12,  5.37s/it, training_loss=0.232]\u001b[A\n",
      "Epoch 1:  31%|███       | 252/824 [24:18<51:12,  5.37s/it, training_loss=0.225]\u001b[A\n",
      "Epoch 1:  31%|███       | 253/824 [24:18<50:34,  5.31s/it, training_loss=0.225]\u001b[A\n",
      "Epoch 1:  31%|███       | 253/824 [24:23<50:34,  5.31s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  31%|███       | 254/824 [24:23<50:13,  5.29s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  31%|███       | 254/824 [24:29<50:13,  5.29s/it, training_loss=0.037]\u001b[A\n",
      "Epoch 1:  31%|███       | 255/824 [24:29<49:54,  5.26s/it, training_loss=0.037]\u001b[A\n",
      "Epoch 1:  31%|███       | 255/824 [24:34<49:54,  5.26s/it, training_loss=0.087]\u001b[A\n",
      "Epoch 1:  31%|███       | 256/824 [24:34<50:20,  5.32s/it, training_loss=0.087]\u001b[A\n",
      "Epoch 1:  31%|███       | 256/824 [24:39<50:20,  5.32s/it, training_loss=0.034]\u001b[A\n",
      "Epoch 1:  31%|███       | 257/824 [24:39<50:04,  5.30s/it, training_loss=0.034]\u001b[A\n",
      "Epoch 1:  31%|███       | 257/824 [24:45<50:04,  5.30s/it, training_loss=0.056]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 258/824 [24:45<50:43,  5.38s/it, training_loss=0.056]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 258/824 [24:50<50:43,  5.38s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 259/824 [24:50<51:18,  5.45s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 1:  31%|███▏      | 259/824 [24:56<51:18,  5.45s/it, training_loss=0.106]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 260/824 [24:56<51:10,  5.44s/it, training_loss=0.106]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 260/824 [25:01<51:10,  5.44s/it, training_loss=0.406]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 261/824 [25:01<51:08,  5.45s/it, training_loss=0.406]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 261/824 [25:07<51:08,  5.45s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 262/824 [25:07<51:01,  5.45s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 262/824 [25:12<51:01,  5.45s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 263/824 [25:12<50:35,  5.41s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 263/824 [25:17<50:35,  5.41s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 264/824 [25:17<49:59,  5.36s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 264/824 [25:23<49:59,  5.36s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 265/824 [25:23<49:29,  5.31s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 265/824 [25:28<49:29,  5.31s/it, training_loss=0.080]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 266/824 [25:28<49:00,  5.27s/it, training_loss=0.080]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 266/824 [25:33<49:00,  5.27s/it, training_loss=0.203]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 267/824 [25:33<48:32,  5.23s/it, training_loss=0.203]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 267/824 [25:38<48:32,  5.23s/it, training_loss=0.092]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 268/824 [25:38<48:35,  5.24s/it, training_loss=0.092]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 268/824 [25:44<48:35,  5.24s/it, training_loss=0.190]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 269/824 [25:44<48:53,  5.29s/it, training_loss=0.190]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 269/824 [25:49<48:53,  5.29s/it, training_loss=0.106]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 270/824 [25:49<48:55,  5.30s/it, training_loss=0.106]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 270/824 [25:54<48:55,  5.30s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 271/824 [25:54<48:23,  5.25s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 271/824 [25:59<48:23,  5.25s/it, training_loss=0.238]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 272/824 [25:59<48:36,  5.28s/it, training_loss=0.238]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 272/824 [26:05<48:36,  5.28s/it, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 273/824 [26:05<48:43,  5.31s/it, training_loss=0.219]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 273/824 [26:10<48:43,  5.31s/it, training_loss=0.171]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 274/824 [26:10<48:50,  5.33s/it, training_loss=0.171]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 274/824 [26:16<48:50,  5.33s/it, training_loss=0.031]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 275/824 [26:16<49:26,  5.40s/it, training_loss=0.031]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 275/824 [26:21<49:26,  5.40s/it, training_loss=0.050]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 276/824 [26:21<49:34,  5.43s/it, training_loss=0.050]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 276/824 [26:27<49:34,  5.43s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 277/824 [26:27<49:23,  5.42s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 277/824 [26:32<49:23,  5.42s/it, training_loss=0.664]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 278/824 [26:32<49:00,  5.38s/it, training_loss=0.664]\u001b[A\n",
      "Epoch 1:  34%|███▎      | 278/824 [26:37<49:00,  5.38s/it, training_loss=0.164]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 279/824 [26:37<49:00,  5.40s/it, training_loss=0.164]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 279/824 [26:43<49:00,  5.40s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 280/824 [26:43<48:54,  5.39s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 280/824 [26:48<48:54,  5.39s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 281/824 [26:48<49:08,  5.43s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 281/824 [26:54<49:08,  5.43s/it, training_loss=0.116]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 282/824 [26:54<49:00,  5.43s/it, training_loss=0.116]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 282/824 [26:59<49:00,  5.43s/it, training_loss=0.178]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 283/824 [26:59<48:51,  5.42s/it, training_loss=0.178]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 283/824 [27:05<48:51,  5.42s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 284/824 [27:05<49:00,  5.45s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 284/824 [27:10<49:00,  5.45s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 285/824 [27:10<48:39,  5.42s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 285/824 [27:15<48:39,  5.42s/it, training_loss=0.149]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 286/824 [27:15<48:40,  5.43s/it, training_loss=0.149]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 286/824 [27:21<48:40,  5.43s/it, training_loss=0.083]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 287/824 [27:21<48:29,  5.42s/it, training_loss=0.083]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 287/824 [27:26<48:29,  5.42s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 288/824 [27:26<48:01,  5.38s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 1:  35%|███▍      | 288/824 [27:31<48:01,  5.38s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 289/824 [27:31<48:02,  5.39s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 289/824 [27:37<48:02,  5.39s/it, training_loss=0.362]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 290/824 [27:37<47:37,  5.35s/it, training_loss=0.362]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 290/824 [27:42<47:37,  5.35s/it, training_loss=0.042]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 291/824 [27:42<47:35,  5.36s/it, training_loss=0.042]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 291/824 [27:47<47:35,  5.36s/it, training_loss=0.088]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  35%|███▌      | 292/824 [27:47<47:32,  5.36s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 292/824 [27:53<47:32,  5.36s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 293/824 [27:53<47:22,  5.35s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 293/824 [27:58<47:22,  5.35s/it, training_loss=0.155]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 294/824 [27:58<47:32,  5.38s/it, training_loss=0.155]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 294/824 [28:04<47:32,  5.38s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 295/824 [28:04<47:38,  5.40s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 295/824 [28:09<47:38,  5.40s/it, training_loss=0.161]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 296/824 [28:09<47:44,  5.43s/it, training_loss=0.161]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 296/824 [28:14<47:44,  5.43s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 297/824 [28:14<47:09,  5.37s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 297/824 [28:20<47:09,  5.37s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 298/824 [28:20<47:04,  5.37s/it, training_loss=0.260]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 298/824 [28:25<47:04,  5.37s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 299/824 [28:25<46:26,  5.31s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 299/824 [28:30<46:26,  5.31s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 300/824 [28:30<46:26,  5.32s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 300/824 [28:36<46:26,  5.32s/it, training_loss=0.032]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 301/824 [28:36<46:11,  5.30s/it, training_loss=0.032]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 301/824 [28:41<46:11,  5.30s/it, training_loss=0.557]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 302/824 [28:41<45:49,  5.27s/it, training_loss=0.557]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 302/824 [28:46<45:49,  5.27s/it, training_loss=0.123]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 303/824 [28:46<46:03,  5.30s/it, training_loss=0.123]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 303/824 [28:51<46:03,  5.30s/it, training_loss=0.075]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 304/824 [28:51<46:11,  5.33s/it, training_loss=0.075]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 304/824 [28:57<46:11,  5.33s/it, training_loss=0.217]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 305/824 [28:57<45:58,  5.32s/it, training_loss=0.217]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 305/824 [29:02<45:58,  5.32s/it, training_loss=0.160]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 306/824 [29:02<45:56,  5.32s/it, training_loss=0.160]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 306/824 [29:08<45:56,  5.32s/it, training_loss=0.210]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 307/824 [29:08<46:11,  5.36s/it, training_loss=0.210]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 307/824 [29:13<46:11,  5.36s/it, training_loss=0.063]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 308/824 [29:13<46:38,  5.42s/it, training_loss=0.063]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 308/824 [29:19<46:38,  5.42s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 309/824 [29:19<46:42,  5.44s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 309/824 [29:24<46:42,  5.44s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 310/824 [29:24<46:55,  5.48s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 310/824 [29:30<46:55,  5.48s/it, training_loss=0.359]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 311/824 [29:30<46:29,  5.44s/it, training_loss=0.359]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 311/824 [29:35<46:29,  5.44s/it, training_loss=0.209]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 312/824 [29:35<46:14,  5.42s/it, training_loss=0.209]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 312/824 [29:40<46:14,  5.42s/it, training_loss=0.520]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 313/824 [29:40<45:42,  5.37s/it, training_loss=0.520]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 313/824 [29:45<45:42,  5.37s/it, training_loss=0.158]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 314/824 [29:45<45:19,  5.33s/it, training_loss=0.158]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 314/824 [29:51<45:19,  5.33s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 315/824 [29:51<45:42,  5.39s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 315/824 [29:56<45:42,  5.39s/it, training_loss=0.187]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 316/824 [29:56<45:31,  5.38s/it, training_loss=0.187]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 316/824 [30:02<45:31,  5.38s/it, training_loss=0.035]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 317/824 [30:02<45:47,  5.42s/it, training_loss=0.035]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 317/824 [30:07<45:47,  5.42s/it, training_loss=0.187]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 318/824 [30:07<45:55,  5.45s/it, training_loss=0.187]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 318/824 [30:13<45:55,  5.45s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 319/824 [30:13<45:53,  5.45s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 319/824 [30:18<45:53,  5.45s/it, training_loss=0.108]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 320/824 [30:18<45:24,  5.41s/it, training_loss=0.108]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 320/824 [30:23<45:24,  5.41s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 321/824 [30:23<45:01,  5.37s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 321/824 [30:29<45:01,  5.37s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 322/824 [30:29<44:41,  5.34s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 322/824 [30:34<44:41,  5.34s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 323/824 [30:34<44:56,  5.38s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 323/824 [30:39<44:56,  5.38s/it, training_loss=0.100]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 324/824 [30:39<44:53,  5.39s/it, training_loss=0.100]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 324/824 [30:45<44:53,  5.39s/it, training_loss=0.157]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 325/824 [30:45<44:33,  5.36s/it, training_loss=0.157]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 325/824 [30:50<44:33,  5.36s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 326/824 [30:50<44:10,  5.32s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 326/824 [30:55<44:10,  5.32s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 327/824 [30:55<43:44,  5.28s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 327/824 [31:01<43:44,  5.28s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 328/824 [31:01<44:26,  5.38s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 328/824 [31:06<44:26,  5.38s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 329/824 [31:06<44:03,  5.34s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 329/824 [31:11<44:03,  5.34s/it, training_loss=0.169]\u001b[A\n",
      "Epoch 1:  40%|████      | 330/824 [31:11<43:59,  5.34s/it, training_loss=0.169]\u001b[A\n",
      "Epoch 1:  40%|████      | 330/824 [31:17<43:59,  5.34s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 1:  40%|████      | 331/824 [31:17<43:38,  5.31s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 1:  40%|████      | 331/824 [31:22<43:38,  5.31s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 1:  40%|████      | 332/824 [31:22<43:54,  5.35s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 1:  40%|████      | 332/824 [31:28<43:54,  5.35s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  40%|████      | 333/824 [31:28<44:18,  5.41s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 1:  40%|████      | 333/824 [31:33<44:18,  5.41s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 1:  41%|████      | 334/824 [31:33<44:31,  5.45s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 1:  41%|████      | 334/824 [31:39<44:31,  5.45s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  41%|████      | 335/824 [31:39<44:34,  5.47s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  41%|████      | 335/824 [31:44<44:34,  5.47s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 1:  41%|████      | 336/824 [31:44<44:02,  5.42s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 1:  41%|████      | 336/824 [31:49<44:02,  5.42s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 1:  41%|████      | 337/824 [31:49<43:50,  5.40s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 1:  41%|████      | 337/824 [31:55<43:50,  5.40s/it, training_loss=0.108]\u001b[A\n",
      "Epoch 1:  41%|████      | 338/824 [31:55<43:37,  5.39s/it, training_loss=0.108]\u001b[A\n",
      "Epoch 1:  41%|████      | 338/824 [32:00<43:37,  5.39s/it, training_loss=0.095]\u001b[A\n",
      "Epoch 1:  41%|████      | 339/824 [32:00<43:30,  5.38s/it, training_loss=0.095]\u001b[A\n",
      "Epoch 1:  41%|████      | 339/824 [32:05<43:30,  5.38s/it, training_loss=0.035]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 340/824 [32:05<43:11,  5.36s/it, training_loss=0.035]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 340/824 [32:11<43:11,  5.36s/it, training_loss=0.379]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 341/824 [32:11<42:50,  5.32s/it, training_loss=0.379]\u001b[A\n",
      "Epoch 1:  41%|████▏     | 341/824 [32:16<42:50,  5.32s/it, training_loss=0.127]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 342/824 [32:16<42:31,  5.29s/it, training_loss=0.127]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 342/824 [32:21<42:31,  5.29s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 343/824 [32:21<42:07,  5.26s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 343/824 [32:26<42:07,  5.26s/it, training_loss=0.103]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 344/824 [32:26<41:51,  5.23s/it, training_loss=0.103]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 344/824 [32:31<41:51,  5.23s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 345/824 [32:31<41:41,  5.22s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 345/824 [32:37<41:41,  5.22s/it, training_loss=0.032]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 346/824 [32:37<41:39,  5.23s/it, training_loss=0.032]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 346/824 [32:42<41:39,  5.23s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 347/824 [32:42<41:41,  5.24s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 347/824 [32:47<41:41,  5.24s/it, training_loss=0.067]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 348/824 [32:47<41:43,  5.26s/it, training_loss=0.067]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 348/824 [32:53<41:43,  5.26s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 349/824 [32:53<41:45,  5.27s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 349/824 [32:58<41:45,  5.27s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 350/824 [32:58<41:39,  5.27s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 350/824 [33:03<41:39,  5.27s/it, training_loss=0.051]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 351/824 [33:03<41:26,  5.26s/it, training_loss=0.051]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 351/824 [33:08<41:26,  5.26s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 352/824 [33:08<41:38,  5.29s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 352/824 [33:14<41:38,  5.29s/it, training_loss=0.058]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 353/824 [33:14<41:33,  5.29s/it, training_loss=0.058]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 353/824 [33:19<41:33,  5.29s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 354/824 [33:19<41:15,  5.27s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 354/824 [33:24<41:15,  5.27s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 355/824 [33:24<40:50,  5.23s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 355/824 [33:29<40:50,  5.23s/it, training_loss=0.212]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 356/824 [33:29<40:56,  5.25s/it, training_loss=0.212]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 356/824 [33:35<40:56,  5.25s/it, training_loss=0.102]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 357/824 [33:35<40:58,  5.27s/it, training_loss=0.102]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 357/824 [33:40<40:58,  5.27s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 358/824 [33:40<40:59,  5.28s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 358/824 [33:45<40:59,  5.28s/it, training_loss=0.029]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 359/824 [33:45<41:03,  5.30s/it, training_loss=0.029]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 359/824 [33:51<41:03,  5.30s/it, training_loss=0.118]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 360/824 [33:51<40:49,  5.28s/it, training_loss=0.118]\u001b[A\n",
      "Epoch 1:  44%|████▎     | 360/824 [33:56<40:49,  5.28s/it, training_loss=0.055]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 361/824 [33:56<40:26,  5.24s/it, training_loss=0.055]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 361/824 [34:01<40:26,  5.24s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 362/824 [34:01<40:05,  5.21s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 362/824 [34:06<40:05,  5.21s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 363/824 [34:06<40:02,  5.21s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 363/824 [34:11<40:02,  5.21s/it, training_loss=0.098]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 364/824 [34:11<40:03,  5.22s/it, training_loss=0.098]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 364/824 [34:16<40:03,  5.22s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 365/824 [34:16<39:58,  5.23s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 365/824 [34:22<39:58,  5.23s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 366/824 [34:22<39:48,  5.21s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 366/824 [34:27<39:48,  5.21s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 367/824 [34:27<39:37,  5.20s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 367/824 [34:32<39:37,  5.20s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 368/824 [34:32<39:40,  5.22s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 368/824 [34:38<39:40,  5.22s/it, training_loss=0.036]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 369/824 [34:38<40:26,  5.33s/it, training_loss=0.036]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 369/824 [34:43<40:26,  5.33s/it, training_loss=0.512]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 370/824 [34:43<40:35,  5.37s/it, training_loss=0.512]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 370/824 [34:49<40:35,  5.37s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 371/824 [34:49<40:39,  5.39s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 371/824 [34:54<40:39,  5.39s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 372/824 [34:54<40:39,  5.40s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 372/824 [34:59<40:39,  5.40s/it, training_loss=0.036]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 373/824 [34:59<40:38,  5.41s/it, training_loss=0.036]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 373/824 [35:05<40:38,  5.41s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 374/824 [35:05<40:31,  5.40s/it, training_loss=0.278]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 374/824 [35:10<40:31,  5.40s/it, training_loss=0.118]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 375/824 [35:10<40:32,  5.42s/it, training_loss=0.118]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 375/824 [35:16<40:32,  5.42s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 376/824 [35:16<40:30,  5.43s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 376/824 [35:21<40:30,  5.43s/it, training_loss=0.037]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 377/824 [35:21<40:24,  5.43s/it, training_loss=0.037]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 377/824 [35:27<40:24,  5.43s/it, training_loss=0.152]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 378/824 [35:27<40:21,  5.43s/it, training_loss=0.152]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 378/824 [35:32<40:21,  5.43s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 379/824 [35:32<40:14,  5.43s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 379/824 [35:37<40:14,  5.43s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 380/824 [35:37<40:06,  5.42s/it, training_loss=0.286]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 380/824 [35:43<40:06,  5.42s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 381/824 [35:43<40:49,  5.53s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 381/824 [35:50<40:49,  5.53s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 382/824 [35:50<42:54,  5.82s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 382/824 [35:56<42:54,  5.82s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 383/824 [35:56<43:14,  5.88s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  46%|████▋     | 383/824 [36:01<43:14,  5.88s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 384/824 [36:01<42:29,  5.79s/it, training_loss=0.323]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 384/824 [36:07<42:29,  5.79s/it, training_loss=0.182]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 385/824 [36:07<41:43,  5.70s/it, training_loss=0.182]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 385/824 [36:12<41:43,  5.70s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 386/824 [36:12<41:13,  5.65s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 386/824 [36:18<41:13,  5.65s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 387/824 [36:18<40:48,  5.60s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 387/824 [36:24<40:48,  5.60s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 388/824 [36:24<41:07,  5.66s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 388/824 [36:29<41:07,  5.66s/it, training_loss=0.390]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 389/824 [36:29<40:43,  5.62s/it, training_loss=0.390]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 389/824 [36:35<40:43,  5.62s/it, training_loss=0.024]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  47%|████▋     | 390/824 [36:35<41:09,  5.69s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 390/824 [36:41<41:09,  5.69s/it, training_loss=0.022]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 391/824 [36:41<41:41,  5.78s/it, training_loss=0.022]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 391/824 [36:47<41:41,  5.78s/it, training_loss=0.115]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 392/824 [36:47<41:15,  5.73s/it, training_loss=0.115]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 392/824 [36:52<41:15,  5.73s/it, training_loss=0.182]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 393/824 [36:52<40:40,  5.66s/it, training_loss=0.182]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 393/824 [36:58<40:40,  5.66s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 394/824 [36:58<40:22,  5.63s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 394/824 [37:03<40:22,  5.63s/it, training_loss=0.126]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 395/824 [37:03<40:04,  5.60s/it, training_loss=0.126]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 395/824 [37:09<40:04,  5.60s/it, training_loss=0.172]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 396/824 [37:09<40:48,  5.72s/it, training_loss=0.172]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 396/824 [37:15<40:48,  5.72s/it, training_loss=0.032]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 397/824 [37:15<41:01,  5.77s/it, training_loss=0.032]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 397/824 [37:21<41:01,  5.77s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 398/824 [37:21<40:25,  5.69s/it, training_loss=0.329]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 398/824 [37:26<40:25,  5.69s/it, training_loss=0.058]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 399/824 [37:26<40:21,  5.70s/it, training_loss=0.058]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 399/824 [37:32<40:21,  5.70s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 400/824 [37:32<40:51,  5.78s/it, training_loss=0.227]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 400/824 [37:38<40:51,  5.78s/it, training_loss=0.054]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 401/824 [37:38<40:17,  5.72s/it, training_loss=0.054]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 401/824 [37:43<40:17,  5.72s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 402/824 [37:43<39:55,  5.68s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 402/824 [37:49<39:55,  5.68s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 403/824 [37:49<40:17,  5.74s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 403/824 [37:55<40:17,  5.74s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 404/824 [37:55<39:38,  5.66s/it, training_loss=0.066]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 404/824 [38:00<39:38,  5.66s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 405/824 [38:00<39:32,  5.66s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 405/824 [38:06<39:32,  5.66s/it, training_loss=0.072]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 406/824 [38:06<38:58,  5.59s/it, training_loss=0.072]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 406/824 [38:11<38:58,  5.59s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 407/824 [38:11<38:50,  5.59s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 407/824 [38:17<38:50,  5.59s/it, training_loss=0.569]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 408/824 [38:17<39:10,  5.65s/it, training_loss=0.569]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 408/824 [38:23<39:10,  5.65s/it, training_loss=0.035]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 409/824 [38:23<39:08,  5.66s/it, training_loss=0.035]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 409/824 [38:28<39:08,  5.66s/it, training_loss=0.045]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 410/824 [38:28<38:32,  5.59s/it, training_loss=0.045]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 410/824 [38:34<38:32,  5.59s/it, training_loss=0.166]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 411/824 [38:34<38:04,  5.53s/it, training_loss=0.166]\u001b[A\n",
      "Epoch 1:  50%|████▉     | 411/824 [38:39<38:04,  5.53s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 1:  50%|█████     | 412/824 [38:39<37:49,  5.51s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 1:  50%|█████     | 412/824 [38:45<37:49,  5.51s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  50%|█████     | 413/824 [38:45<37:31,  5.48s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  50%|█████     | 413/824 [38:50<37:31,  5.48s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  50%|█████     | 414/824 [38:50<37:13,  5.45s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 1:  50%|█████     | 414/824 [38:55<37:13,  5.45s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  50%|█████     | 415/824 [38:55<37:03,  5.44s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 1:  50%|█████     | 415/824 [39:01<37:03,  5.44s/it, training_loss=0.148]\u001b[A\n",
      "Epoch 1:  50%|█████     | 416/824 [39:01<37:33,  5.52s/it, training_loss=0.148]\u001b[A\n",
      "Epoch 1:  50%|█████     | 416/824 [39:07<37:33,  5.52s/it, training_loss=0.369]\u001b[A\n",
      "Epoch 1:  51%|█████     | 417/824 [39:07<37:36,  5.54s/it, training_loss=0.369]\u001b[A\n",
      "Epoch 1:  51%|█████     | 417/824 [39:13<37:36,  5.54s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  51%|█████     | 418/824 [39:13<38:03,  5.62s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  51%|█████     | 418/824 [39:19<38:03,  5.62s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  51%|█████     | 419/824 [39:19<38:56,  5.77s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  51%|█████     | 419/824 [39:25<38:56,  5.77s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  51%|█████     | 420/824 [39:25<39:24,  5.85s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  51%|█████     | 420/824 [39:30<39:24,  5.85s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  51%|█████     | 421/824 [39:30<38:52,  5.79s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  51%|█████     | 421/824 [39:36<38:52,  5.79s/it, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  51%|█████     | 422/824 [39:36<38:23,  5.73s/it, training_loss=0.248]\u001b[A\n",
      "Epoch 1:  51%|█████     | 422/824 [39:42<38:23,  5.73s/it, training_loss=0.213]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 423/824 [39:42<38:01,  5.69s/it, training_loss=0.213]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 423/824 [39:47<38:01,  5.69s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 424/824 [39:47<37:24,  5.61s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 424/824 [39:53<37:24,  5.61s/it, training_loss=0.199]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 425/824 [39:53<37:43,  5.67s/it, training_loss=0.199]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 425/824 [39:58<37:43,  5.67s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 426/824 [39:58<37:08,  5.60s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 426/824 [40:04<37:08,  5.60s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 427/824 [40:04<36:54,  5.58s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 427/824 [40:09<36:54,  5.58s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 428/824 [40:09<36:26,  5.52s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 428/824 [40:15<36:26,  5.52s/it, training_loss=0.139]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 429/824 [40:15<36:11,  5.50s/it, training_loss=0.139]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 429/824 [40:20<36:11,  5.50s/it, training_loss=0.509]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 430/824 [40:20<35:53,  5.47s/it, training_loss=0.509]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 430/824 [40:25<35:53,  5.47s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 431/824 [40:25<35:40,  5.45s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 431/824 [40:31<35:40,  5.45s/it, training_loss=0.050]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 432/824 [40:31<35:30,  5.44s/it, training_loss=0.050]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 432/824 [40:36<35:30,  5.44s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 433/824 [40:36<35:21,  5.42s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 433/824 [40:42<35:21,  5.42s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 434/824 [40:42<35:14,  5.42s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 434/824 [40:47<35:14,  5.42s/it, training_loss=0.377]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 435/824 [40:47<35:06,  5.42s/it, training_loss=0.377]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 435/824 [40:52<35:06,  5.42s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 436/824 [40:52<35:02,  5.42s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 436/824 [40:58<35:02,  5.42s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 437/824 [40:58<35:09,  5.45s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 437/824 [41:04<35:09,  5.45s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 438/824 [41:04<35:30,  5.52s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 438/824 [41:10<35:30,  5.52s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 439/824 [41:10<36:13,  5.64s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 439/824 [41:15<36:13,  5.64s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 440/824 [41:15<36:22,  5.68s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 440/824 [41:21<36:22,  5.68s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 441/824 [41:21<36:50,  5.77s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 441/824 [41:27<36:50,  5.77s/it, training_loss=0.090]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 442/824 [41:27<37:33,  5.90s/it, training_loss=0.090]\u001b[A\n",
      "Epoch 1:  54%|█████▎    | 442/824 [41:33<37:33,  5.90s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 443/824 [41:33<37:10,  5.86s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 443/824 [41:39<37:10,  5.86s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 444/824 [41:39<37:13,  5.88s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 444/824 [41:45<37:13,  5.88s/it, training_loss=0.117]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 445/824 [41:45<36:21,  5.76s/it, training_loss=0.117]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 445/824 [41:50<36:21,  5.76s/it, training_loss=0.378]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 446/824 [41:50<36:01,  5.72s/it, training_loss=0.378]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 446/824 [41:56<36:01,  5.72s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 447/824 [41:56<36:14,  5.77s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 447/824 [42:02<36:14,  5.77s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 448/824 [42:02<36:51,  5.88s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 448/824 [42:08<36:51,  5.88s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 449/824 [42:08<36:39,  5.87s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 449/824 [42:14<36:39,  5.87s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 450/824 [42:14<36:21,  5.83s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 450/824 [42:20<36:21,  5.83s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 451/824 [42:20<36:15,  5.83s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 451/824 [42:26<36:15,  5.83s/it, training_loss=0.077]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 452/824 [42:26<36:13,  5.84s/it, training_loss=0.077]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 452/824 [42:32<36:13,  5.84s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 453/824 [42:32<36:29,  5.90s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 453/824 [42:38<36:29,  5.90s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 454/824 [42:38<36:35,  5.93s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 454/824 [42:43<36:35,  5.93s/it, training_loss=0.367]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 455/824 [42:43<36:11,  5.88s/it, training_loss=0.367]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 455/824 [42:49<36:11,  5.88s/it, training_loss=0.170]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 456/824 [42:49<35:51,  5.85s/it, training_loss=0.170]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 456/824 [42:55<35:51,  5.85s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 457/824 [42:55<35:48,  5.85s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 457/824 [43:01<35:48,  5.85s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 458/824 [43:01<35:13,  5.77s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 458/824 [43:06<35:13,  5.77s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 459/824 [43:06<34:24,  5.66s/it, training_loss=0.255]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 459/824 [43:11<34:24,  5.66s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 460/824 [43:11<33:52,  5.58s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 460/824 [43:17<33:52,  5.58s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 461/824 [43:17<33:36,  5.56s/it, training_loss=0.223]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 461/824 [43:22<33:36,  5.56s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 462/824 [43:22<33:30,  5.55s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 462/824 [43:28<33:30,  5.55s/it, training_loss=0.503]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 463/824 [43:28<33:26,  5.56s/it, training_loss=0.503]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 463/824 [43:34<33:26,  5.56s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 464/824 [43:34<34:01,  5.67s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 464/824 [43:40<34:01,  5.67s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 465/824 [43:40<34:27,  5.76s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  56%|█████▋    | 465/824 [43:46<34:27,  5.76s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 466/824 [43:46<34:32,  5.79s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 466/824 [43:52<34:32,  5.79s/it, training_loss=0.147]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 467/824 [43:52<34:21,  5.77s/it, training_loss=0.147]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 467/824 [43:57<34:21,  5.77s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 468/824 [43:57<33:56,  5.72s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 468/824 [44:03<33:56,  5.72s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 469/824 [44:03<33:42,  5.70s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 469/824 [44:08<33:42,  5.70s/it, training_loss=0.086]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 470/824 [44:08<33:03,  5.60s/it, training_loss=0.086]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 470/824 [44:14<33:03,  5.60s/it, training_loss=0.176]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 471/824 [44:14<32:55,  5.60s/it, training_loss=0.176]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 471/824 [44:19<32:55,  5.60s/it, training_loss=0.192]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 472/824 [44:19<33:00,  5.63s/it, training_loss=0.192]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 472/824 [44:25<33:00,  5.63s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 473/824 [44:25<33:00,  5.64s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 473/824 [44:31<33:00,  5.64s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 474/824 [44:31<32:53,  5.64s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 474/824 [44:36<32:53,  5.64s/it, training_loss=0.087]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 475/824 [44:36<32:47,  5.64s/it, training_loss=0.087]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 475/824 [44:42<32:47,  5.64s/it, training_loss=0.037]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 476/824 [44:42<32:49,  5.66s/it, training_loss=0.037]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 476/824 [44:48<32:49,  5.66s/it, training_loss=0.191]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 477/824 [44:48<33:02,  5.71s/it, training_loss=0.191]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 477/824 [44:54<33:02,  5.71s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 478/824 [44:54<32:58,  5.72s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 478/824 [45:00<32:58,  5.72s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 479/824 [45:00<33:07,  5.76s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 479/824 [45:05<33:07,  5.76s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 480/824 [45:05<32:47,  5.72s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 480/824 [45:11<32:47,  5.72s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 481/824 [45:11<32:38,  5.71s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 481/824 [45:16<32:38,  5.71s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 482/824 [45:16<32:26,  5.69s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 482/824 [45:22<32:26,  5.69s/it, training_loss=0.144]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 483/824 [45:22<32:29,  5.72s/it, training_loss=0.144]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 483/824 [45:28<32:29,  5.72s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 484/824 [45:28<32:01,  5.65s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  59%|█████▊    | 484/824 [45:33<32:01,  5.65s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 485/824 [45:33<31:36,  5.59s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 485/824 [45:39<31:36,  5.59s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 486/824 [45:39<31:47,  5.64s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 486/824 [45:45<31:47,  5.64s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 487/824 [45:45<31:35,  5.62s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 487/824 [45:50<31:35,  5.62s/it, training_loss=0.006]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  59%|█████▉    | 488/824 [45:50<31:27,  5.62s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 488/824 [45:56<31:27,  5.62s/it, training_loss=0.114]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 489/824 [45:56<31:05,  5.57s/it, training_loss=0.114]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 489/824 [46:01<31:05,  5.57s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 490/824 [46:01<30:41,  5.51s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 490/824 [46:06<30:41,  5.51s/it, training_loss=0.043]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 491/824 [46:06<30:26,  5.49s/it, training_loss=0.043]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 491/824 [46:12<30:26,  5.49s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 492/824 [46:12<30:19,  5.48s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 492/824 [46:17<30:19,  5.48s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 493/824 [46:17<30:06,  5.46s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 493/824 [46:22<30:06,  5.46s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 494/824 [46:22<29:16,  5.32s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 1:  60%|█████▉    | 494/824 [46:27<29:16,  5.32s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  60%|██████    | 495/824 [46:27<28:32,  5.21s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  60%|██████    | 495/824 [46:32<28:32,  5.21s/it, training_loss=0.500]\u001b[A\n",
      "Epoch 1:  60%|██████    | 496/824 [46:32<28:17,  5.17s/it, training_loss=0.500]\u001b[A\n",
      "Epoch 1:  60%|██████    | 496/824 [46:38<28:17,  5.17s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  60%|██████    | 497/824 [46:38<28:27,  5.22s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  60%|██████    | 497/824 [46:43<28:27,  5.22s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 1:  60%|██████    | 498/824 [46:43<28:53,  5.32s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 1:  60%|██████    | 498/824 [46:49<28:53,  5.32s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 1:  61%|██████    | 499/824 [46:49<29:10,  5.39s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 1:  61%|██████    | 499/824 [46:54<29:10,  5.39s/it, training_loss=0.184]\u001b[A\n",
      "Epoch 1:  61%|██████    | 500/824 [46:54<29:08,  5.40s/it, training_loss=0.184]\u001b[A\n",
      "Epoch 1:  61%|██████    | 500/824 [47:00<29:08,  5.40s/it, training_loss=0.079]\u001b[A\n",
      "Epoch 1:  61%|██████    | 501/824 [47:00<29:00,  5.39s/it, training_loss=0.079]\u001b[A\n",
      "Epoch 1:  61%|██████    | 501/824 [47:05<29:00,  5.39s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  61%|██████    | 502/824 [47:05<28:53,  5.38s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  61%|██████    | 502/824 [47:10<28:53,  5.38s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  61%|██████    | 503/824 [47:10<29:07,  5.44s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 1:  61%|██████    | 503/824 [47:16<29:07,  5.44s/it, training_loss=0.029]\u001b[A\n",
      "Epoch 1:  61%|██████    | 504/824 [47:16<29:20,  5.50s/it, training_loss=0.029]\u001b[A\n",
      "Epoch 1:  61%|██████    | 504/824 [47:22<29:20,  5.50s/it, training_loss=0.191]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 505/824 [47:22<29:24,  5.53s/it, training_loss=0.191]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 505/824 [47:27<29:24,  5.53s/it, training_loss=0.191]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 506/824 [47:27<29:39,  5.59s/it, training_loss=0.191]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 506/824 [47:33<29:39,  5.59s/it, training_loss=0.150]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 507/824 [47:33<29:53,  5.66s/it, training_loss=0.150]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 507/824 [47:39<29:53,  5.66s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 508/824 [47:39<30:09,  5.73s/it, training_loss=0.233]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 508/824 [47:45<30:09,  5.73s/it, training_loss=0.029]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 509/824 [47:45<30:07,  5.74s/it, training_loss=0.029]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 509/824 [47:50<30:07,  5.74s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 510/824 [47:50<29:34,  5.65s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 510/824 [47:56<29:34,  5.65s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 511/824 [47:56<30:00,  5.75s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 511/824 [48:02<30:00,  5.75s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 512/824 [48:02<29:40,  5.71s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 512/824 [48:08<29:40,  5.71s/it, training_loss=0.092]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 513/824 [48:08<30:00,  5.79s/it, training_loss=0.092]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 513/824 [48:14<30:00,  5.79s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 514/824 [48:14<30:05,  5.82s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 514/824 [48:19<30:05,  5.82s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  62%|██████▎   | 515/824 [48:19<29:39,  5.76s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  62%|██████▎   | 515/824 [48:25<29:39,  5.76s/it, training_loss=0.571]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 516/824 [48:25<29:30,  5.75s/it, training_loss=0.571]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 516/824 [48:31<29:30,  5.75s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 517/824 [48:31<29:23,  5.74s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 517/824 [48:37<29:23,  5.74s/it, training_loss=0.054]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 518/824 [48:37<29:14,  5.73s/it, training_loss=0.054]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 518/824 [48:42<29:14,  5.73s/it, training_loss=0.238]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 519/824 [48:42<29:07,  5.73s/it, training_loss=0.238]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 519/824 [48:48<29:07,  5.73s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 520/824 [48:48<29:09,  5.76s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 520/824 [48:54<29:09,  5.76s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 521/824 [48:54<28:57,  5.74s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 521/824 [49:00<28:57,  5.74s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 522/824 [49:00<28:48,  5.72s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 522/824 [49:05<28:48,  5.72s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 523/824 [49:05<28:40,  5.71s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 523/824 [49:11<28:40,  5.71s/it, training_loss=0.133]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 524/824 [49:11<28:30,  5.70s/it, training_loss=0.133]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 524/824 [49:16<28:30,  5.70s/it, training_loss=0.342]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 525/824 [49:16<27:58,  5.61s/it, training_loss=0.342]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 525/824 [49:22<27:58,  5.61s/it, training_loss=0.392]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 526/824 [49:22<27:39,  5.57s/it, training_loss=0.392]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 526/824 [49:27<27:39,  5.57s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 527/824 [49:27<27:38,  5.59s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 527/824 [49:33<27:38,  5.59s/it, training_loss=0.062]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 528/824 [49:33<27:39,  5.61s/it, training_loss=0.062]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 528/824 [49:39<27:39,  5.61s/it, training_loss=0.092]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 529/824 [49:39<27:23,  5.57s/it, training_loss=0.092]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 529/824 [49:45<27:23,  5.57s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 530/824 [49:45<28:15,  5.77s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 530/824 [49:51<28:15,  5.77s/it, training_loss=0.122]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 531/824 [49:51<28:15,  5.79s/it, training_loss=0.122]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 531/824 [49:56<28:15,  5.79s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 532/824 [49:56<28:09,  5.78s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 532/824 [50:03<28:09,  5.78s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 533/824 [50:03<28:46,  5.93s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 533/824 [50:08<28:46,  5.93s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 534/824 [50:08<28:03,  5.80s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 534/824 [50:14<28:03,  5.80s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 535/824 [50:14<27:38,  5.74s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 535/824 [50:19<27:38,  5.74s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 536/824 [50:19<27:16,  5.68s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 536/824 [50:25<27:16,  5.68s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 537/824 [50:25<27:02,  5.65s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 537/824 [50:30<27:02,  5.65s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 538/824 [50:30<26:47,  5.62s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 538/824 [50:36<26:47,  5.62s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 539/824 [50:36<26:35,  5.60s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  65%|██████▌   | 539/824 [50:41<26:35,  5.60s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 540/824 [50:41<26:22,  5.57s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 540/824 [50:47<26:22,  5.57s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 541/824 [50:47<26:14,  5.56s/it, training_loss=0.301]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 541/824 [50:53<26:14,  5.56s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 542/824 [50:53<26:08,  5.56s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 542/824 [50:58<26:08,  5.56s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 543/824 [50:58<26:02,  5.56s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 543/824 [51:03<26:02,  5.56s/it, training_loss=0.056]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 544/824 [51:03<25:34,  5.48s/it, training_loss=0.056]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 544/824 [51:09<25:34,  5.48s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 545/824 [51:09<25:33,  5.50s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 545/824 [51:15<25:33,  5.50s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 546/824 [51:15<25:34,  5.52s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 546/824 [51:20<25:34,  5.52s/it, training_loss=0.353]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 547/824 [51:20<25:25,  5.51s/it, training_loss=0.353]\u001b[A\n",
      "Epoch 1:  66%|██████▋   | 547/824 [51:26<25:25,  5.51s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 548/824 [51:26<25:26,  5.53s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 548/824 [51:31<25:26,  5.53s/it, training_loss=0.144]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 549/824 [51:31<25:18,  5.52s/it, training_loss=0.144]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 549/824 [51:37<25:18,  5.52s/it, training_loss=0.437]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 550/824 [51:37<25:16,  5.53s/it, training_loss=0.437]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 550/824 [51:42<25:16,  5.53s/it, training_loss=0.198]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 551/824 [51:42<25:10,  5.53s/it, training_loss=0.198]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 551/824 [51:48<25:10,  5.53s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 552/824 [51:48<25:11,  5.56s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 552/824 [51:53<25:11,  5.56s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 553/824 [51:53<25:03,  5.55s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 553/824 [51:59<25:03,  5.55s/it, training_loss=0.078]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 554/824 [51:59<24:54,  5.53s/it, training_loss=0.078]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 554/824 [52:04<24:54,  5.53s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 555/824 [52:04<24:47,  5.53s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 555/824 [52:10<24:47,  5.53s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 556/824 [52:10<24:41,  5.53s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 556/824 [52:15<24:41,  5.53s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 557/824 [52:15<24:40,  5.54s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 557/824 [52:21<24:40,  5.54s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 558/824 [52:21<24:32,  5.53s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 558/824 [52:27<24:32,  5.53s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 559/824 [52:27<24:27,  5.54s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 559/824 [52:32<24:27,  5.54s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 560/824 [52:32<24:12,  5.50s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 560/824 [52:37<24:12,  5.50s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 561/824 [52:37<24:06,  5.50s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 561/824 [52:43<24:06,  5.50s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 562/824 [52:43<24:06,  5.52s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 562/824 [52:49<24:06,  5.52s/it, training_loss=0.058]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 563/824 [52:49<24:02,  5.53s/it, training_loss=0.058]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 563/824 [52:54<24:02,  5.53s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 564/824 [52:54<23:55,  5.52s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 564/824 [53:00<23:55,  5.52s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  69%|██████▊   | 565/824 [53:00<23:54,  5.54s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 1:  69%|██████▊   | 565/824 [53:05<23:54,  5.54s/it, training_loss=0.722]\u001b[A\n",
      "Epoch 1:  69%|██████▊   | 566/824 [53:05<23:45,  5.52s/it, training_loss=0.722]\u001b[A\n",
      "Epoch 1:  69%|██████▊   | 566/824 [53:11<23:45,  5.52s/it, training_loss=0.150]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 567/824 [53:11<23:42,  5.53s/it, training_loss=0.150]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 567/824 [53:16<23:42,  5.53s/it, training_loss=0.412]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 568/824 [53:16<23:36,  5.53s/it, training_loss=0.412]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 568/824 [53:22<23:36,  5.53s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 569/824 [53:22<23:29,  5.53s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 569/824 [53:27<23:29,  5.53s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 570/824 [53:27<23:25,  5.53s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 570/824 [53:33<23:25,  5.53s/it, training_loss=0.342]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 571/824 [53:33<23:15,  5.52s/it, training_loss=0.342]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 571/824 [53:38<23:15,  5.52s/it, training_loss=0.745]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 572/824 [53:38<23:23,  5.57s/it, training_loss=0.745]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 572/824 [53:44<23:23,  5.57s/it, training_loss=0.160]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 573/824 [53:44<23:33,  5.63s/it, training_loss=0.160]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 573/824 [53:50<23:33,  5.63s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 574/824 [53:50<23:25,  5.62s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 574/824 [53:55<23:25,  5.62s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 575/824 [53:55<23:06,  5.57s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 575/824 [54:01<23:06,  5.57s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 576/824 [54:01<22:52,  5.53s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 576/824 [54:06<22:52,  5.53s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 1:  70%|███████   | 577/824 [54:06<22:39,  5.50s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 1:  70%|███████   | 577/824 [54:12<22:39,  5.50s/it, training_loss=0.073]\u001b[A\n",
      "Epoch 1:  70%|███████   | 578/824 [54:12<22:29,  5.48s/it, training_loss=0.073]\u001b[A\n",
      "Epoch 1:  70%|███████   | 578/824 [54:17<22:29,  5.48s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  70%|███████   | 579/824 [54:17<22:20,  5.47s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  70%|███████   | 579/824 [54:22<22:20,  5.47s/it, training_loss=0.180]\u001b[A\n",
      "Epoch 1:  70%|███████   | 580/824 [54:22<22:11,  5.46s/it, training_loss=0.180]\u001b[A\n",
      "Epoch 1:  70%|███████   | 580/824 [54:28<22:11,  5.46s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 1:  71%|███████   | 581/824 [54:28<22:01,  5.44s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 1:  71%|███████   | 581/824 [54:33<22:01,  5.44s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  71%|███████   | 582/824 [54:33<21:55,  5.44s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  71%|███████   | 582/824 [54:39<21:55,  5.44s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  71%|███████   | 583/824 [54:39<21:47,  5.43s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  71%|███████   | 583/824 [54:44<21:47,  5.43s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  71%|███████   | 584/824 [54:44<21:45,  5.44s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  71%|███████   | 584/824 [54:50<21:45,  5.44s/it, training_loss=0.352]\u001b[A\n",
      "Epoch 1:  71%|███████   | 585/824 [54:50<21:41,  5.44s/it, training_loss=0.352]\u001b[A\n",
      "Epoch 1:  71%|███████   | 585/824 [54:55<21:41,  5.44s/it, training_loss=0.449]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  71%|███████   | 586/824 [54:55<21:34,  5.44s/it, training_loss=0.449]\u001b[A\n",
      "Epoch 1:  71%|███████   | 586/824 [55:00<21:34,  5.44s/it, training_loss=0.151]\u001b[A\n",
      "Epoch 1:  71%|███████   | 587/824 [55:00<21:28,  5.44s/it, training_loss=0.151]\u001b[A\n",
      "Epoch 1:  71%|███████   | 587/824 [55:06<21:28,  5.44s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  71%|███████▏  | 588/824 [55:06<21:23,  5.44s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  71%|███████▏  | 588/824 [55:11<21:23,  5.44s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  71%|███████▏  | 589/824 [55:11<21:20,  5.45s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  71%|███████▏  | 589/824 [55:17<21:20,  5.45s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 590/824 [55:17<21:13,  5.44s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 590/824 [55:22<21:13,  5.44s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 591/824 [55:22<21:07,  5.44s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 591/824 [55:28<21:07,  5.44s/it, training_loss=0.188]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 592/824 [55:28<21:02,  5.44s/it, training_loss=0.188]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 592/824 [55:33<21:02,  5.44s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 593/824 [55:33<20:54,  5.43s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 593/824 [55:39<20:54,  5.43s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 594/824 [55:39<20:47,  5.42s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 594/824 [55:44<20:47,  5.42s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 595/824 [55:44<20:43,  5.43s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 595/824 [55:49<20:43,  5.43s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 596/824 [55:49<20:36,  5.42s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 596/824 [55:55<20:36,  5.42s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 597/824 [55:55<20:31,  5.42s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 597/824 [56:00<20:31,  5.42s/it, training_loss=0.138]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 598/824 [56:00<20:25,  5.42s/it, training_loss=0.138]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 598/824 [56:06<20:25,  5.42s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 599/824 [56:06<20:19,  5.42s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 599/824 [56:11<20:19,  5.42s/it, training_loss=0.108]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 600/824 [56:11<20:16,  5.43s/it, training_loss=0.108]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 600/824 [56:16<20:16,  5.43s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 601/824 [56:17<20:10,  5.43s/it, training_loss=0.309]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 601/824 [56:22<20:10,  5.43s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 602/824 [56:22<20:05,  5.43s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 602/824 [56:27<20:05,  5.43s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 603/824 [56:27<19:59,  5.43s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 603/824 [56:33<19:59,  5.43s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 604/824 [56:33<19:58,  5.45s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 604/824 [56:38<19:58,  5.45s/it, training_loss=0.661]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 605/824 [56:38<19:53,  5.45s/it, training_loss=0.661]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 605/824 [56:44<19:53,  5.45s/it, training_loss=0.171]\u001b[A\n",
      "Epoch 1:  74%|███████▎  | 606/824 [56:44<19:54,  5.48s/it, training_loss=0.171]\u001b[A\n",
      "Epoch 1:  74%|███████▎  | 606/824 [56:49<19:54,  5.48s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  74%|███████▎  | 607/824 [56:49<19:56,  5.51s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  74%|███████▎  | 607/824 [56:55<19:56,  5.51s/it, training_loss=0.568]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 608/824 [56:55<20:08,  5.60s/it, training_loss=0.568]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 608/824 [57:01<20:08,  5.60s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 609/824 [57:01<20:01,  5.59s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 609/824 [57:06<20:01,  5.59s/it, training_loss=0.185]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 610/824 [57:06<19:43,  5.53s/it, training_loss=0.185]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 610/824 [57:12<19:43,  5.53s/it, training_loss=0.369]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 611/824 [57:12<19:32,  5.50s/it, training_loss=0.369]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 611/824 [57:17<19:32,  5.50s/it, training_loss=0.168]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 612/824 [57:17<19:21,  5.48s/it, training_loss=0.168]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 612/824 [57:22<19:21,  5.48s/it, training_loss=0.210]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 613/824 [57:22<19:13,  5.47s/it, training_loss=0.210]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 613/824 [57:28<19:13,  5.47s/it, training_loss=0.428]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 614/824 [57:28<19:06,  5.46s/it, training_loss=0.428]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 614/824 [57:33<19:06,  5.46s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 615/824 [57:33<18:58,  5.45s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 615/824 [57:39<18:58,  5.45s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 616/824 [57:39<18:52,  5.44s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 616/824 [57:44<18:52,  5.44s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 617/824 [57:44<18:47,  5.45s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  75%|███████▍  | 617/824 [57:50<18:47,  5.45s/it, training_loss=0.170]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 618/824 [57:50<18:41,  5.44s/it, training_loss=0.170]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 618/824 [57:55<18:41,  5.44s/it, training_loss=0.252]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 619/824 [57:55<18:35,  5.44s/it, training_loss=0.252]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 619/824 [58:01<18:35,  5.44s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 620/824 [58:01<18:28,  5.43s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 620/824 [58:06<18:28,  5.43s/it, training_loss=0.108]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 621/824 [58:06<18:22,  5.43s/it, training_loss=0.108]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 621/824 [58:11<18:22,  5.43s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 622/824 [58:11<18:17,  5.43s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 622/824 [58:17<18:17,  5.43s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 623/824 [58:17<18:12,  5.43s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 623/824 [58:22<18:12,  5.43s/it, training_loss=0.408]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 624/824 [58:22<18:06,  5.43s/it, training_loss=0.408]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 624/824 [58:28<18:06,  5.43s/it, training_loss=0.083]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 625/824 [58:28<18:00,  5.43s/it, training_loss=0.083]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 625/824 [58:33<18:00,  5.43s/it, training_loss=0.053]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 626/824 [58:33<17:54,  5.43s/it, training_loss=0.053]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 626/824 [58:39<17:54,  5.43s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 627/824 [58:39<17:49,  5.43s/it, training_loss=0.291]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 627/824 [58:44<17:49,  5.43s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 628/824 [58:44<17:47,  5.44s/it, training_loss=0.310]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 628/824 [58:49<17:47,  5.44s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  76%|███████▋  | 629/824 [58:49<17:40,  5.44s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  76%|███████▋  | 629/824 [58:55<17:40,  5.44s/it, training_loss=0.425]\u001b[A\n",
      "Epoch 1:  76%|███████▋  | 630/824 [58:55<17:32,  5.43s/it, training_loss=0.425]\u001b[A\n",
      "Epoch 1:  76%|███████▋  | 630/824 [59:00<17:32,  5.43s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 631/824 [59:00<17:27,  5.43s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 631/824 [59:06<17:27,  5.43s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 632/824 [59:06<17:20,  5.42s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 632/824 [59:11<17:20,  5.42s/it, training_loss=0.216]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 633/824 [59:11<17:15,  5.42s/it, training_loss=0.216]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 633/824 [59:17<17:15,  5.42s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 634/824 [59:17<17:11,  5.43s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 634/824 [59:22<17:11,  5.43s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 635/824 [59:22<17:05,  5.43s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 635/824 [59:27<17:05,  5.43s/it, training_loss=0.126]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 636/824 [59:27<17:02,  5.44s/it, training_loss=0.126]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 636/824 [59:33<17:02,  5.44s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 637/824 [59:33<17:00,  5.46s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 637/824 [59:38<17:00,  5.46s/it, training_loss=0.054]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 638/824 [59:38<16:54,  5.45s/it, training_loss=0.054]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 638/824 [59:44<16:54,  5.45s/it, training_loss=0.474]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 639/824 [59:44<16:53,  5.48s/it, training_loss=0.474]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 639/824 [59:49<16:53,  5.48s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 640/824 [59:49<16:48,  5.48s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 640/824 [59:55<16:48,  5.48s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 641/824 [59:55<16:43,  5.48s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 641/824 [1:00:00<16:43,  5.48s/it, training_loss=0.841]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 642/824 [1:00:00<16:43,  5.51s/it, training_loss=0.841]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 642/824 [1:00:06<16:43,  5.51s/it, training_loss=0.342]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 643/824 [1:00:06<16:37,  5.51s/it, training_loss=0.342]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 643/824 [1:00:11<16:37,  5.51s/it, training_loss=0.158]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 644/824 [1:00:11<16:31,  5.51s/it, training_loss=0.158]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 644/824 [1:00:17<16:31,  5.51s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 645/824 [1:00:17<16:19,  5.47s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 645/824 [1:00:23<16:19,  5.47s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 646/824 [1:00:23<16:28,  5.55s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 646/824 [1:00:28<16:28,  5.55s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  79%|███████▊  | 647/824 [1:00:28<16:19,  5.53s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  79%|███████▊  | 647/824 [1:00:34<16:19,  5.53s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  79%|███████▊  | 648/824 [1:00:34<16:20,  5.57s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  79%|███████▊  | 648/824 [1:00:39<16:20,  5.57s/it, training_loss=0.199]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 649/824 [1:00:39<16:20,  5.60s/it, training_loss=0.199]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 649/824 [1:00:45<16:20,  5.60s/it, training_loss=0.431]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 650/824 [1:00:45<16:13,  5.60s/it, training_loss=0.431]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 650/824 [1:00:51<16:13,  5.60s/it, training_loss=0.041]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 651/824 [1:00:51<16:37,  5.77s/it, training_loss=0.041]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 651/824 [1:00:57<16:37,  5.77s/it, training_loss=0.045]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 652/824 [1:00:57<16:47,  5.86s/it, training_loss=0.045]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 652/824 [1:01:03<16:47,  5.86s/it, training_loss=0.022]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 653/824 [1:01:03<16:34,  5.82s/it, training_loss=0.022]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 653/824 [1:01:09<16:34,  5.82s/it, training_loss=0.509]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 654/824 [1:01:09<16:35,  5.85s/it, training_loss=0.509]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 654/824 [1:01:15<16:35,  5.85s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 655/824 [1:01:15<16:28,  5.85s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 655/824 [1:01:20<16:28,  5.85s/it, training_loss=0.079]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 656/824 [1:01:20<16:05,  5.75s/it, training_loss=0.079]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 656/824 [1:01:26<16:05,  5.75s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 657/824 [1:01:26<15:55,  5.72s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 657/824 [1:01:31<15:55,  5.72s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 658/824 [1:01:31<15:37,  5.64s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 658/824 [1:01:37<15:37,  5.64s/it, training_loss=0.083]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 659/824 [1:01:37<15:17,  5.56s/it, training_loss=0.083]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 659/824 [1:01:42<15:17,  5.56s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  80%|████████  | 660/824 [1:01:42<15:04,  5.51s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  80%|████████  | 660/824 [1:01:48<15:04,  5.51s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  80%|████████  | 661/824 [1:01:48<14:51,  5.47s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  80%|████████  | 661/824 [1:01:53<14:51,  5.47s/it, training_loss=0.226]\u001b[A\n",
      "Epoch 1:  80%|████████  | 662/824 [1:01:53<14:42,  5.45s/it, training_loss=0.226]\u001b[A\n",
      "Epoch 1:  80%|████████  | 662/824 [1:01:58<14:42,  5.45s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  80%|████████  | 663/824 [1:01:58<14:32,  5.42s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  80%|████████  | 663/824 [1:02:04<14:32,  5.42s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  81%|████████  | 664/824 [1:02:04<14:23,  5.40s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  81%|████████  | 664/824 [1:02:09<14:23,  5.40s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  81%|████████  | 665/824 [1:02:09<14:17,  5.39s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  81%|████████  | 665/824 [1:02:14<14:17,  5.39s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  81%|████████  | 666/824 [1:02:14<14:13,  5.40s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  81%|████████  | 666/824 [1:02:20<14:13,  5.40s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  81%|████████  | 667/824 [1:02:20<14:06,  5.39s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 1:  81%|████████  | 667/824 [1:02:25<14:06,  5.39s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  81%|████████  | 668/824 [1:02:25<13:58,  5.38s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 1:  81%|████████  | 668/824 [1:02:30<13:58,  5.38s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  81%|████████  | 669/824 [1:02:30<13:51,  5.36s/it, training_loss=0.328]\u001b[A\n",
      "Epoch 1:  81%|████████  | 669/824 [1:02:36<13:51,  5.36s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  81%|████████▏ | 670/824 [1:02:36<14:01,  5.47s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  81%|████████▏ | 670/824 [1:02:42<14:01,  5.47s/it, training_loss=0.145]\u001b[A\n",
      "Epoch 1:  81%|████████▏ | 671/824 [1:02:42<14:31,  5.69s/it, training_loss=0.145]\u001b[A\n",
      "Epoch 1:  81%|████████▏ | 671/824 [1:02:49<14:31,  5.69s/it, training_loss=0.435]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 672/824 [1:02:49<14:53,  5.88s/it, training_loss=0.435]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 672/824 [1:02:55<14:53,  5.88s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 673/824 [1:02:55<14:44,  5.86s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 673/824 [1:03:00<14:44,  5.86s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 674/824 [1:03:00<14:25,  5.77s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 674/824 [1:03:06<14:25,  5.77s/it, training_loss=0.120]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 675/824 [1:03:06<14:09,  5.70s/it, training_loss=0.120]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 675/824 [1:03:11<14:09,  5.70s/it, training_loss=0.415]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 676/824 [1:03:11<14:00,  5.68s/it, training_loss=0.415]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 676/824 [1:03:17<14:00,  5.68s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 677/824 [1:03:17<13:53,  5.67s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 677/824 [1:03:22<13:53,  5.67s/it, training_loss=0.532]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 678/824 [1:03:22<13:44,  5.64s/it, training_loss=0.532]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 678/824 [1:03:28<13:44,  5.64s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 679/824 [1:03:28<13:35,  5.62s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 679/824 [1:03:34<13:35,  5.62s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 680/824 [1:03:34<13:23,  5.58s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 680/824 [1:03:39<13:23,  5.58s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 681/824 [1:03:39<13:13,  5.55s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 681/824 [1:03:45<13:13,  5.55s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 682/824 [1:03:45<13:10,  5.57s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 682/824 [1:03:50<13:10,  5.57s/it, training_loss=0.125]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  83%|████████▎ | 683/824 [1:03:50<13:01,  5.54s/it, training_loss=0.125]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 683/824 [1:03:56<13:01,  5.54s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 684/824 [1:03:56<12:55,  5.54s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 684/824 [1:04:01<12:55,  5.54s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 685/824 [1:04:01<12:46,  5.52s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 685/824 [1:04:07<12:46,  5.52s/it, training_loss=0.235]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 686/824 [1:04:07<12:39,  5.50s/it, training_loss=0.235]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 686/824 [1:04:12<12:39,  5.50s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 687/824 [1:04:12<12:34,  5.50s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 687/824 [1:04:18<12:34,  5.50s/it, training_loss=0.083]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 688/824 [1:04:18<12:27,  5.49s/it, training_loss=0.083]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 688/824 [1:04:23<12:27,  5.49s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 1:  84%|████████▎ | 689/824 [1:04:23<12:17,  5.46s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 1:  84%|████████▎ | 689/824 [1:04:28<12:17,  5.46s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  84%|████████▎ | 690/824 [1:04:28<12:07,  5.43s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  84%|████████▎ | 690/824 [1:04:34<12:07,  5.43s/it, training_loss=0.451]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 691/824 [1:04:34<12:07,  5.47s/it, training_loss=0.451]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 691/824 [1:04:39<12:07,  5.47s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 692/824 [1:04:39<12:02,  5.48s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 692/824 [1:04:45<12:02,  5.48s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 693/824 [1:04:45<12:00,  5.50s/it, training_loss=0.250]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 693/824 [1:04:51<12:00,  5.50s/it, training_loss=0.145]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 694/824 [1:04:51<12:21,  5.70s/it, training_loss=0.145]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 694/824 [1:04:57<12:21,  5.70s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 695/824 [1:04:57<12:43,  5.92s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 695/824 [1:05:04<12:43,  5.92s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 696/824 [1:05:04<12:45,  5.98s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 696/824 [1:05:10<12:45,  5.98s/it, training_loss=0.058]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 697/824 [1:05:10<12:40,  5.99s/it, training_loss=0.058]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 697/824 [1:05:15<12:40,  5.99s/it, training_loss=0.186]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 698/824 [1:05:15<12:28,  5.94s/it, training_loss=0.186]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 698/824 [1:05:21<12:28,  5.94s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 699/824 [1:05:21<12:08,  5.82s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 699/824 [1:05:27<12:08,  5.82s/it, training_loss=0.247]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 700/824 [1:05:27<11:51,  5.74s/it, training_loss=0.247]\u001b[A\n",
      "Epoch 1:  85%|████████▍ | 700/824 [1:05:32<11:51,  5.74s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 701/824 [1:05:32<11:40,  5.69s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 701/824 [1:05:38<11:40,  5.69s/it, training_loss=0.222]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 702/824 [1:05:38<11:33,  5.69s/it, training_loss=0.222]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 702/824 [1:05:44<11:33,  5.69s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 703/824 [1:05:44<11:47,  5.84s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 703/824 [1:05:50<11:47,  5.84s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 704/824 [1:05:50<11:35,  5.79s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 704/824 [1:05:55<11:35,  5.79s/it, training_loss=0.197]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 705/824 [1:05:55<11:18,  5.70s/it, training_loss=0.197]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 705/824 [1:06:01<11:18,  5.70s/it, training_loss=0.184]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 706/824 [1:06:01<11:04,  5.63s/it, training_loss=0.184]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 706/824 [1:06:06<11:04,  5.63s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 707/824 [1:06:06<10:49,  5.55s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 707/824 [1:06:11<10:49,  5.55s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 708/824 [1:06:11<10:39,  5.51s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 708/824 [1:06:17<10:39,  5.51s/it, training_loss=0.374]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 709/824 [1:06:17<10:30,  5.48s/it, training_loss=0.374]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 709/824 [1:06:22<10:30,  5.48s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 710/824 [1:06:22<10:21,  5.45s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 710/824 [1:06:28<10:21,  5.45s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 711/824 [1:06:28<10:14,  5.43s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 711/824 [1:06:33<10:14,  5.43s/it, training_loss=0.491]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 712/824 [1:06:33<10:07,  5.43s/it, training_loss=0.491]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 712/824 [1:06:38<10:07,  5.43s/it, training_loss=0.442]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 713/824 [1:06:38<09:59,  5.40s/it, training_loss=0.442]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 713/824 [1:06:44<09:59,  5.40s/it, training_loss=0.538]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 714/824 [1:06:44<09:54,  5.40s/it, training_loss=0.538]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 714/824 [1:06:49<09:54,  5.40s/it, training_loss=0.046]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 715/824 [1:06:49<09:48,  5.40s/it, training_loss=0.046]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 715/824 [1:06:55<09:48,  5.40s/it, training_loss=0.136]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 716/824 [1:06:55<09:43,  5.40s/it, training_loss=0.136]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 716/824 [1:07:00<09:43,  5.40s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 717/824 [1:07:00<09:36,  5.39s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 717/824 [1:07:05<09:36,  5.39s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 718/824 [1:07:05<09:30,  5.38s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 718/824 [1:07:11<09:30,  5.38s/it, training_loss=0.736]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 719/824 [1:07:11<09:24,  5.38s/it, training_loss=0.736]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 719/824 [1:07:16<09:24,  5.38s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 720/824 [1:07:16<09:20,  5.38s/it, training_loss=0.273]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 720/824 [1:07:21<09:20,  5.38s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 721/824 [1:07:21<09:13,  5.38s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 721/824 [1:07:27<09:13,  5.38s/it, training_loss=0.083]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 722/824 [1:07:27<09:09,  5.39s/it, training_loss=0.083]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 722/824 [1:07:32<09:09,  5.39s/it, training_loss=0.747]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 723/824 [1:07:32<09:05,  5.40s/it, training_loss=0.747]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 723/824 [1:07:38<09:05,  5.40s/it, training_loss=0.528]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 724/824 [1:07:38<08:59,  5.39s/it, training_loss=0.528]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 724/824 [1:07:43<08:59,  5.39s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 725/824 [1:07:43<08:54,  5.40s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 725/824 [1:07:48<08:54,  5.40s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 726/824 [1:07:48<08:47,  5.39s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 726/824 [1:07:54<08:47,  5.39s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 727/824 [1:07:54<08:44,  5.40s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 727/824 [1:07:59<08:44,  5.40s/it, training_loss=0.109]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 728/824 [1:07:59<08:39,  5.41s/it, training_loss=0.109]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 728/824 [1:08:05<08:39,  5.41s/it, training_loss=0.111]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 729/824 [1:08:05<08:35,  5.43s/it, training_loss=0.111]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 729/824 [1:08:10<08:35,  5.43s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 730/824 [1:08:10<08:32,  5.45s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 730/824 [1:08:16<08:32,  5.45s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 731/824 [1:08:16<08:25,  5.43s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 731/824 [1:08:21<08:25,  5.43s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 732/824 [1:08:21<08:17,  5.41s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 732/824 [1:08:26<08:17,  5.41s/it, training_loss=0.176]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 733/824 [1:08:26<08:10,  5.39s/it, training_loss=0.176]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 733/824 [1:08:32<08:10,  5.39s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 734/824 [1:08:32<08:03,  5.37s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 734/824 [1:08:37<08:03,  5.37s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 735/824 [1:08:37<08:02,  5.42s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 735/824 [1:08:43<08:02,  5.42s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 736/824 [1:08:43<08:01,  5.47s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 736/824 [1:08:48<08:01,  5.47s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 737/824 [1:08:48<07:58,  5.50s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 737/824 [1:08:54<07:58,  5.50s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 738/824 [1:08:54<08:05,  5.65s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 738/824 [1:09:00<08:05,  5.65s/it, training_loss=0.170]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 739/824 [1:09:00<08:12,  5.80s/it, training_loss=0.170]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 739/824 [1:09:06<08:12,  5.80s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 740/824 [1:09:06<08:11,  5.85s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 740/824 [1:09:13<08:11,  5.85s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 741/824 [1:09:13<08:19,  6.01s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 741/824 [1:09:19<08:19,  6.01s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 742/824 [1:09:19<08:11,  6.00s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 742/824 [1:09:24<08:11,  6.00s/it, training_loss=0.161]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 743/824 [1:09:24<07:56,  5.88s/it, training_loss=0.161]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 743/824 [1:09:30<07:56,  5.88s/it, training_loss=0.060]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 744/824 [1:09:30<07:47,  5.84s/it, training_loss=0.060]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 744/824 [1:09:36<07:47,  5.84s/it, training_loss=0.154]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 745/824 [1:09:36<07:40,  5.83s/it, training_loss=0.154]\u001b[A\n",
      "Epoch 1:  90%|█████████ | 745/824 [1:09:42<07:40,  5.83s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 746/824 [1:09:42<07:30,  5.77s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 746/824 [1:09:47<07:30,  5.77s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 747/824 [1:09:47<07:23,  5.77s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 747/824 [1:09:53<07:23,  5.77s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 748/824 [1:09:53<07:16,  5.74s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 748/824 [1:09:59<07:16,  5.74s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 749/824 [1:09:59<07:11,  5.75s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 749/824 [1:10:05<07:11,  5.75s/it, training_loss=0.184]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 750/824 [1:10:05<07:11,  5.83s/it, training_loss=0.184]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 750/824 [1:10:10<07:11,  5.83s/it, training_loss=0.723]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 751/824 [1:10:10<06:58,  5.73s/it, training_loss=0.723]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 751/824 [1:10:16<06:58,  5.73s/it, training_loss=0.147]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 752/824 [1:10:16<06:52,  5.73s/it, training_loss=0.147]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 752/824 [1:10:22<06:52,  5.73s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 753/824 [1:10:22<06:45,  5.71s/it, training_loss=0.312]\u001b[A\n",
      "Epoch 1:  91%|█████████▏| 753/824 [1:10:28<06:45,  5.71s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 754/824 [1:10:28<06:51,  5.88s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 754/824 [1:10:34<06:51,  5.88s/it, training_loss=0.137]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 755/824 [1:10:34<06:43,  5.84s/it, training_loss=0.137]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 755/824 [1:10:40<06:43,  5.84s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 756/824 [1:10:40<06:38,  5.85s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 756/824 [1:10:46<06:38,  5.85s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 757/824 [1:10:46<06:33,  5.87s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 757/824 [1:10:51<06:33,  5.87s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 758/824 [1:10:51<06:20,  5.77s/it, training_loss=0.257]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 758/824 [1:10:57<06:20,  5.77s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 759/824 [1:10:57<06:11,  5.72s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 759/824 [1:11:03<06:11,  5.72s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 760/824 [1:11:03<06:12,  5.82s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 760/824 [1:11:08<06:12,  5.82s/it, training_loss=0.072]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 761/824 [1:11:08<06:03,  5.76s/it, training_loss=0.072]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 761/824 [1:11:14<06:03,  5.76s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 762/824 [1:11:14<05:58,  5.77s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 762/824 [1:11:20<05:58,  5.77s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 763/824 [1:11:20<05:49,  5.73s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 763/824 [1:11:25<05:49,  5.73s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 764/824 [1:11:25<05:42,  5.70s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 764/824 [1:11:31<05:42,  5.70s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 765/824 [1:11:31<05:42,  5.80s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 765/824 [1:11:37<05:42,  5.80s/it, training_loss=0.037]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 766/824 [1:11:37<05:34,  5.77s/it, training_loss=0.037]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 766/824 [1:11:43<05:34,  5.77s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 767/824 [1:11:43<05:30,  5.80s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 767/824 [1:11:49<05:30,  5.80s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 768/824 [1:11:49<05:24,  5.79s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 768/824 [1:11:55<05:24,  5.79s/it, training_loss=0.043]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 769/824 [1:11:55<05:17,  5.77s/it, training_loss=0.043]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 769/824 [1:12:00<05:17,  5.77s/it, training_loss=0.154]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 770/824 [1:12:00<05:08,  5.72s/it, training_loss=0.154]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 770/824 [1:12:06<05:08,  5.72s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 771/824 [1:12:06<05:04,  5.75s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 771/824 [1:12:12<05:04,  5.75s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 772/824 [1:12:12<04:59,  5.76s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  94%|█████████▎| 772/824 [1:12:18<04:59,  5.76s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 773/824 [1:12:18<04:54,  5.77s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 773/824 [1:12:23<04:54,  5.77s/it, training_loss=0.708]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 774/824 [1:12:23<04:44,  5.69s/it, training_loss=0.708]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 774/824 [1:12:28<04:44,  5.69s/it, training_loss=0.175]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 775/824 [1:12:28<04:34,  5.60s/it, training_loss=0.175]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 775/824 [1:12:34<04:34,  5.60s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 776/824 [1:12:34<04:29,  5.61s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 776/824 [1:12:40<04:29,  5.61s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 777/824 [1:12:40<04:26,  5.67s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 777/824 [1:12:46<04:26,  5.67s/it, training_loss=0.187]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 778/824 [1:12:46<04:21,  5.68s/it, training_loss=0.187]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 778/824 [1:12:51<04:21,  5.68s/it, training_loss=0.004]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  95%|█████████▍| 779/824 [1:12:51<04:13,  5.63s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 779/824 [1:12:57<04:13,  5.63s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 780/824 [1:12:57<04:09,  5.67s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 780/824 [1:13:02<04:09,  5.67s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 781/824 [1:13:02<04:02,  5.64s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 781/824 [1:13:08<04:02,  5.64s/it, training_loss=0.379]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 782/824 [1:13:08<03:55,  5.62s/it, training_loss=0.379]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 782/824 [1:13:13<03:55,  5.62s/it, training_loss=0.082]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 783/824 [1:13:13<03:47,  5.55s/it, training_loss=0.082]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 783/824 [1:13:19<03:47,  5.55s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 784/824 [1:13:19<03:40,  5.50s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 784/824 [1:13:24<03:40,  5.50s/it, training_loss=0.638]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 785/824 [1:13:24<03:33,  5.46s/it, training_loss=0.638]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 785/824 [1:13:30<03:33,  5.46s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 786/824 [1:13:30<03:26,  5.44s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 786/824 [1:13:35<03:26,  5.44s/it, training_loss=0.154]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 787/824 [1:13:35<03:20,  5.43s/it, training_loss=0.154]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 787/824 [1:13:40<03:20,  5.43s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 788/824 [1:13:40<03:14,  5.41s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 788/824 [1:13:46<03:14,  5.41s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 789/824 [1:13:46<03:09,  5.42s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 789/824 [1:13:51<03:09,  5.42s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 790/824 [1:13:51<03:05,  5.46s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 790/824 [1:13:57<03:05,  5.46s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 791/824 [1:13:57<03:04,  5.59s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 791/824 [1:14:03<03:04,  5.59s/it, training_loss=0.225]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 792/824 [1:14:03<03:01,  5.67s/it, training_loss=0.225]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 792/824 [1:14:09<03:01,  5.67s/it, training_loss=0.171]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 793/824 [1:14:09<02:54,  5.64s/it, training_loss=0.171]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 793/824 [1:14:14<02:54,  5.64s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 794/824 [1:14:14<02:49,  5.66s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 794/824 [1:14:20<02:49,  5.66s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 795/824 [1:14:20<02:43,  5.65s/it, training_loss=0.303]\u001b[A\n",
      "Epoch 1:  96%|█████████▋| 795/824 [1:14:25<02:43,  5.65s/it, training_loss=0.192]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 796/824 [1:14:25<02:36,  5.60s/it, training_loss=0.192]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 796/824 [1:14:31<02:36,  5.60s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 797/824 [1:14:31<02:30,  5.57s/it, training_loss=0.253]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 797/824 [1:14:37<02:30,  5.57s/it, training_loss=0.157]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 798/824 [1:14:37<02:25,  5.60s/it, training_loss=0.157]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 798/824 [1:14:42<02:25,  5.60s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 799/824 [1:14:42<02:19,  5.57s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 799/824 [1:14:48<02:19,  5.57s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 800/824 [1:14:48<02:13,  5.57s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 800/824 [1:14:53<02:13,  5.57s/it, training_loss=0.032]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 801/824 [1:14:53<02:08,  5.57s/it, training_loss=0.032]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 801/824 [1:14:59<02:08,  5.57s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 802/824 [1:14:59<02:05,  5.70s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 802/824 [1:15:05<02:05,  5.70s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 803/824 [1:15:05<01:59,  5.71s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 803/824 [1:15:11<01:59,  5.71s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 804/824 [1:15:11<01:56,  5.82s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 804/824 [1:15:17<01:56,  5.82s/it, training_loss=0.427]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 805/824 [1:15:17<01:50,  5.81s/it, training_loss=0.427]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 805/824 [1:15:23<01:50,  5.81s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 806/824 [1:15:23<01:44,  5.83s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 806/824 [1:15:28<01:44,  5.83s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 807/824 [1:15:28<01:38,  5.82s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 807/824 [1:15:34<01:38,  5.82s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 808/824 [1:15:34<01:32,  5.78s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 808/824 [1:15:40<01:32,  5.78s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 809/824 [1:15:40<01:27,  5.85s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 809/824 [1:15:46<01:27,  5.85s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 810/824 [1:15:46<01:22,  5.90s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 810/824 [1:15:52<01:22,  5.90s/it, training_loss=0.644]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 811/824 [1:15:52<01:16,  5.89s/it, training_loss=0.644]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 811/824 [1:15:58<01:16,  5.89s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 812/824 [1:15:58<01:10,  5.84s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 812/824 [1:16:03<01:10,  5.84s/it, training_loss=0.504]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 813/824 [1:16:03<01:03,  5.77s/it, training_loss=0.504]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 813/824 [1:16:09<01:03,  5.77s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 814/824 [1:16:09<00:56,  5.67s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 814/824 [1:16:14<00:56,  5.67s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 815/824 [1:16:14<00:50,  5.60s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 815/824 [1:16:20<00:50,  5.60s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 816/824 [1:16:20<00:44,  5.55s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 816/824 [1:16:25<00:44,  5.55s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 817/824 [1:16:25<00:38,  5.54s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 817/824 [1:16:31<00:38,  5.54s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 818/824 [1:16:31<00:33,  5.52s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 818/824 [1:16:36<00:33,  5.52s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 819/824 [1:16:36<00:27,  5.50s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 819/824 [1:16:42<00:27,  5.50s/it, training_loss=0.149]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 820/824 [1:16:42<00:22,  5.56s/it, training_loss=0.149]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 820/824 [1:16:48<00:22,  5.56s/it, training_loss=0.053]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 821/824 [1:16:48<00:17,  5.72s/it, training_loss=0.053]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 821/824 [1:16:54<00:17,  5.72s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 822/824 [1:16:54<00:11,  5.77s/it, training_loss=0.048]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 822/824 [1:17:00<00:11,  5.77s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 823/824 [1:17:00<00:05,  5.79s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 1: 100%|█████████▉| 823/824 [1:17:04<00:05,  5.79s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 1: 100%|██████████| 824/824 [1:17:04<00:00,  5.48s/it, training_loss=0.006]\u001b[A\n",
      "  0%|          | 0/3 [1:17:07<?, ?it/s]                                          \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 0.4667830017024597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [1:20:57<2:41:54, 4857.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.436770397838052\n",
      "F1 Score (Weighted): 0.8630187235067245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2:   0%|          | 0/824 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:   0%|          | 0/824 [00:05<?, ?it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   0%|          | 1/824 [00:05<1:10:15,  5.12s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   0%|          | 1/824 [00:10<1:10:15,  5.12s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   0%|          | 2/824 [00:10<1:10:04,  5.11s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   0%|          | 2/824 [00:15<1:10:04,  5.11s/it, training_loss=0.165]\u001b[A\n",
      "Epoch 2:   0%|          | 3/824 [00:15<1:10:00,  5.12s/it, training_loss=0.165]\u001b[A\n",
      "Epoch 2:   0%|          | 3/824 [00:20<1:10:00,  5.12s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:   0%|          | 4/824 [00:20<1:09:50,  5.11s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:   0%|          | 4/824 [00:25<1:09:50,  5.11s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:   1%|          | 5/824 [00:25<1:09:39,  5.10s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:   1%|          | 5/824 [00:30<1:09:39,  5.10s/it, training_loss=0.060]\u001b[A\n",
      "Epoch 2:   1%|          | 6/824 [00:30<1:09:51,  5.12s/it, training_loss=0.060]\u001b[A\n",
      "Epoch 2:   1%|          | 6/824 [00:35<1:09:51,  5.12s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 2:   1%|          | 7/824 [00:35<1:09:38,  5.12s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 2:   1%|          | 7/824 [00:40<1:09:38,  5.12s/it, training_loss=0.200]\u001b[A\n",
      "Epoch 2:   1%|          | 8/824 [00:40<1:09:27,  5.11s/it, training_loss=0.200]\u001b[A\n",
      "Epoch 2:   1%|          | 8/824 [00:46<1:09:27,  5.11s/it, training_loss=0.083]\u001b[A\n",
      "Epoch 2:   1%|          | 9/824 [00:46<1:09:25,  5.11s/it, training_loss=0.083]\u001b[A\n",
      "Epoch 2:   1%|          | 9/824 [00:51<1:09:25,  5.11s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:   1%|          | 10/824 [00:51<1:09:16,  5.11s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:   1%|          | 10/824 [00:56<1:09:16,  5.11s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   1%|▏         | 11/824 [00:56<1:09:14,  5.11s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   1%|▏         | 11/824 [01:01<1:09:14,  5.11s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:   1%|▏         | 12/824 [01:01<1:09:07,  5.11s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:   1%|▏         | 12/824 [01:06<1:09:07,  5.11s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 2:   2%|▏         | 13/824 [01:06<1:08:59,  5.10s/it, training_loss=0.288]\u001b[A\n",
      "Epoch 2:   2%|▏         | 13/824 [01:11<1:08:59,  5.10s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 2:   2%|▏         | 14/824 [01:11<1:08:46,  5.09s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 2:   2%|▏         | 14/824 [01:16<1:08:46,  5.09s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:   2%|▏         | 15/824 [01:16<1:08:47,  5.10s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:   2%|▏         | 15/824 [01:21<1:08:47,  5.10s/it, training_loss=0.355]\u001b[A\n",
      "Epoch 2:   2%|▏         | 16/824 [01:21<1:08:35,  5.09s/it, training_loss=0.355]\u001b[A\n",
      "Epoch 2:   2%|▏         | 16/824 [01:26<1:08:35,  5.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   2%|▏         | 17/824 [01:26<1:08:37,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   2%|▏         | 17/824 [01:31<1:08:37,  5.10s/it, training_loss=0.165]\u001b[A\n",
      "Epoch 2:   2%|▏         | 18/824 [01:31<1:08:23,  5.09s/it, training_loss=0.165]\u001b[A\n",
      "Epoch 2:   2%|▏         | 18/824 [01:36<1:08:23,  5.09s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:   2%|▏         | 19/824 [01:36<1:08:17,  5.09s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:   2%|▏         | 19/824 [01:42<1:08:17,  5.09s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   2%|▏         | 20/824 [01:42<1:08:10,  5.09s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   2%|▏         | 20/824 [01:47<1:08:10,  5.09s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   3%|▎         | 21/824 [01:47<1:08:12,  5.10s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   3%|▎         | 21/824 [01:52<1:08:12,  5.10s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 2:   3%|▎         | 22/824 [01:52<1:08:03,  5.09s/it, training_loss=0.241]\u001b[A\n",
      "Epoch 2:   3%|▎         | 22/824 [01:57<1:08:03,  5.09s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 2:   3%|▎         | 23/824 [01:57<1:07:58,  5.09s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 2:   3%|▎         | 23/824 [02:02<1:07:58,  5.09s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 2:   3%|▎         | 24/824 [02:02<1:07:50,  5.09s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 2:   3%|▎         | 24/824 [02:07<1:07:50,  5.09s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 2:   3%|▎         | 25/824 [02:07<1:07:51,  5.10s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 2:   3%|▎         | 25/824 [02:12<1:07:51,  5.10s/it, training_loss=0.111]\u001b[A\n",
      "Epoch 2:   3%|▎         | 26/824 [02:12<1:07:42,  5.09s/it, training_loss=0.111]\u001b[A\n",
      "Epoch 2:   3%|▎         | 26/824 [02:17<1:07:42,  5.09s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   3%|▎         | 27/824 [02:17<1:07:39,  5.09s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   3%|▎         | 27/824 [02:22<1:07:39,  5.09s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:   3%|▎         | 28/824 [02:22<1:07:30,  5.09s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:   3%|▎         | 28/824 [02:27<1:07:30,  5.09s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:   4%|▎         | 29/824 [02:27<1:07:29,  5.09s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:   4%|▎         | 29/824 [02:33<1:07:29,  5.09s/it, training_loss=0.191]\u001b[A\n",
      "Epoch 2:   4%|▎         | 30/824 [02:33<1:07:28,  5.10s/it, training_loss=0.191]\u001b[A\n",
      "Epoch 2:   4%|▎         | 30/824 [02:38<1:07:28,  5.10s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 2:   4%|▍         | 31/824 [02:38<1:07:18,  5.09s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 2:   4%|▍         | 31/824 [02:43<1:07:18,  5.09s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   4%|▍         | 32/824 [02:43<1:07:10,  5.09s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   4%|▍         | 32/824 [02:48<1:07:10,  5.09s/it, training_loss=0.155]\u001b[A\n",
      "Epoch 2:   4%|▍         | 33/824 [02:48<1:07:18,  5.11s/it, training_loss=0.155]\u001b[A\n",
      "Epoch 2:   4%|▍         | 33/824 [02:53<1:07:18,  5.11s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   4%|▍         | 34/824 [02:53<1:07:07,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   4%|▍         | 34/824 [02:58<1:07:07,  5.10s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 2:   4%|▍         | 35/824 [02:58<1:07:02,  5.10s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 2:   4%|▍         | 35/824 [03:03<1:07:02,  5.10s/it, training_loss=0.247]\u001b[A\n",
      "Epoch 2:   4%|▍         | 36/824 [03:03<1:06:55,  5.10s/it, training_loss=0.247]\u001b[A\n",
      "Epoch 2:   4%|▍         | 36/824 [03:08<1:06:55,  5.10s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 2:   4%|▍         | 37/824 [03:08<1:06:51,  5.10s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 2:   4%|▍         | 37/824 [03:13<1:06:51,  5.10s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:   5%|▍         | 38/824 [03:13<1:06:46,  5.10s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:   5%|▍         | 38/824 [03:18<1:06:46,  5.10s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   5%|▍         | 39/824 [03:18<1:06:45,  5.10s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   5%|▍         | 39/824 [03:23<1:06:45,  5.10s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 2:   5%|▍         | 40/824 [03:23<1:06:36,  5.10s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 2:   5%|▍         | 40/824 [03:29<1:06:36,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   5%|▍         | 41/824 [03:29<1:06:30,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   5%|▍         | 41/824 [03:34<1:06:30,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   5%|▌         | 42/824 [03:34<1:06:21,  5.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   5%|▌         | 42/824 [03:39<1:06:21,  5.09s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:   5%|▌         | 43/824 [03:39<1:06:15,  5.09s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:   5%|▌         | 43/824 [03:44<1:06:15,  5.09s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   5%|▌         | 44/824 [03:44<1:06:15,  5.10s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   5%|▌         | 44/824 [03:49<1:06:15,  5.10s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:   5%|▌         | 45/824 [03:49<1:06:43,  5.14s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:   5%|▌         | 45/824 [03:55<1:06:43,  5.14s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   6%|▌         | 46/824 [03:55<1:07:48,  5.23s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   6%|▌         | 46/824 [04:00<1:07:48,  5.23s/it, training_loss=0.041]\u001b[A\n",
      "Epoch 2:   6%|▌         | 47/824 [04:00<1:07:27,  5.21s/it, training_loss=0.041]\u001b[A\n",
      "Epoch 2:   6%|▌         | 47/824 [04:05<1:07:27,  5.21s/it, training_loss=0.043]\u001b[A\n",
      "Epoch 2:   6%|▌         | 48/824 [04:05<1:06:52,  5.17s/it, training_loss=0.043]\u001b[A\n",
      "Epoch 2:   6%|▌         | 48/824 [04:10<1:06:52,  5.17s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   6%|▌         | 49/824 [04:10<1:06:25,  5.14s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   6%|▌         | 49/824 [04:15<1:06:25,  5.14s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   6%|▌         | 50/824 [04:15<1:06:23,  5.15s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   6%|▌         | 50/824 [04:20<1:06:23,  5.15s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:   6%|▌         | 51/824 [04:20<1:06:06,  5.13s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:   6%|▌         | 51/824 [04:25<1:06:06,  5.13s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:   6%|▋         | 52/824 [04:25<1:05:46,  5.11s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:   6%|▋         | 52/824 [04:30<1:05:46,  5.11s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 2:   6%|▋         | 53/824 [04:30<1:05:44,  5.12s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 2:   6%|▋         | 53/824 [04:35<1:05:44,  5.12s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   7%|▋         | 54/824 [04:35<1:05:29,  5.10s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:   7%|▋         | 54/824 [04:40<1:05:29,  5.10s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:   7%|▋         | 55/824 [04:40<1:05:18,  5.10s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:   7%|▋         | 55/824 [04:46<1:05:18,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   7%|▋         | 56/824 [04:46<1:05:21,  5.11s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   7%|▋         | 56/824 [04:51<1:05:21,  5.11s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 2:   7%|▋         | 57/824 [04:51<1:05:14,  5.10s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 2:   7%|▋         | 57/824 [04:56<1:05:14,  5.10s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 2:   7%|▋         | 58/824 [04:56<1:05:00,  5.09s/it, training_loss=0.295]\u001b[A\n",
      "Epoch 2:   7%|▋         | 58/824 [05:01<1:05:00,  5.09s/it, training_loss=0.087]\u001b[A\n",
      "Epoch 2:   7%|▋         | 59/824 [05:01<1:04:54,  5.09s/it, training_loss=0.087]\u001b[A\n",
      "Epoch 2:   7%|▋         | 59/824 [05:06<1:04:54,  5.09s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:   7%|▋         | 60/824 [05:06<1:04:45,  5.09s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:   7%|▋         | 60/824 [05:11<1:04:45,  5.09s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:   7%|▋         | 61/824 [05:11<1:04:37,  5.08s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:   7%|▋         | 61/824 [05:16<1:04:37,  5.08s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:   8%|▊         | 62/824 [05:16<1:04:39,  5.09s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:   8%|▊         | 62/824 [05:21<1:04:39,  5.09s/it, training_loss=0.069]\u001b[A\n",
      "Epoch 2:   8%|▊         | 63/824 [05:21<1:04:29,  5.08s/it, training_loss=0.069]\u001b[A\n",
      "Epoch 2:   8%|▊         | 63/824 [05:26<1:04:29,  5.08s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 2:   8%|▊         | 64/824 [05:26<1:04:19,  5.08s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 2:   8%|▊         | 64/824 [05:31<1:04:19,  5.08s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:   8%|▊         | 65/824 [05:31<1:04:14,  5.08s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:   8%|▊         | 65/824 [05:36<1:04:14,  5.08s/it, training_loss=0.370]\u001b[A\n",
      "Epoch 2:   8%|▊         | 66/824 [05:36<1:04:21,  5.09s/it, training_loss=0.370]\u001b[A\n",
      "Epoch 2:   8%|▊         | 66/824 [05:42<1:04:21,  5.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   8%|▊         | 67/824 [05:42<1:04:18,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   8%|▊         | 67/824 [05:47<1:04:18,  5.10s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 2:   8%|▊         | 68/824 [05:47<1:04:42,  5.13s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 2:   8%|▊         | 68/824 [05:52<1:04:42,  5.13s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 2:   8%|▊         | 69/824 [05:52<1:04:32,  5.13s/it, training_loss=0.282]\u001b[A\n",
      "Epoch 2:   8%|▊         | 69/824 [05:57<1:04:32,  5.13s/it, training_loss=0.356]\u001b[A\n",
      "Epoch 2:   8%|▊         | 70/824 [05:57<1:04:20,  5.12s/it, training_loss=0.356]\u001b[A\n",
      "Epoch 2:   8%|▊         | 70/824 [06:02<1:04:20,  5.12s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   9%|▊         | 71/824 [06:02<1:04:07,  5.11s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   9%|▊         | 71/824 [06:07<1:04:07,  5.11s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   9%|▊         | 72/824 [06:07<1:03:55,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   9%|▊         | 72/824 [06:12<1:03:55,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   9%|▉         | 73/824 [06:12<1:03:42,  5.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:   9%|▉         | 73/824 [06:17<1:03:42,  5.09s/it, training_loss=0.045]\u001b[A\n",
      "Epoch 2:   9%|▉         | 74/824 [06:17<1:03:42,  5.10s/it, training_loss=0.045]\u001b[A\n",
      "Epoch 2:   9%|▉         | 74/824 [06:22<1:03:42,  5.10s/it, training_loss=0.053]\u001b[A\n",
      "Epoch 2:   9%|▉         | 75/824 [06:22<1:03:34,  5.09s/it, training_loss=0.053]\u001b[A\n",
      "Epoch 2:   9%|▉         | 75/824 [06:27<1:03:34,  5.09s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:   9%|▉         | 76/824 [06:27<1:03:31,  5.10s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:   9%|▉         | 76/824 [06:33<1:03:31,  5.10s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 2:   9%|▉         | 77/824 [06:33<1:03:26,  5.10s/it, training_loss=0.319]\u001b[A\n",
      "Epoch 2:   9%|▉         | 77/824 [06:38<1:03:26,  5.10s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 2:   9%|▉         | 78/824 [06:38<1:03:16,  5.09s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 2:   9%|▉         | 78/824 [06:43<1:03:16,  5.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  10%|▉         | 79/824 [06:43<1:03:06,  5.08s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  10%|▉         | 79/824 [06:48<1:03:06,  5.08s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  10%|▉         | 80/824 [06:48<1:03:11,  5.10s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  10%|▉         | 80/824 [06:53<1:03:11,  5.10s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  10%|▉         | 81/824 [06:53<1:03:00,  5.09s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  10%|▉         | 81/824 [06:58<1:03:00,  5.09s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 2:  10%|▉         | 82/824 [06:58<1:02:58,  5.09s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 2:  10%|▉         | 82/824 [07:03<1:02:58,  5.09s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  10%|█         | 83/824 [07:03<1:02:49,  5.09s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  10%|█         | 83/824 [07:08<1:02:49,  5.09s/it, training_loss=0.497]\u001b[A\n",
      "Epoch 2:  10%|█         | 84/824 [07:08<1:02:45,  5.09s/it, training_loss=0.497]\u001b[A\n",
      "Epoch 2:  10%|█         | 84/824 [07:13<1:02:45,  5.09s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  10%|█         | 85/824 [07:13<1:02:38,  5.09s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  10%|█         | 85/824 [07:18<1:02:38,  5.09s/it, training_loss=0.144]\u001b[A\n",
      "Epoch 2:  10%|█         | 86/824 [07:18<1:02:38,  5.09s/it, training_loss=0.144]\u001b[A\n",
      "Epoch 2:  10%|█         | 86/824 [07:23<1:02:38,  5.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  11%|█         | 87/824 [07:23<1:02:28,  5.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  11%|█         | 87/824 [07:29<1:02:28,  5.09s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  11%|█         | 88/824 [07:29<1:02:26,  5.09s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  11%|█         | 88/824 [07:34<1:02:26,  5.09s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 2:  11%|█         | 89/824 [07:34<1:02:16,  5.08s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 2:  11%|█         | 89/824 [07:39<1:02:16,  5.08s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  11%|█         | 90/824 [07:39<1:02:12,  5.08s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  11%|█         | 90/824 [07:44<1:02:12,  5.08s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  11%|█         | 91/824 [07:44<1:02:04,  5.08s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  11%|█         | 91/824 [07:49<1:02:04,  5.08s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  11%|█         | 92/824 [07:49<1:02:17,  5.11s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  11%|█         | 92/824 [07:54<1:02:17,  5.11s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  11%|█▏        | 93/824 [07:54<1:02:07,  5.10s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  11%|█▏        | 93/824 [07:59<1:02:07,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  11%|█▏        | 94/824 [07:59<1:01:57,  5.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  11%|█▏        | 94/824 [08:04<1:01:57,  5.09s/it, training_loss=0.468]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 95/824 [08:04<1:01:50,  5.09s/it, training_loss=0.468]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 95/824 [08:09<1:01:50,  5.09s/it, training_loss=0.123]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 96/824 [08:09<1:01:44,  5.09s/it, training_loss=0.123]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 96/824 [08:14<1:01:44,  5.09s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 97/824 [08:14<1:01:42,  5.09s/it, training_loss=0.004]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  12%|█▏        | 97/824 [08:19<1:01:42,  5.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 98/824 [08:19<1:01:35,  5.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 98/824 [08:25<1:01:35,  5.09s/it, training_loss=0.177]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 99/824 [08:25<1:01:27,  5.09s/it, training_loss=0.177]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 99/824 [08:30<1:01:27,  5.09s/it, training_loss=0.401]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 100/824 [08:30<1:01:34,  5.10s/it, training_loss=0.401]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 100/824 [08:35<1:01:34,  5.10s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 101/824 [08:35<1:01:24,  5.10s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 101/824 [08:40<1:01:24,  5.10s/it, training_loss=0.082]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 102/824 [08:40<1:01:15,  5.09s/it, training_loss=0.082]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 102/824 [08:45<1:01:15,  5.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  12%|█▎        | 103/824 [08:45<1:01:12,  5.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  12%|█▎        | 103/824 [08:50<1:01:12,  5.09s/it, training_loss=0.381]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 104/824 [08:50<1:01:06,  5.09s/it, training_loss=0.381]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 104/824 [08:55<1:01:06,  5.09s/it, training_loss=0.141]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 105/824 [08:55<1:00:57,  5.09s/it, training_loss=0.141]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 105/824 [09:00<1:00:57,  5.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 106/824 [09:00<1:00:49,  5.08s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 106/824 [09:05<1:00:49,  5.08s/it, training_loss=0.367]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 107/824 [09:05<1:00:44,  5.08s/it, training_loss=0.367]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 107/824 [09:10<1:00:44,  5.08s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 108/824 [09:10<1:00:40,  5.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 108/824 [09:15<1:00:40,  5.09s/it, training_loss=0.579]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 109/824 [09:15<1:00:40,  5.09s/it, training_loss=0.579]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 109/824 [09:21<1:00:40,  5.09s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 110/824 [09:21<1:00:33,  5.09s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 110/824 [09:26<1:00:33,  5.09s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 111/824 [09:26<1:00:27,  5.09s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 111/824 [09:31<1:00:27,  5.09s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  14%|█▎        | 112/824 [09:31<1:00:18,  5.08s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  14%|█▎        | 112/824 [09:36<1:00:18,  5.08s/it, training_loss=0.051]\u001b[A\n",
      "Epoch 2:  14%|█▎        | 113/824 [09:36<1:00:12,  5.08s/it, training_loss=0.051]\u001b[A\n",
      "Epoch 2:  14%|█▎        | 113/824 [09:41<1:00:12,  5.08s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 114/824 [09:41<1:00:09,  5.08s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 114/824 [09:46<1:00:09,  5.08s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 115/824 [09:46<1:00:10,  5.09s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 115/824 [09:51<1:00:10,  5.09s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 116/824 [09:51<1:00:06,  5.09s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 116/824 [09:56<1:00:06,  5.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 117/824 [09:56<1:00:01,  5.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 117/824 [10:01<1:00:01,  5.09s/it, training_loss=0.180]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 118/824 [10:01<59:51,  5.09s/it, training_loss=0.180]  \u001b[A\n",
      "Epoch 2:  14%|█▍        | 118/824 [10:06<59:51,  5.09s/it, training_loss=0.145]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 119/824 [10:06<59:47,  5.09s/it, training_loss=0.145]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 119/824 [10:11<59:47,  5.09s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 120/824 [10:11<59:43,  5.09s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 120/824 [10:17<59:43,  5.09s/it, training_loss=0.192]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 121/824 [10:17<59:45,  5.10s/it, training_loss=0.192]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 121/824 [10:22<59:45,  5.10s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 122/824 [10:22<59:35,  5.09s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 122/824 [10:27<59:35,  5.09s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 123/824 [10:27<59:30,  5.09s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 123/824 [10:32<59:30,  5.09s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 124/824 [10:32<59:33,  5.11s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 124/824 [10:37<59:33,  5.11s/it, training_loss=0.117]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 125/824 [10:37<59:23,  5.10s/it, training_loss=0.117]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 125/824 [10:42<59:23,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 126/824 [10:42<59:15,  5.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 126/824 [10:47<59:15,  5.09s/it, training_loss=0.370]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 127/824 [10:47<59:15,  5.10s/it, training_loss=0.370]\u001b[A\n",
      "Epoch 2:  15%|█▌        | 127/824 [10:52<59:15,  5.10s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 128/824 [10:52<59:12,  5.10s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 128/824 [10:57<59:12,  5.10s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 129/824 [10:57<59:08,  5.11s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 129/824 [11:02<59:08,  5.11s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 130/824 [11:02<59:00,  5.10s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 130/824 [11:08<59:00,  5.10s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 131/824 [11:08<58:54,  5.10s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 131/824 [11:13<58:54,  5.10s/it, training_loss=0.369]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 132/824 [11:13<58:47,  5.10s/it, training_loss=0.369]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 132/824 [11:18<58:47,  5.10s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 133/824 [11:18<58:47,  5.10s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 133/824 [11:23<58:47,  5.10s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 2:  16%|█▋        | 134/824 [11:23<58:39,  5.10s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 2:  16%|█▋        | 134/824 [11:28<58:39,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  16%|█▋        | 135/824 [11:28<58:30,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  16%|█▋        | 135/824 [11:33<58:30,  5.10s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 136/824 [11:33<58:30,  5.10s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 136/824 [11:38<58:30,  5.10s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 137/824 [11:38<58:20,  5.10s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 137/824 [11:43<58:20,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 138/824 [11:43<58:17,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 138/824 [11:48<58:17,  5.10s/it, training_loss=0.189]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 139/824 [11:48<58:20,  5.11s/it, training_loss=0.189]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 139/824 [11:53<58:20,  5.11s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 140/824 [11:53<58:15,  5.11s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 140/824 [11:59<58:15,  5.11s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 141/824 [11:59<58:03,  5.10s/it, training_loss=0.281]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 141/824 [12:04<58:03,  5.10s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 142/824 [12:04<57:55,  5.10s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 142/824 [12:09<57:55,  5.10s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 143/824 [12:09<57:45,  5.09s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 143/824 [12:14<57:45,  5.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 144/824 [12:14<57:42,  5.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 144/824 [12:19<57:42,  5.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 145/824 [12:19<57:44,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 145/824 [12:24<57:44,  5.10s/it, training_loss=0.497]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 146/824 [12:24<57:37,  5.10s/it, training_loss=0.497]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 146/824 [12:29<57:37,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 147/824 [12:29<57:31,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 147/824 [12:34<57:31,  5.10s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 148/824 [12:34<57:25,  5.10s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 148/824 [12:39<57:25,  5.10s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 149/824 [12:39<57:19,  5.10s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 149/824 [12:44<57:19,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 150/824 [12:44<57:13,  5.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 150/824 [12:50<57:13,  5.09s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 151/824 [12:50<57:11,  5.10s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 151/824 [12:55<57:11,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 152/824 [12:55<57:03,  5.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 152/824 [13:00<57:03,  5.09s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 2:  19%|█▊        | 153/824 [13:00<56:57,  5.09s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 2:  19%|█▊        | 153/824 [13:05<56:57,  5.09s/it, training_loss=0.479]\u001b[A\n",
      "Epoch 2:  19%|█▊        | 154/824 [13:05<56:53,  5.09s/it, training_loss=0.479]\u001b[A\n",
      "Epoch 2:  19%|█▊        | 154/824 [13:10<56:53,  5.09s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 155/824 [13:10<56:51,  5.10s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 155/824 [13:15<56:51,  5.10s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 156/824 [13:15<56:52,  5.11s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 156/824 [13:20<56:52,  5.11s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 157/824 [13:20<56:43,  5.10s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 157/824 [13:25<56:43,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 158/824 [13:25<56:37,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 158/824 [13:30<56:37,  5.10s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 159/824 [13:30<56:31,  5.10s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 159/824 [13:35<56:31,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 160/824 [13:35<56:23,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 160/824 [13:40<56:23,  5.10s/it, training_loss=0.045]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 161/824 [13:40<56:15,  5.09s/it, training_loss=0.045]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 161/824 [13:46<56:15,  5.09s/it, training_loss=0.207]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 162/824 [13:46<56:17,  5.10s/it, training_loss=0.207]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 162/824 [13:51<56:17,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 163/824 [13:51<56:13,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 163/824 [13:56<56:13,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 164/824 [13:56<56:03,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 164/824 [14:01<56:03,  5.10s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  20%|██        | 165/824 [14:01<56:01,  5.10s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  20%|██        | 165/824 [14:06<56:01,  5.10s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 2:  20%|██        | 166/824 [14:06<55:57,  5.10s/it, training_loss=0.237]\u001b[A\n",
      "Epoch 2:  20%|██        | 166/824 [14:11<55:57,  5.10s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 2:  20%|██        | 167/824 [14:11<55:55,  5.11s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 2:  20%|██        | 167/824 [14:16<55:55,  5.11s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 2:  20%|██        | 168/824 [14:16<55:53,  5.11s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 2:  20%|██        | 168/824 [14:21<55:53,  5.11s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  21%|██        | 169/824 [14:21<55:46,  5.11s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  21%|██        | 169/824 [14:26<55:46,  5.11s/it, training_loss=0.369]\u001b[A\n",
      "Epoch 2:  21%|██        | 170/824 [14:26<55:40,  5.11s/it, training_loss=0.369]\u001b[A\n",
      "Epoch 2:  21%|██        | 170/824 [14:32<55:40,  5.11s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  21%|██        | 171/824 [14:32<55:38,  5.11s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  21%|██        | 171/824 [14:37<55:38,  5.11s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 2:  21%|██        | 172/824 [14:37<55:28,  5.11s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 2:  21%|██        | 172/824 [14:42<55:28,  5.11s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  21%|██        | 173/824 [14:42<55:19,  5.10s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  21%|██        | 173/824 [14:47<55:19,  5.10s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 2:  21%|██        | 174/824 [14:47<55:17,  5.10s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 2:  21%|██        | 174/824 [14:52<55:17,  5.10s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 2:  21%|██        | 175/824 [14:52<55:12,  5.10s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 2:  21%|██        | 175/824 [14:57<55:12,  5.10s/it, training_loss=0.029]\u001b[A\n",
      "Epoch 2:  21%|██▏       | 176/824 [14:57<55:06,  5.10s/it, training_loss=0.029]\u001b[A\n",
      "Epoch 2:  21%|██▏       | 176/824 [15:02<55:06,  5.10s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 2:  21%|██▏       | 177/824 [15:02<55:03,  5.11s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 2:  21%|██▏       | 177/824 [15:07<55:03,  5.11s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 178/824 [15:07<54:56,  5.10s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 178/824 [15:12<54:56,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 179/824 [15:12<54:51,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 179/824 [15:18<54:51,  5.10s/it, training_loss=0.032]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 180/824 [15:18<55:39,  5.19s/it, training_loss=0.032]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 180/824 [15:23<55:39,  5.19s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 181/824 [15:23<56:14,  5.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 181/824 [15:28<56:14,  5.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 182/824 [15:28<56:14,  5.26s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 182/824 [15:34<56:14,  5.26s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 183/824 [15:34<55:45,  5.22s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 183/824 [15:39<55:45,  5.22s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 184/824 [15:39<55:17,  5.18s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 184/824 [15:44<55:17,  5.18s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 185/824 [15:44<54:55,  5.16s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 185/824 [15:49<54:55,  5.16s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 186/824 [15:49<54:47,  5.15s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 186/824 [15:54<54:47,  5.15s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 187/824 [15:54<54:52,  5.17s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 187/824 [16:00<54:52,  5.17s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 188/824 [16:00<55:37,  5.25s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 188/824 [16:05<55:37,  5.25s/it, training_loss=0.392]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 189/824 [16:05<56:28,  5.34s/it, training_loss=0.392]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 189/824 [16:10<56:28,  5.34s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 190/824 [16:10<55:54,  5.29s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 190/824 [16:15<55:54,  5.29s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 191/824 [16:15<55:19,  5.24s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 191/824 [16:21<55:19,  5.24s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 192/824 [16:21<54:46,  5.20s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 192/824 [16:26<54:46,  5.20s/it, training_loss=0.167]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 193/824 [16:26<54:29,  5.18s/it, training_loss=0.167]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 193/824 [16:31<54:29,  5.18s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 2:  24%|██▎       | 194/824 [16:31<54:57,  5.23s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 2:  24%|██▎       | 194/824 [16:36<54:57,  5.23s/it, training_loss=0.002]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  24%|██▎       | 195/824 [16:36<55:00,  5.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  24%|██▎       | 195/824 [16:41<55:00,  5.25s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 196/824 [16:41<54:40,  5.22s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 196/824 [16:47<54:40,  5.22s/it, training_loss=0.415]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 197/824 [16:47<55:21,  5.30s/it, training_loss=0.415]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 197/824 [16:53<55:21,  5.30s/it, training_loss=0.118]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 198/824 [16:53<57:19,  5.50s/it, training_loss=0.118]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 198/824 [16:59<57:19,  5.50s/it, training_loss=0.127]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 199/824 [16:59<58:21,  5.60s/it, training_loss=0.127]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 199/824 [17:04<58:21,  5.60s/it, training_loss=0.126]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 200/824 [17:04<58:19,  5.61s/it, training_loss=0.126]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 200/824 [17:10<58:19,  5.61s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 201/824 [17:10<59:02,  5.69s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 201/824 [17:16<59:02,  5.69s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 202/824 [17:16<59:33,  5.75s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 202/824 [17:22<59:33,  5.75s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 203/824 [17:22<1:00:50,  5.88s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 203/824 [17:28<1:00:50,  5.88s/it, training_loss=0.062]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 204/824 [17:28<1:00:23,  5.84s/it, training_loss=0.062]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 204/824 [17:34<1:00:23,  5.84s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 205/824 [17:34<1:01:27,  5.96s/it, training_loss=0.314]\u001b[A\n",
      "Epoch 2:  25%|██▍       | 205/824 [17:40<1:01:27,  5.96s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 206/824 [17:40<1:01:46,  6.00s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 206/824 [17:46<1:01:46,  6.00s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 207/824 [17:46<1:01:32,  5.98s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 207/824 [17:52<1:01:32,  5.98s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 208/824 [17:52<1:01:12,  5.96s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 208/824 [17:58<1:01:12,  5.96s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 209/824 [17:58<1:01:06,  5.96s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 209/824 [18:04<1:01:06,  5.96s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 210/824 [18:04<1:00:31,  5.91s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 210/824 [18:10<1:00:31,  5.91s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 211/824 [18:10<1:01:09,  5.99s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 211/824 [18:16<1:01:09,  5.99s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 212/824 [18:16<1:01:39,  6.04s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 212/824 [18:23<1:01:39,  6.04s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 213/824 [18:23<1:04:26,  6.33s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 213/824 [18:29<1:04:26,  6.33s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 214/824 [18:29<1:03:17,  6.23s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 214/824 [18:35<1:03:17,  6.23s/it, training_loss=0.122]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 215/824 [18:35<1:02:10,  6.13s/it, training_loss=0.122]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 215/824 [18:41<1:02:10,  6.13s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 216/824 [18:41<1:01:28,  6.07s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 216/824 [18:47<1:01:28,  6.07s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 2:  26%|██▋       | 217/824 [18:47<1:01:02,  6.03s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 2:  26%|██▋       | 217/824 [18:53<1:01:02,  6.03s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  26%|██▋       | 218/824 [18:53<1:01:49,  6.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  26%|██▋       | 218/824 [19:00<1:01:49,  6.12s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 219/824 [19:00<1:03:19,  6.28s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 219/824 [19:07<1:03:19,  6.28s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 220/824 [19:07<1:06:27,  6.60s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 220/824 [19:14<1:06:27,  6.60s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 221/824 [19:14<1:06:55,  6.66s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 221/824 [19:20<1:06:55,  6.66s/it, training_loss=0.110]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 222/824 [19:20<1:05:03,  6.48s/it, training_loss=0.110]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 222/824 [19:26<1:05:03,  6.48s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 223/824 [19:26<1:04:03,  6.39s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 223/824 [19:33<1:04:03,  6.39s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 224/824 [19:33<1:03:10,  6.32s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 224/824 [19:39<1:03:10,  6.32s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 225/824 [19:39<1:03:01,  6.31s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 225/824 [19:45<1:03:01,  6.31s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 226/824 [19:45<1:02:19,  6.25s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 226/824 [19:51<1:02:19,  6.25s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 227/824 [19:51<1:01:52,  6.22s/it, training_loss=0.321]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 227/824 [19:57<1:01:52,  6.22s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 228/824 [19:57<1:01:17,  6.17s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 228/824 [20:03<1:01:17,  6.17s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 229/824 [20:03<1:01:01,  6.15s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 229/824 [20:09<1:01:01,  6.15s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 230/824 [20:09<1:00:17,  6.09s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 230/824 [20:15<1:00:17,  6.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 231/824 [20:15<59:54,  6.06s/it, training_loss=0.002]  \u001b[A\n",
      "Epoch 2:  28%|██▊       | 231/824 [20:21<59:54,  6.06s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 232/824 [20:21<59:28,  6.03s/it, training_loss=0.283]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 232/824 [20:27<59:28,  6.03s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 233/824 [20:27<59:16,  6.02s/it, training_loss=0.038]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 233/824 [20:33<59:16,  6.02s/it, training_loss=0.400]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 234/824 [20:33<59:08,  6.01s/it, training_loss=0.400]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 234/824 [20:39<59:08,  6.01s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  29%|██▊       | 235/824 [20:39<58:48,  5.99s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  29%|██▊       | 235/824 [20:45<58:48,  5.99s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  29%|██▊       | 236/824 [20:45<58:44,  5.99s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  29%|██▊       | 236/824 [20:52<58:44,  5.99s/it, training_loss=0.022]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 237/824 [20:52<1:00:16,  6.16s/it, training_loss=0.022]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 237/824 [20:59<1:00:16,  6.16s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 238/824 [20:59<1:03:31,  6.50s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 238/824 [21:07<1:03:31,  6.50s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 239/824 [21:07<1:09:06,  7.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 239/824 [21:16<1:09:06,  7.09s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 240/824 [21:16<1:13:56,  7.60s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 240/824 [21:25<1:13:56,  7.60s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 241/824 [21:25<1:16:51,  7.91s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 241/824 [21:33<1:16:51,  7.91s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 242/824 [21:33<1:18:30,  8.09s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 242/824 [21:41<1:18:30,  8.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 243/824 [21:41<1:18:11,  8.07s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 243/824 [21:49<1:18:11,  8.07s/it, training_loss=0.449]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 244/824 [21:49<1:17:47,  8.05s/it, training_loss=0.449]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 244/824 [21:57<1:17:47,  8.05s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 245/824 [21:57<1:16:54,  7.97s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 245/824 [22:05<1:16:54,  7.97s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 246/824 [22:05<1:15:14,  7.81s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 246/824 [22:12<1:15:14,  7.81s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 247/824 [22:12<1:13:52,  7.68s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 247/824 [22:19<1:13:52,  7.68s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  30%|███       | 248/824 [22:19<1:12:48,  7.58s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  30%|███       | 248/824 [22:27<1:12:48,  7.58s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  30%|███       | 249/824 [22:27<1:12:05,  7.52s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  30%|███       | 249/824 [22:34<1:12:05,  7.52s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  30%|███       | 250/824 [22:34<1:09:50,  7.30s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  30%|███       | 250/824 [22:40<1:09:50,  7.30s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  30%|███       | 251/824 [22:40<1:08:17,  7.15s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  30%|███       | 251/824 [22:47<1:08:17,  7.15s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  31%|███       | 252/824 [22:47<1:07:28,  7.08s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  31%|███       | 252/824 [22:54<1:07:28,  7.08s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  31%|███       | 253/824 [22:54<1:06:46,  7.02s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  31%|███       | 253/824 [23:01<1:06:46,  7.02s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  31%|███       | 254/824 [23:01<1:06:44,  7.03s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  31%|███       | 254/824 [23:08<1:06:44,  7.03s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  31%|███       | 255/824 [23:08<1:07:17,  7.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  31%|███       | 255/824 [23:16<1:07:17,  7.10s/it, training_loss=0.143]\u001b[A\n",
      "Epoch 2:  31%|███       | 256/824 [23:16<1:07:43,  7.15s/it, training_loss=0.143]\u001b[A\n",
      "Epoch 2:  31%|███       | 256/824 [23:23<1:07:43,  7.15s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  31%|███       | 257/824 [23:23<1:08:12,  7.22s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  31%|███       | 257/824 [23:31<1:08:12,  7.22s/it, training_loss=0.254]\u001b[A\n",
      "Epoch 2:  31%|███▏      | 258/824 [23:31<1:09:08,  7.33s/it, training_loss=0.254]\u001b[A\n",
      "Epoch 2:  31%|███▏      | 258/824 [23:38<1:09:08,  7.33s/it, training_loss=0.569]\u001b[A\n",
      "Epoch 2:  31%|███▏      | 259/824 [23:38<1:09:06,  7.34s/it, training_loss=0.569]\u001b[A\n",
      "Epoch 2:  31%|███▏      | 259/824 [23:45<1:09:06,  7.34s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 260/824 [23:45<1:08:44,  7.31s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 260/824 [23:52<1:08:44,  7.31s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 261/824 [23:52<1:07:29,  7.19s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 261/824 [23:59<1:07:29,  7.19s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 262/824 [23:59<1:06:19,  7.08s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 262/824 [24:06<1:06:19,  7.08s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 263/824 [24:06<1:05:16,  6.98s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 263/824 [24:13<1:05:16,  6.98s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 264/824 [24:13<1:04:45,  6.94s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 264/824 [24:19<1:04:45,  6.94s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 265/824 [24:19<1:04:05,  6.88s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 265/824 [24:26<1:04:05,  6.88s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 266/824 [24:26<1:02:51,  6.76s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 266/824 [24:32<1:02:51,  6.76s/it, training_loss=0.036]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 267/824 [24:32<1:02:04,  6.69s/it, training_loss=0.036]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 267/824 [24:39<1:02:04,  6.69s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 268/824 [24:39<1:01:44,  6.66s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 268/824 [24:46<1:01:44,  6.66s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 269/824 [24:46<1:02:37,  6.77s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 269/824 [24:53<1:02:37,  6.77s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 270/824 [24:53<1:03:20,  6.86s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 270/824 [25:00<1:03:20,  6.86s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 271/824 [25:00<1:04:26,  6.99s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 271/824 [25:08<1:04:26,  6.99s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 272/824 [25:08<1:04:59,  7.06s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 272/824 [25:15<1:04:59,  7.06s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 273/824 [25:15<1:05:19,  7.11s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 273/824 [25:22<1:05:19,  7.11s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 274/824 [25:22<1:05:11,  7.11s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 274/824 [25:29<1:05:11,  7.11s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 275/824 [25:29<1:04:30,  7.05s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 275/824 [25:36<1:04:30,  7.05s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 276/824 [25:36<1:03:28,  6.95s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 276/824 [25:42<1:03:28,  6.95s/it, training_loss=0.220]\u001b[A\n",
      "Epoch 2:  34%|███▎      | 277/824 [25:42<1:02:47,  6.89s/it, training_loss=0.220]\u001b[A\n",
      "Epoch 2:  34%|███▎      | 277/824 [25:49<1:02:47,  6.89s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  34%|███▎      | 278/824 [25:49<1:02:17,  6.85s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  34%|███▎      | 278/824 [25:56<1:02:17,  6.85s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 279/824 [25:56<1:02:25,  6.87s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 279/824 [26:03<1:02:25,  6.87s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 280/824 [26:03<1:02:34,  6.90s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 280/824 [26:10<1:02:34,  6.90s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 281/824 [26:10<1:02:32,  6.91s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 281/824 [26:17<1:02:32,  6.91s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 282/824 [26:17<1:02:35,  6.93s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 282/824 [26:24<1:02:35,  6.93s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 283/824 [26:24<1:02:23,  6.92s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 283/824 [26:30<1:02:23,  6.92s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 284/824 [26:30<1:01:49,  6.87s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 284/824 [26:37<1:01:49,  6.87s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 285/824 [26:37<1:01:15,  6.82s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 285/824 [26:44<1:01:15,  6.82s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 286/824 [26:44<1:00:55,  6.79s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 286/824 [26:51<1:00:55,  6.79s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 287/824 [26:51<1:00:41,  6.78s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 287/824 [26:57<1:00:41,  6.78s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 288/824 [26:57<1:00:29,  6.77s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  35%|███▍      | 288/824 [27:04<1:00:29,  6.77s/it, training_loss=0.107]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 289/824 [27:04<1:00:15,  6.76s/it, training_loss=0.107]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 289/824 [27:11<1:00:15,  6.76s/it, training_loss=0.068]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 290/824 [27:11<1:00:03,  6.75s/it, training_loss=0.068]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 290/824 [27:18<1:00:03,  6.75s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 291/824 [27:18<59:59,  6.75s/it, training_loss=0.003]  \u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  35%|███▌      | 291/824 [27:24<59:59,  6.75s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 292/824 [27:24<1:00:05,  6.78s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 292/824 [27:31<1:00:05,  6.78s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 293/824 [27:31<1:00:23,  6.82s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 293/824 [27:38<1:00:23,  6.82s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 294/824 [27:38<1:00:35,  6.86s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 294/824 [27:45<1:00:35,  6.86s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 295/824 [27:45<1:00:48,  6.90s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 295/824 [27:52<1:00:48,  6.90s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 296/824 [27:52<1:00:50,  6.91s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 296/824 [27:59<1:00:50,  6.91s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 297/824 [27:59<1:00:53,  6.93s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 297/824 [28:06<1:00:53,  6.93s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 298/824 [28:06<1:01:03,  6.96s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 298/824 [28:13<1:01:03,  6.96s/it, training_loss=0.426]\u001b[A\n",
      "Epoch 2:  36%|███▋      | 299/824 [28:13<1:00:27,  6.91s/it, training_loss=0.426]\u001b[A\n",
      "Epoch 2:  36%|███▋      | 299/824 [28:20<1:00:27,  6.91s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  36%|███▋      | 300/824 [28:20<59:24,  6.80s/it, training_loss=0.003]  \u001b[A\n",
      "Epoch 2:  36%|███▋      | 300/824 [28:26<59:24,  6.80s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 301/824 [28:26<58:35,  6.72s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 301/824 [28:33<58:35,  6.72s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 302/824 [28:33<57:49,  6.65s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 302/824 [28:39<57:49,  6.65s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 303/824 [28:39<57:22,  6.61s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 303/824 [28:46<57:22,  6.61s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 304/824 [28:46<57:05,  6.59s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 304/824 [28:52<57:05,  6.59s/it, training_loss=0.058]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 305/824 [28:52<57:11,  6.61s/it, training_loss=0.058]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 305/824 [28:59<57:11,  6.61s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 306/824 [28:59<57:25,  6.65s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 306/824 [29:06<57:25,  6.65s/it, training_loss=0.423]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 307/824 [29:06<57:53,  6.72s/it, training_loss=0.423]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 307/824 [29:13<57:53,  6.72s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 308/824 [29:13<58:28,  6.80s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 308/824 [29:20<58:28,  6.80s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 309/824 [29:20<58:37,  6.83s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 309/824 [29:27<58:37,  6.83s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 310/824 [29:27<58:50,  6.87s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 310/824 [29:34<58:50,  6.87s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 311/824 [29:34<58:53,  6.89s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 311/824 [29:41<58:53,  6.89s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 312/824 [29:41<58:54,  6.90s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 312/824 [29:48<58:54,  6.90s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 313/824 [29:48<58:29,  6.87s/it, training_loss=0.311]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 313/824 [29:54<58:29,  6.87s/it, training_loss=0.086]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 314/824 [29:54<57:54,  6.81s/it, training_loss=0.086]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 314/824 [30:01<57:54,  6.81s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 315/824 [30:01<57:10,  6.74s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 315/824 [30:07<57:10,  6.74s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 316/824 [30:07<56:30,  6.68s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 316/824 [30:14<56:30,  6.68s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 317/824 [30:14<55:59,  6.63s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 317/824 [30:20<55:59,  6.63s/it, training_loss=0.034]\u001b[A\n",
      "Epoch 2:  39%|███▊      | 318/824 [30:20<55:33,  6.59s/it, training_loss=0.034]\u001b[A\n",
      "Epoch 2:  39%|███▊      | 318/824 [30:27<55:33,  6.59s/it, training_loss=0.402]\u001b[A\n",
      "Epoch 2:  39%|███▊      | 319/824 [30:27<55:20,  6.58s/it, training_loss=0.402]\u001b[A\n",
      "Epoch 2:  39%|███▊      | 319/824 [30:33<55:20,  6.58s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 320/824 [30:33<55:09,  6.57s/it, training_loss=0.261]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 320/824 [30:40<55:09,  6.57s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 321/824 [30:40<55:29,  6.62s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 321/824 [30:47<55:29,  6.62s/it, training_loss=0.134]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 322/824 [30:47<55:58,  6.69s/it, training_loss=0.134]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 322/824 [30:54<55:58,  6.69s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 323/824 [30:54<56:40,  6.79s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 323/824 [31:01<56:40,  6.79s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 324/824 [31:01<57:01,  6.84s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 324/824 [31:08<57:01,  6.84s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 325/824 [31:08<57:11,  6.88s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 325/824 [31:15<57:11,  6.88s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 326/824 [31:15<57:02,  6.87s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 326/824 [31:22<57:02,  6.87s/it, training_loss=0.036]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 327/824 [31:22<56:33,  6.83s/it, training_loss=0.036]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 327/824 [31:28<56:33,  6.83s/it, training_loss=0.380]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 328/824 [31:28<56:11,  6.80s/it, training_loss=0.380]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 328/824 [31:35<56:11,  6.80s/it, training_loss=0.406]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 329/824 [31:35<55:32,  6.73s/it, training_loss=0.406]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 329/824 [31:41<55:32,  6.73s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  40%|████      | 330/824 [31:41<54:54,  6.67s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  40%|████      | 330/824 [31:48<54:54,  6.67s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  40%|████      | 331/824 [31:48<54:27,  6.63s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  40%|████      | 331/824 [31:54<54:27,  6.63s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 2:  40%|████      | 332/824 [31:54<54:05,  6.60s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 2:  40%|████      | 332/824 [32:01<54:05,  6.60s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 2:  40%|████      | 333/824 [32:01<53:46,  6.57s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 2:  40%|████      | 333/824 [32:07<53:46,  6.57s/it, training_loss=0.495]\u001b[A\n",
      "Epoch 2:  41%|████      | 334/824 [32:07<53:30,  6.55s/it, training_loss=0.495]\u001b[A\n",
      "Epoch 2:  41%|████      | 334/824 [32:14<53:30,  6.55s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  41%|████      | 335/824 [32:14<53:22,  6.55s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  41%|████      | 335/824 [32:21<53:22,  6.55s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 2:  41%|████      | 336/824 [32:21<53:20,  6.56s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 2:  41%|████      | 336/824 [32:27<53:20,  6.56s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  41%|████      | 337/824 [32:27<54:07,  6.67s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  41%|████      | 337/824 [32:34<54:07,  6.67s/it, training_loss=0.128]\u001b[A\n",
      "Epoch 2:  41%|████      | 338/824 [32:34<54:08,  6.68s/it, training_loss=0.128]\u001b[A\n",
      "Epoch 2:  41%|████      | 338/824 [32:41<54:08,  6.68s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  41%|████      | 339/824 [32:41<54:26,  6.74s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  41%|████      | 339/824 [32:48<54:26,  6.74s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  41%|████▏     | 340/824 [32:48<55:02,  6.82s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  41%|████▏     | 340/824 [32:55<55:02,  6.82s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 2:  41%|████▏     | 341/824 [32:55<55:11,  6.86s/it, training_loss=0.251]\u001b[A\n",
      "Epoch 2:  41%|████▏     | 341/824 [33:02<55:11,  6.86s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 342/824 [33:02<54:42,  6.81s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 342/824 [33:08<54:42,  6.81s/it, training_loss=0.095]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 343/824 [33:08<54:20,  6.78s/it, training_loss=0.095]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 343/824 [33:15<54:20,  6.78s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 344/824 [33:15<54:11,  6.77s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 344/824 [33:22<54:11,  6.77s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 345/824 [33:22<54:03,  6.77s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 345/824 [33:29<54:03,  6.77s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 346/824 [33:29<53:53,  6.77s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 346/824 [33:35<53:53,  6.77s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 347/824 [33:35<53:37,  6.75s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 347/824 [33:42<53:37,  6.75s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 348/824 [33:42<52:57,  6.68s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 348/824 [33:48<52:57,  6.68s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 349/824 [33:48<52:30,  6.63s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 349/824 [33:55<52:30,  6.63s/it, training_loss=0.415]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 350/824 [33:55<52:09,  6.60s/it, training_loss=0.415]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 350/824 [34:01<52:09,  6.60s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 351/824 [34:01<51:52,  6.58s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 351/824 [34:08<51:52,  6.58s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 352/824 [34:08<51:38,  6.56s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 352/824 [34:15<51:38,  6.56s/it, training_loss=0.416]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 353/824 [34:15<51:28,  6.56s/it, training_loss=0.416]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 353/824 [34:21<51:28,  6.56s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 354/824 [34:21<51:50,  6.62s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 354/824 [34:28<51:50,  6.62s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 355/824 [34:28<52:02,  6.66s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 355/824 [34:35<52:02,  6.66s/it, training_loss=0.042]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 356/824 [34:35<52:05,  6.68s/it, training_loss=0.042]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 356/824 [34:42<52:05,  6.68s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 357/824 [34:42<53:50,  6.92s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 357/824 [34:50<53:50,  6.92s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 358/824 [34:50<54:32,  7.02s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 358/824 [34:57<54:32,  7.02s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  44%|████▎     | 359/824 [34:57<54:41,  7.06s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  44%|████▎     | 359/824 [35:04<54:41,  7.06s/it, training_loss=0.454]\u001b[A\n",
      "Epoch 2:  44%|████▎     | 360/824 [35:04<54:12,  7.01s/it, training_loss=0.454]\u001b[A\n",
      "Epoch 2:  44%|████▎     | 360/824 [35:10<54:12,  7.01s/it, training_loss=0.118]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 361/824 [35:10<53:16,  6.90s/it, training_loss=0.118]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 361/824 [35:17<53:16,  6.90s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 362/824 [35:17<52:19,  6.80s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 362/824 [35:23<52:19,  6.80s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 363/824 [35:23<51:36,  6.72s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 363/824 [35:30<51:36,  6.72s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 364/824 [35:30<51:10,  6.68s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 364/824 [35:37<51:10,  6.68s/it, training_loss=0.032]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 365/824 [35:37<50:56,  6.66s/it, training_loss=0.032]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 365/824 [35:43<50:56,  6.66s/it, training_loss=0.358]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 366/824 [35:43<51:20,  6.73s/it, training_loss=0.358]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 366/824 [35:50<51:20,  6.73s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 367/824 [35:50<51:54,  6.81s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 367/824 [35:57<51:54,  6.81s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 368/824 [35:57<52:09,  6.86s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 368/824 [36:04<52:09,  6.86s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 369/824 [36:04<52:17,  6.90s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 369/824 [36:11<52:17,  6.90s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 370/824 [36:11<52:19,  6.91s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 370/824 [36:18<52:19,  6.91s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 371/824 [36:18<52:00,  6.89s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 371/824 [36:25<52:00,  6.89s/it, training_loss=0.168]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 372/824 [36:25<51:29,  6.84s/it, training_loss=0.168]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 372/824 [36:31<51:29,  6.84s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 373/824 [36:31<50:49,  6.76s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 373/824 [36:38<50:49,  6.76s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 374/824 [36:38<50:14,  6.70s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 374/824 [36:45<50:14,  6.70s/it, training_loss=0.382]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 375/824 [36:45<49:52,  6.66s/it, training_loss=0.382]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 375/824 [36:51<49:52,  6.66s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 376/824 [36:51<49:34,  6.64s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 376/824 [36:58<49:34,  6.64s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 377/824 [36:58<49:09,  6.60s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 377/824 [37:04<49:09,  6.60s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 378/824 [37:04<48:51,  6.57s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 378/824 [37:11<48:51,  6.57s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 379/824 [37:11<48:46,  6.58s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 379/824 [37:17<48:46,  6.58s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 380/824 [37:17<48:57,  6.62s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 380/824 [37:24<48:57,  6.62s/it, training_loss=0.056]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 381/824 [37:24<49:07,  6.65s/it, training_loss=0.056]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 381/824 [37:31<49:07,  6.65s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  46%|████▋     | 382/824 [37:31<49:13,  6.68s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  46%|████▋     | 382/824 [37:38<49:13,  6.68s/it, training_loss=0.844]\u001b[A\n",
      "Epoch 2:  46%|████▋     | 383/824 [37:38<49:12,  6.70s/it, training_loss=0.844]\u001b[A\n",
      "Epoch 2:  46%|████▋     | 383/824 [37:45<49:12,  6.70s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 384/824 [37:45<49:27,  6.74s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 384/824 [37:51<49:27,  6.74s/it, training_loss=0.428]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 385/824 [37:51<49:06,  6.71s/it, training_loss=0.428]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 385/824 [37:58<49:06,  6.71s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 386/824 [37:58<48:44,  6.68s/it, training_loss=0.243]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 386/824 [38:04<48:44,  6.68s/it, training_loss=0.128]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 387/824 [38:04<48:22,  6.64s/it, training_loss=0.128]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 387/824 [38:11<48:22,  6.64s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 388/824 [38:11<48:01,  6.61s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 388/824 [38:17<48:01,  6.61s/it, training_loss=0.423]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 389/824 [38:17<47:44,  6.59s/it, training_loss=0.423]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  47%|████▋     | 389/824 [38:24<47:44,  6.59s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 390/824 [38:24<47:51,  6.62s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 390/824 [38:31<47:51,  6.62s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 391/824 [38:31<47:58,  6.65s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 391/824 [38:38<47:58,  6.65s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 392/824 [38:38<47:58,  6.66s/it, training_loss=0.345]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 392/824 [38:44<47:58,  6.66s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 393/824 [38:44<47:56,  6.67s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 393/824 [38:51<47:56,  6.67s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 394/824 [38:51<47:53,  6.68s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 394/824 [38:58<47:53,  6.68s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 395/824 [38:58<47:56,  6.71s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 395/824 [39:04<47:56,  6.71s/it, training_loss=0.180]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 396/824 [39:04<47:47,  6.70s/it, training_loss=0.180]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 396/824 [39:11<47:47,  6.70s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 397/824 [39:11<47:28,  6.67s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 397/824 [39:17<47:28,  6.67s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 398/824 [39:17<47:03,  6.63s/it, training_loss=0.344]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 398/824 [39:24<47:03,  6.63s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 399/824 [39:24<46:44,  6.60s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 399/824 [39:31<46:44,  6.60s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  49%|████▊     | 400/824 [39:31<46:26,  6.57s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  49%|████▊     | 400/824 [39:37<46:26,  6.57s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  49%|████▊     | 401/824 [39:37<46:15,  6.56s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  49%|████▊     | 401/824 [39:44<46:15,  6.56s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 402/824 [39:44<45:59,  6.54s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 402/824 [39:50<45:59,  6.54s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 403/824 [39:50<45:44,  6.52s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 403/824 [39:56<45:44,  6.52s/it, training_loss=0.206]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 404/824 [39:56<45:11,  6.46s/it, training_loss=0.206]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 404/824 [40:03<45:11,  6.46s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 405/824 [40:03<44:46,  6.41s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 405/824 [40:09<44:46,  6.41s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 406/824 [40:09<44:47,  6.43s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 406/824 [40:16<44:47,  6.43s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 407/824 [40:16<44:55,  6.46s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 407/824 [40:22<44:55,  6.46s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 408/824 [40:22<45:12,  6.52s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 408/824 [40:29<45:12,  6.52s/it, training_loss=0.140]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 409/824 [40:29<45:27,  6.57s/it, training_loss=0.140]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 409/824 [40:36<45:27,  6.57s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 410/824 [40:36<45:44,  6.63s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 410/824 [40:43<45:44,  6.63s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 411/824 [40:43<45:52,  6.66s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  50%|████▉     | 411/824 [40:49<45:52,  6.66s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 2:  50%|█████     | 412/824 [40:49<45:55,  6.69s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 2:  50%|█████     | 412/824 [40:56<45:55,  6.69s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 2:  50%|█████     | 413/824 [40:56<45:43,  6.68s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 2:  50%|█████     | 413/824 [41:02<45:43,  6.68s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  50%|█████     | 414/824 [41:02<45:16,  6.62s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  50%|█████     | 414/824 [41:09<45:16,  6.62s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  50%|█████     | 415/824 [41:09<44:53,  6.59s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  50%|█████     | 415/824 [41:15<44:53,  6.59s/it, training_loss=0.475]\u001b[A\n",
      "Epoch 2:  50%|█████     | 416/824 [41:15<44:40,  6.57s/it, training_loss=0.475]\u001b[A\n",
      "Epoch 2:  50%|█████     | 416/824 [41:22<44:40,  6.57s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  51%|█████     | 417/824 [41:22<44:35,  6.57s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  51%|█████     | 417/824 [41:29<44:35,  6.57s/it, training_loss=0.372]\u001b[A\n",
      "Epoch 2:  51%|█████     | 418/824 [41:29<44:37,  6.60s/it, training_loss=0.372]\u001b[A\n",
      "Epoch 2:  51%|█████     | 418/824 [41:35<44:37,  6.60s/it, training_loss=0.034]\u001b[A\n",
      "Epoch 2:  51%|█████     | 419/824 [41:35<44:22,  6.57s/it, training_loss=0.034]\u001b[A\n",
      "Epoch 2:  51%|█████     | 419/824 [41:42<44:22,  6.57s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  51%|█████     | 420/824 [41:42<44:15,  6.57s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  51%|█████     | 420/824 [41:49<44:15,  6.57s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████     | 421/824 [41:49<44:30,  6.63s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  51%|█████     | 421/824 [41:55<44:30,  6.63s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 2:  51%|█████     | 422/824 [41:55<44:41,  6.67s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 2:  51%|█████     | 422/824 [42:02<44:41,  6.67s/it, training_loss=0.195]\u001b[A\n",
      "Epoch 2:  51%|█████▏    | 423/824 [42:02<44:42,  6.69s/it, training_loss=0.195]\u001b[A\n",
      "Epoch 2:  51%|█████▏    | 423/824 [42:09<44:42,  6.69s/it, training_loss=0.343]\u001b[A\n",
      "Epoch 2:  51%|█████▏    | 424/824 [42:09<44:43,  6.71s/it, training_loss=0.343]\u001b[A\n",
      "Epoch 2:  51%|█████▏    | 424/824 [42:16<44:43,  6.71s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 425/824 [42:16<44:41,  6.72s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 425/824 [42:22<44:41,  6.72s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 426/824 [42:22<44:35,  6.72s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 426/824 [42:29<44:35,  6.72s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 427/824 [42:29<44:36,  6.74s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 427/824 [42:36<44:36,  6.74s/it, training_loss=0.499]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 428/824 [42:36<44:40,  6.77s/it, training_loss=0.499]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 428/824 [42:42<44:40,  6.77s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 429/824 [42:43<44:18,  6.73s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 429/824 [42:49<44:18,  6.73s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 430/824 [42:49<43:36,  6.64s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 430/824 [42:55<43:36,  6.64s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 431/824 [42:55<42:52,  6.55s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 431/824 [43:02<42:52,  6.55s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 432/824 [43:02<42:26,  6.50s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 432/824 [43:08<42:26,  6.50s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 433/824 [43:08<41:58,  6.44s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 433/824 [43:14<41:58,  6.44s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 434/824 [43:14<41:36,  6.40s/it, training_loss=0.274]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 434/824 [43:21<41:36,  6.40s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 435/824 [43:21<41:26,  6.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 435/824 [43:27<41:26,  6.39s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 436/824 [43:27<41:29,  6.42s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 436/824 [43:34<41:29,  6.42s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 437/824 [43:34<41:31,  6.44s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 437/824 [43:40<41:31,  6.44s/it, training_loss=0.628]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 438/824 [43:40<41:28,  6.45s/it, training_loss=0.628]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 438/824 [43:47<41:28,  6.45s/it, training_loss=0.184]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 439/824 [43:47<41:26,  6.46s/it, training_loss=0.184]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 439/824 [43:53<41:26,  6.46s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 440/824 [43:53<41:21,  6.46s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 440/824 [43:59<41:21,  6.46s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▎    | 441/824 [43:59<41:16,  6.47s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▎    | 441/824 [44:06<41:16,  6.47s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▎    | 442/824 [44:06<41:11,  6.47s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▎    | 442/824 [44:12<41:11,  6.47s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 443/824 [44:12<40:43,  6.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 443/824 [44:19<40:43,  6.41s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 444/824 [44:19<40:24,  6.38s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 444/824 [44:25<40:24,  6.38s/it, training_loss=0.120]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 445/824 [44:25<40:08,  6.35s/it, training_loss=0.120]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 445/824 [44:31<40:08,  6.35s/it, training_loss=0.433]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 446/824 [44:31<39:57,  6.34s/it, training_loss=0.433]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 446/824 [44:38<39:57,  6.34s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 447/824 [44:38<40:04,  6.38s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 447/824 [44:44<40:04,  6.38s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 448/824 [44:44<40:14,  6.42s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 448/824 [44:51<40:14,  6.42s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 449/824 [44:51<40:37,  6.50s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 449/824 [44:58<40:37,  6.50s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 450/824 [44:58<40:52,  6.56s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 450/824 [45:04<40:52,  6.56s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 451/824 [45:04<41:24,  6.66s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 451/824 [45:11<41:24,  6.66s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 452/824 [45:11<41:44,  6.73s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 452/824 [45:18<41:44,  6.73s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 453/824 [45:18<41:57,  6.79s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 453/824 [45:25<41:57,  6.79s/it, training_loss=0.150]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 454/824 [45:25<41:39,  6.76s/it, training_loss=0.150]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 454/824 [45:31<41:39,  6.76s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 455/824 [45:31<41:06,  6.68s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 455/824 [45:38<41:06,  6.68s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 456/824 [45:38<40:31,  6.61s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 456/824 [45:44<40:31,  6.61s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 457/824 [45:44<39:50,  6.51s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 457/824 [45:51<39:50,  6.51s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 458/824 [45:51<39:31,  6.48s/it, training_loss=0.268]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 458/824 [45:57<39:31,  6.48s/it, training_loss=0.471]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 459/824 [45:57<39:36,  6.51s/it, training_loss=0.471]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 459/824 [46:04<39:36,  6.51s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 460/824 [46:04<39:52,  6.57s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 460/824 [46:11<39:52,  6.57s/it, training_loss=0.157]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 461/824 [46:11<40:01,  6.62s/it, training_loss=0.157]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 461/824 [46:17<40:01,  6.62s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 462/824 [46:17<40:07,  6.65s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 462/824 [46:24<40:07,  6.65s/it, training_loss=0.115]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 463/824 [46:24<40:09,  6.67s/it, training_loss=0.115]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 463/824 [46:31<40:09,  6.67s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  56%|█████▋    | 464/824 [46:31<40:10,  6.70s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  56%|█████▋    | 464/824 [46:37<40:10,  6.70s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  56%|█████▋    | 465/824 [46:37<39:43,  6.64s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  56%|█████▋    | 465/824 [46:44<39:43,  6.64s/it, training_loss=0.100]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 466/824 [46:44<39:24,  6.60s/it, training_loss=0.100]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 466/824 [46:50<39:24,  6.60s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 467/824 [46:50<39:09,  6.58s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 467/824 [46:57<39:09,  6.58s/it, training_loss=0.116]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 468/824 [46:57<38:52,  6.55s/it, training_loss=0.116]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 468/824 [47:03<38:52,  6.55s/it, training_loss=0.364]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 469/824 [47:03<38:39,  6.53s/it, training_loss=0.364]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 469/824 [47:10<38:39,  6.53s/it, training_loss=0.080]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 470/824 [47:10<38:31,  6.53s/it, training_loss=0.080]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 470/824 [47:17<38:31,  6.53s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 471/824 [47:17<38:45,  6.59s/it, training_loss=0.306]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 471/824 [47:23<38:45,  6.59s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 472/824 [47:23<38:55,  6.64s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 472/824 [47:30<38:55,  6.64s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 473/824 [47:30<38:55,  6.65s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 473/824 [47:37<38:55,  6.65s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 474/824 [47:37<38:54,  6.67s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 474/824 [47:43<38:54,  6.67s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 475/824 [47:43<38:55,  6.69s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 475/824 [47:50<38:55,  6.69s/it, training_loss=0.151]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 476/824 [47:50<38:43,  6.68s/it, training_loss=0.151]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 476/824 [47:57<38:43,  6.68s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 477/824 [47:57<38:18,  6.62s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 477/824 [48:03<38:18,  6.62s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 478/824 [48:03<37:57,  6.58s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 478/824 [48:10<37:57,  6.58s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 479/824 [48:10<37:47,  6.57s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 479/824 [48:16<37:47,  6.57s/it, training_loss=0.032]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 480/824 [48:16<37:33,  6.55s/it, training_loss=0.032]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 480/824 [48:22<37:33,  6.55s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 481/824 [48:22<37:01,  6.48s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 481/824 [48:29<37:01,  6.48s/it, training_loss=0.109]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 482/824 [48:29<36:42,  6.44s/it, training_loss=0.109]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 482/824 [48:35<36:42,  6.44s/it, training_loss=0.211]\u001b[A\n",
      "Epoch 2:  59%|█████▊    | 483/824 [48:35<36:37,  6.44s/it, training_loss=0.211]\u001b[A\n",
      "Epoch 2:  59%|█████▊    | 483/824 [48:42<36:37,  6.44s/it, training_loss=0.365]\u001b[A\n",
      "Epoch 2:  59%|█████▊    | 484/824 [48:42<36:16,  6.40s/it, training_loss=0.365]\u001b[A\n",
      "Epoch 2:  59%|█████▊    | 484/824 [48:48<36:16,  6.40s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 485/824 [48:48<36:18,  6.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 485/824 [48:55<36:18,  6.43s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 486/824 [48:55<36:35,  6.50s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 486/824 [49:01<36:35,  6.50s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 487/824 [49:01<36:41,  6.53s/it, training_loss=0.001]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  59%|█████▉    | 487/824 [49:08<36:41,  6.53s/it, training_loss=0.225]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 488/824 [49:08<37:02,  6.62s/it, training_loss=0.225]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 488/824 [49:15<37:02,  6.62s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 489/824 [49:15<37:09,  6.65s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 489/824 [49:22<37:09,  6.65s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 490/824 [49:22<37:11,  6.68s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 490/824 [49:28<37:11,  6.68s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 491/824 [49:28<37:13,  6.71s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 491/824 [49:35<37:13,  6.71s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 492/824 [49:35<37:02,  6.70s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 492/824 [49:42<37:02,  6.70s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 493/824 [49:42<36:39,  6.64s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 493/824 [49:48<36:39,  6.64s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 494/824 [49:48<36:25,  6.62s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  60%|█████▉    | 494/824 [49:55<36:25,  6.62s/it, training_loss=0.211]\u001b[A\n",
      "Epoch 2:  60%|██████    | 495/824 [49:55<36:10,  6.60s/it, training_loss=0.211]\u001b[A\n",
      "Epoch 2:  60%|██████    | 495/824 [50:01<36:10,  6.60s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  60%|██████    | 496/824 [50:01<36:00,  6.59s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  60%|██████    | 496/824 [50:08<36:00,  6.59s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  60%|██████    | 497/824 [50:08<35:53,  6.59s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  60%|██████    | 497/824 [50:14<35:53,  6.59s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  60%|██████    | 498/824 [50:14<35:51,  6.60s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  60%|██████    | 498/824 [50:21<35:51,  6.60s/it, training_loss=0.636]\u001b[A\n",
      "Epoch 2:  61%|██████    | 499/824 [50:21<35:38,  6.58s/it, training_loss=0.636]\u001b[A\n",
      "Epoch 2:  61%|██████    | 499/824 [50:27<35:38,  6.58s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  61%|██████    | 500/824 [50:27<35:24,  6.56s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  61%|██████    | 500/824 [50:34<35:24,  6.56s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  61%|██████    | 501/824 [50:34<35:24,  6.58s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  61%|██████    | 501/824 [50:41<35:24,  6.58s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  61%|██████    | 502/824 [50:41<35:28,  6.61s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  61%|██████    | 502/824 [50:48<35:28,  6.61s/it, training_loss=0.127]\u001b[A\n",
      "Epoch 2:  61%|██████    | 503/824 [50:48<35:31,  6.64s/it, training_loss=0.127]\u001b[A\n",
      "Epoch 2:  61%|██████    | 503/824 [50:54<35:31,  6.64s/it, training_loss=0.106]\u001b[A\n",
      "Epoch 2:  61%|██████    | 504/824 [50:54<35:30,  6.66s/it, training_loss=0.106]\u001b[A\n",
      "Epoch 2:  61%|██████    | 504/824 [51:01<35:30,  6.66s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  61%|██████▏   | 505/824 [51:01<35:41,  6.71s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  61%|██████▏   | 505/824 [51:08<35:41,  6.71s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  61%|██████▏   | 506/824 [51:08<35:32,  6.71s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  61%|██████▏   | 506/824 [51:14<35:32,  6.71s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 507/824 [51:14<35:09,  6.65s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 507/824 [51:21<35:09,  6.65s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 508/824 [51:21<34:49,  6.61s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 508/824 [51:27<34:49,  6.61s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 509/824 [51:27<34:31,  6.58s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 509/824 [51:34<34:31,  6.58s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 510/824 [51:34<34:16,  6.55s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 510/824 [51:40<34:16,  6.55s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 511/824 [51:40<33:58,  6.51s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 511/824 [51:47<33:58,  6.51s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 512/824 [51:47<33:36,  6.46s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 512/824 [51:53<33:36,  6.46s/it, training_loss=0.207]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 513/824 [51:53<33:18,  6.43s/it, training_loss=0.207]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 513/824 [51:59<33:18,  6.43s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 514/824 [51:59<33:22,  6.46s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 514/824 [52:06<33:22,  6.46s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  62%|██████▎   | 515/824 [52:06<33:26,  6.49s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  62%|██████▎   | 515/824 [52:13<33:26,  6.49s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 516/824 [52:13<33:40,  6.56s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 516/824 [52:19<33:40,  6.56s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 517/824 [52:19<33:47,  6.61s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 517/824 [52:26<33:47,  6.61s/it, training_loss=0.387]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 518/824 [52:26<33:50,  6.64s/it, training_loss=0.387]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 518/824 [52:33<33:50,  6.64s/it, training_loss=0.124]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 519/824 [52:33<33:52,  6.66s/it, training_loss=0.124]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 519/824 [52:40<33:52,  6.66s/it, training_loss=0.379]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 520/824 [52:40<33:50,  6.68s/it, training_loss=0.379]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 520/824 [52:46<33:50,  6.68s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 521/824 [52:46<33:57,  6.72s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 521/824 [52:53<33:57,  6.72s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 522/824 [52:53<33:47,  6.71s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 522/824 [53:00<33:47,  6.71s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 523/824 [53:00<33:42,  6.72s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 523/824 [53:07<33:42,  6.72s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 2:  64%|██████▎   | 524/824 [53:07<33:36,  6.72s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 2:  64%|██████▎   | 524/824 [53:13<33:36,  6.72s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 2:  64%|██████▎   | 525/824 [53:13<33:42,  6.76s/it, training_loss=0.262]\u001b[A\n",
      "Epoch 2:  64%|██████▎   | 525/824 [53:20<33:42,  6.76s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 526/824 [53:20<33:39,  6.78s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 526/824 [53:28<33:39,  6.78s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 527/824 [53:28<35:11,  7.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 527/824 [53:38<35:11,  7.11s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 528/824 [53:38<38:28,  7.80s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 528/824 [53:46<38:28,  7.80s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 529/824 [53:46<38:55,  7.92s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 529/824 [53:54<38:55,  7.92s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 530/824 [53:54<38:48,  7.92s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 530/824 [54:01<38:48,  7.92s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 531/824 [54:01<38:11,  7.82s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 531/824 [54:08<38:11,  7.82s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 532/824 [54:08<37:11,  7.64s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 532/824 [54:15<37:11,  7.64s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 533/824 [54:15<36:01,  7.43s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 533/824 [54:22<36:01,  7.43s/it, training_loss=0.651]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 534/824 [54:22<34:44,  7.19s/it, training_loss=0.651]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 534/824 [54:28<34:44,  7.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 535/824 [54:28<33:26,  6.94s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 535/824 [54:35<33:26,  6.94s/it, training_loss=0.390]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 536/824 [54:35<32:26,  6.76s/it, training_loss=0.390]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 536/824 [54:41<32:26,  6.76s/it, training_loss=0.679]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 537/824 [54:41<31:42,  6.63s/it, training_loss=0.679]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 537/824 [54:47<31:42,  6.63s/it, training_loss=0.213]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 538/824 [54:47<31:16,  6.56s/it, training_loss=0.213]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 538/824 [54:54<31:16,  6.56s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 539/824 [54:54<30:45,  6.48s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  65%|██████▌   | 539/824 [55:00<30:45,  6.48s/it, training_loss=0.410]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 540/824 [55:00<30:16,  6.40s/it, training_loss=0.410]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 540/824 [55:06<30:16,  6.40s/it, training_loss=0.112]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 541/824 [55:06<29:57,  6.35s/it, training_loss=0.112]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 541/824 [55:13<29:57,  6.35s/it, training_loss=0.065]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 542/824 [55:13<29:53,  6.36s/it, training_loss=0.065]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 542/824 [55:19<29:53,  6.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 543/824 [55:19<30:05,  6.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 543/824 [55:26<30:05,  6.42s/it, training_loss=0.371]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 544/824 [55:26<30:13,  6.48s/it, training_loss=0.371]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 544/824 [55:32<30:13,  6.48s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 545/824 [55:32<30:27,  6.55s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 545/824 [55:39<30:27,  6.55s/it, training_loss=0.592]\u001b[A\n",
      "Epoch 2:  66%|██████▋   | 546/824 [55:39<30:35,  6.60s/it, training_loss=0.592]\u001b[A\n",
      "Epoch 2:  66%|██████▋   | 546/824 [55:46<30:35,  6.60s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  66%|██████▋   | 547/824 [55:46<30:39,  6.64s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  66%|██████▋   | 547/824 [55:53<30:39,  6.64s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 548/824 [55:53<30:37,  6.66s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 548/824 [55:59<30:37,  6.66s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 549/824 [55:59<30:34,  6.67s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 549/824 [56:06<30:34,  6.67s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 550/824 [56:06<30:29,  6.68s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 550/824 [56:13<30:29,  6.68s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 551/824 [56:13<30:29,  6.70s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 551/824 [56:19<30:29,  6.70s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 552/824 [56:19<30:24,  6.71s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 552/824 [56:26<30:24,  6.71s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 553/824 [56:26<30:16,  6.70s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 553/824 [56:33<30:16,  6.70s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 554/824 [56:33<30:11,  6.71s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 554/824 [56:40<30:11,  6.71s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 555/824 [56:40<30:08,  6.72s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 555/824 [56:46<30:08,  6.72s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 556/824 [56:46<30:08,  6.75s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 556/824 [56:53<30:08,  6.75s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 557/824 [56:53<29:53,  6.72s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 557/824 [57:00<29:53,  6.72s/it, training_loss=0.487]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 558/824 [57:00<29:29,  6.65s/it, training_loss=0.487]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 558/824 [57:06<29:29,  6.65s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 559/824 [57:06<29:10,  6.61s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 559/824 [57:13<29:10,  6.61s/it, training_loss=0.420]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 560/824 [57:13<28:55,  6.58s/it, training_loss=0.420]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 560/824 [57:19<28:55,  6.58s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 561/824 [57:19<28:45,  6.56s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 561/824 [57:26<28:45,  6.56s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 562/824 [57:26<28:49,  6.60s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 562/824 [57:33<28:49,  6.60s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 563/824 [57:33<28:52,  6.64s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 563/824 [57:39<28:52,  6.64s/it, training_loss=0.431]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 564/824 [57:39<28:54,  6.67s/it, training_loss=0.431]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 564/824 [57:46<28:54,  6.67s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  69%|██████▊   | 565/824 [57:46<28:51,  6.69s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  69%|██████▊   | 565/824 [57:53<28:51,  6.69s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  69%|██████▊   | 566/824 [57:53<28:49,  6.70s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  69%|██████▊   | 566/824 [57:59<28:49,  6.70s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 567/824 [57:59<28:44,  6.71s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 567/824 [58:06<28:44,  6.71s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 568/824 [58:06<28:35,  6.70s/it, training_loss=0.266]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 568/824 [58:13<28:35,  6.70s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 569/824 [58:13<28:12,  6.64s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 569/824 [58:19<28:12,  6.64s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 570/824 [58:19<27:59,  6.61s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 570/824 [58:26<27:59,  6.61s/it, training_loss=0.202]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 571/824 [58:26<27:44,  6.58s/it, training_loss=0.202]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 571/824 [58:32<27:44,  6.58s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 572/824 [58:32<27:45,  6.61s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 572/824 [58:39<27:45,  6.61s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 573/824 [58:39<27:59,  6.69s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 573/824 [58:46<27:59,  6.69s/it, training_loss=0.193]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 574/824 [58:46<28:07,  6.75s/it, training_loss=0.193]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 574/824 [58:53<28:07,  6.75s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 575/824 [58:53<28:09,  6.79s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 575/824 [59:00<28:09,  6.79s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 576/824 [59:00<28:04,  6.79s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 576/824 [59:06<28:04,  6.79s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|███████   | 577/824 [59:06<27:40,  6.72s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|███████   | 577/824 [59:13<27:40,  6.72s/it, training_loss=0.183]\u001b[A\n",
      "Epoch 2:  70%|███████   | 578/824 [59:13<27:13,  6.64s/it, training_loss=0.183]\u001b[A\n",
      "Epoch 2:  70%|███████   | 578/824 [59:19<27:13,  6.64s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|███████   | 579/824 [59:19<26:57,  6.60s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|███████   | 579/824 [59:26<26:57,  6.60s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|███████   | 580/824 [59:26<26:34,  6.54s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  70%|███████   | 580/824 [59:32<26:34,  6.54s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 2:  71%|███████   | 581/824 [59:32<26:10,  6.46s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 2:  71%|███████   | 581/824 [59:38<26:10,  6.46s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  71%|███████   | 582/824 [59:38<25:56,  6.43s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  71%|███████   | 582/824 [59:45<25:56,  6.43s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  71%|███████   | 583/824 [59:45<25:42,  6.40s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  71%|███████   | 583/824 [59:51<25:42,  6.40s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  71%|███████   | 584/824 [59:51<25:27,  6.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  71%|███████   | 584/824 [59:57<25:27,  6.37s/it, training_loss=0.128]\u001b[A\n",
      "Epoch 2:  71%|███████   | 585/824 [59:57<25:20,  6.36s/it, training_loss=0.128]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  71%|███████   | 585/824 [1:00:04<25:20,  6.36s/it, training_loss=0.183]\u001b[A\n",
      "Epoch 2:  71%|███████   | 586/824 [1:00:04<25:20,  6.39s/it, training_loss=0.183]\u001b[A\n",
      "Epoch 2:  71%|███████   | 586/824 [1:00:10<25:20,  6.39s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  71%|███████   | 587/824 [1:00:10<25:18,  6.41s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  71%|███████   | 587/824 [1:00:17<25:18,  6.41s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  71%|███████▏  | 588/824 [1:00:17<25:22,  6.45s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  71%|███████▏  | 588/824 [1:00:23<25:22,  6.45s/it, training_loss=0.201]\u001b[A\n",
      "Epoch 2:  71%|███████▏  | 589/824 [1:00:23<25:30,  6.51s/it, training_loss=0.201]\u001b[A\n",
      "Epoch 2:  71%|███████▏  | 589/824 [1:00:30<25:30,  6.51s/it, training_loss=0.065]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 590/824 [1:00:30<25:34,  6.56s/it, training_loss=0.065]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 590/824 [1:00:37<25:34,  6.56s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 591/824 [1:00:37<25:35,  6.59s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 591/824 [1:00:43<25:35,  6.59s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 592/824 [1:00:43<25:36,  6.62s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 592/824 [1:00:50<25:36,  6.62s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 593/824 [1:00:50<25:36,  6.65s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 593/824 [1:00:57<25:36,  6.65s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 594/824 [1:00:57<25:29,  6.65s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 594/824 [1:01:04<25:29,  6.65s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 595/824 [1:01:04<25:23,  6.65s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 595/824 [1:01:10<25:23,  6.65s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 596/824 [1:01:10<25:07,  6.61s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 596/824 [1:01:16<25:07,  6.61s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 597/824 [1:01:16<24:50,  6.57s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 597/824 [1:01:23<24:50,  6.57s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 598/824 [1:01:23<24:36,  6.53s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 598/824 [1:01:29<24:36,  6.53s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 599/824 [1:01:29<24:25,  6.52s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 599/824 [1:01:36<24:25,  6.52s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 600/824 [1:01:36<24:13,  6.49s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 600/824 [1:01:42<24:13,  6.49s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 601/824 [1:01:42<23:52,  6.43s/it, training_loss=0.275]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 601/824 [1:01:48<23:52,  6.43s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 602/824 [1:01:48<23:35,  6.38s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 602/824 [1:01:55<23:35,  6.38s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 603/824 [1:01:55<23:28,  6.37s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 603/824 [1:02:01<23:28,  6.37s/it, training_loss=0.212]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 604/824 [1:02:01<23:26,  6.39s/it, training_loss=0.212]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 604/824 [1:02:08<23:26,  6.39s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 605/824 [1:02:08<23:25,  6.42s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 605/824 [1:02:14<23:25,  6.42s/it, training_loss=0.362]\u001b[A\n",
      "Epoch 2:  74%|███████▎  | 606/824 [1:02:14<23:24,  6.44s/it, training_loss=0.362]\u001b[A\n",
      "Epoch 2:  74%|███████▎  | 606/824 [1:02:21<23:24,  6.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|███████▎  | 607/824 [1:02:21<23:33,  6.51s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|███████▎  | 607/824 [1:02:28<23:33,  6.51s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 608/824 [1:02:28<23:40,  6.57s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 608/824 [1:02:34<23:40,  6.57s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 609/824 [1:02:34<23:49,  6.65s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 609/824 [1:02:41<23:49,  6.65s/it, training_loss=0.141]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 610/824 [1:02:41<23:58,  6.72s/it, training_loss=0.141]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 610/824 [1:02:48<23:58,  6.72s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 611/824 [1:02:48<24:03,  6.78s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 611/824 [1:02:55<24:03,  6.78s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 612/824 [1:02:55<24:04,  6.81s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 612/824 [1:03:02<24:04,  6.81s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 613/824 [1:03:02<23:58,  6.82s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 613/824 [1:03:09<23:58,  6.82s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  75%|███████▍  | 614/824 [1:03:09<23:48,  6.80s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  75%|███████▍  | 614/824 [1:03:15<23:48,  6.80s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 2:  75%|███████▍  | 615/824 [1:03:15<23:39,  6.79s/it, training_loss=0.020]\u001b[A\n",
      "Epoch 2:  75%|███████▍  | 615/824 [1:03:22<23:39,  6.79s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  75%|███████▍  | 616/824 [1:03:22<23:15,  6.71s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  75%|███████▍  | 616/824 [1:03:28<23:15,  6.71s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  75%|███████▍  | 617/824 [1:03:28<22:54,  6.64s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  75%|███████▍  | 617/824 [1:03:35<22:54,  6.64s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 618/824 [1:03:35<22:38,  6.60s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 618/824 [1:03:41<22:38,  6.60s/it, training_loss=0.091]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 619/824 [1:03:41<22:29,  6.58s/it, training_loss=0.091]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 619/824 [1:03:48<22:29,  6.58s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 620/824 [1:03:48<22:32,  6.63s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 620/824 [1:03:55<22:32,  6.63s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 621/824 [1:03:55<22:24,  6.62s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 621/824 [1:04:02<22:24,  6.62s/it, training_loss=0.472]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 622/824 [1:04:02<22:27,  6.67s/it, training_loss=0.472]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 622/824 [1:04:08<22:27,  6.67s/it, training_loss=0.198]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 623/824 [1:04:09<22:34,  6.74s/it, training_loss=0.198]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 623/824 [1:04:15<22:34,  6.74s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 624/824 [1:04:15<22:39,  6.80s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 624/824 [1:04:22<22:39,  6.80s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 625/824 [1:04:22<22:39,  6.83s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 625/824 [1:04:29<22:39,  6.83s/it, training_loss=0.386]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 626/824 [1:04:29<22:37,  6.86s/it, training_loss=0.386]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 626/824 [1:04:36<22:37,  6.86s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 627/824 [1:04:36<22:35,  6.88s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 627/824 [1:04:43<22:35,  6.88s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 628/824 [1:04:43<22:26,  6.87s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 628/824 [1:04:50<22:26,  6.87s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 2:  76%|███████▋  | 629/824 [1:04:50<22:10,  6.82s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 2:  76%|███████▋  | 629/824 [1:04:57<22:10,  6.82s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  76%|███████▋  | 630/824 [1:04:57<22:01,  6.81s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  76%|███████▋  | 630/824 [1:05:03<22:01,  6.81s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 631/824 [1:05:03<21:40,  6.74s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 631/824 [1:05:10<21:40,  6.74s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 632/824 [1:05:10<21:20,  6.67s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 632/824 [1:05:16<21:20,  6.67s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 633/824 [1:05:16<20:58,  6.59s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 633/824 [1:05:22<20:58,  6.59s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 634/824 [1:05:22<20:35,  6.50s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 634/824 [1:05:29<20:35,  6.50s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 635/824 [1:05:29<20:16,  6.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 635/824 [1:05:35<20:16,  6.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 636/824 [1:05:35<20:02,  6.40s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 636/824 [1:05:41<20:02,  6.40s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 637/824 [1:05:41<19:54,  6.39s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 637/824 [1:05:48<19:54,  6.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 638/824 [1:05:48<19:49,  6.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 638/824 [1:05:54<19:49,  6.39s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 639/824 [1:05:54<19:48,  6.43s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 639/824 [1:06:01<19:48,  6.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 640/824 [1:06:01<19:45,  6.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 640/824 [1:06:07<19:45,  6.44s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 641/824 [1:06:07<19:48,  6.49s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 641/824 [1:06:14<19:48,  6.49s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 642/824 [1:06:14<19:55,  6.57s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 642/824 [1:06:21<19:55,  6.57s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 643/824 [1:06:21<20:02,  6.65s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 643/824 [1:06:28<20:02,  6.65s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 644/824 [1:06:28<20:13,  6.74s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 644/824 [1:06:35<20:13,  6.74s/it, training_loss=0.430]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 645/824 [1:06:35<20:28,  6.86s/it, training_loss=0.430]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 645/824 [1:06:42<20:28,  6.86s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 646/824 [1:06:42<20:38,  6.96s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 646/824 [1:06:49<20:38,  6.96s/it, training_loss=0.378]\u001b[A\n",
      "Epoch 2:  79%|███████▊  | 647/824 [1:06:49<20:43,  7.02s/it, training_loss=0.378]\u001b[A\n",
      "Epoch 2:  79%|███████▊  | 647/824 [1:06:56<20:43,  7.02s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  79%|███████▊  | 648/824 [1:06:56<20:27,  6.97s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  79%|███████▊  | 648/824 [1:07:03<20:27,  6.97s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 649/824 [1:07:03<20:03,  6.88s/it, training_loss=0.244]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 649/824 [1:07:09<20:03,  6.88s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 650/824 [1:07:09<19:33,  6.75s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 650/824 [1:07:16<19:33,  6.75s/it, training_loss=0.110]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 651/824 [1:07:16<19:14,  6.67s/it, training_loss=0.110]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 651/824 [1:07:22<19:14,  6.67s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 652/824 [1:07:22<18:56,  6.61s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 652/824 [1:07:29<18:56,  6.61s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 653/824 [1:07:29<18:42,  6.56s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 653/824 [1:07:35<18:42,  6.56s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 654/824 [1:07:35<18:24,  6.50s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 654/824 [1:07:42<18:24,  6.50s/it, training_loss=0.100]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 655/824 [1:07:42<18:21,  6.52s/it, training_loss=0.100]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 655/824 [1:07:48<18:21,  6.52s/it, training_loss=0.053]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 656/824 [1:07:48<18:22,  6.56s/it, training_loss=0.053]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 656/824 [1:07:55<18:22,  6.56s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 657/824 [1:07:55<18:38,  6.70s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 657/824 [1:08:04<18:38,  6.70s/it, training_loss=0.134]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 658/824 [1:08:04<20:34,  7.44s/it, training_loss=0.134]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 658/824 [1:08:13<20:34,  7.44s/it, training_loss=0.526]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 659/824 [1:08:13<21:00,  7.64s/it, training_loss=0.526]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 659/824 [1:08:21<21:00,  7.64s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 2:  80%|████████  | 660/824 [1:08:21<21:40,  7.93s/it, training_loss=0.059]\u001b[A\n",
      "Epoch 2:  80%|████████  | 660/824 [1:08:30<21:40,  7.93s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 2:  80%|████████  | 661/824 [1:08:30<22:12,  8.17s/it, training_loss=0.264]\u001b[A\n",
      "Epoch 2:  80%|████████  | 661/824 [1:08:38<22:12,  8.17s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  80%|████████  | 662/824 [1:08:38<21:55,  8.12s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  80%|████████  | 662/824 [1:08:45<21:55,  8.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  80%|████████  | 663/824 [1:08:45<21:11,  7.90s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  80%|████████  | 663/824 [1:08:52<21:11,  7.90s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 2:  81%|████████  | 664/824 [1:08:52<20:10,  7.56s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 2:  81%|████████  | 664/824 [1:08:59<20:10,  7.56s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  81%|████████  | 665/824 [1:08:59<19:14,  7.26s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  81%|████████  | 665/824 [1:09:05<19:14,  7.26s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  81%|████████  | 666/824 [1:09:05<18:23,  6.98s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  81%|████████  | 666/824 [1:09:11<18:23,  6.98s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  81%|████████  | 667/824 [1:09:11<17:43,  6.77s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 2:  81%|████████  | 667/824 [1:09:17<17:43,  6.77s/it, training_loss=0.679]\u001b[A\n",
      "Epoch 2:  81%|████████  | 668/824 [1:09:18<17:13,  6.63s/it, training_loss=0.679]\u001b[A\n",
      "Epoch 2:  81%|████████  | 668/824 [1:09:24<17:13,  6.63s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  81%|████████  | 669/824 [1:09:24<16:51,  6.52s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  81%|████████  | 669/824 [1:09:31<16:51,  6.52s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  81%|████████▏ | 670/824 [1:09:31<16:54,  6.59s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  81%|████████▏ | 670/824 [1:09:37<16:54,  6.59s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  81%|████████▏ | 671/824 [1:09:37<16:57,  6.65s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  81%|████████▏ | 671/824 [1:09:44<16:57,  6.65s/it, training_loss=0.080]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 672/824 [1:09:44<17:02,  6.73s/it, training_loss=0.080]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 672/824 [1:09:51<17:02,  6.73s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 673/824 [1:09:51<17:17,  6.87s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 673/824 [1:09:59<17:17,  6.87s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 674/824 [1:09:59<17:39,  7.07s/it, training_loss=0.304]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 674/824 [1:10:06<17:39,  7.07s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 675/824 [1:10:06<17:48,  7.17s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 675/824 [1:10:14<17:48,  7.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 676/824 [1:10:14<17:56,  7.27s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 676/824 [1:10:21<17:56,  7.27s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 677/824 [1:10:21<18:02,  7.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 677/824 [1:10:29<18:02,  7.36s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 678/824 [1:10:29<18:10,  7.47s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 678/824 [1:10:37<18:10,  7.47s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 679/824 [1:10:37<18:02,  7.46s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 679/824 [1:10:44<18:02,  7.46s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 680/824 [1:10:44<17:41,  7.37s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 680/824 [1:10:51<17:41,  7.37s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 681/824 [1:10:51<17:09,  7.20s/it, training_loss=0.002]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  83%|████████▎ | 681/824 [1:10:57<17:09,  7.20s/it, training_loss=0.427]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 682/824 [1:10:57<16:44,  7.07s/it, training_loss=0.427]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 682/824 [1:11:04<16:44,  7.07s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 683/824 [1:11:04<16:24,  6.98s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 683/824 [1:11:11<16:24,  6.98s/it, training_loss=0.203]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 684/824 [1:11:11<16:05,  6.89s/it, training_loss=0.203]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 684/824 [1:11:18<16:05,  6.89s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 685/824 [1:11:18<15:51,  6.85s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 685/824 [1:11:24<15:51,  6.85s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 686/824 [1:11:24<15:45,  6.85s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 686/824 [1:11:31<15:45,  6.85s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 687/824 [1:11:31<15:36,  6.83s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 687/824 [1:11:38<15:36,  6.83s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 688/824 [1:11:38<15:24,  6.79s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 688/824 [1:11:45<15:24,  6.79s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 2:  84%|████████▎ | 689/824 [1:11:45<15:23,  6.84s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 2:  84%|████████▎ | 689/824 [1:11:52<15:23,  6.84s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 2:  84%|████████▎ | 690/824 [1:11:52<15:26,  6.91s/it, training_loss=0.296]\u001b[A\n",
      "Epoch 2:  84%|████████▎ | 690/824 [1:11:59<15:26,  6.91s/it, training_loss=0.060]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 691/824 [1:11:59<15:31,  7.01s/it, training_loss=0.060]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 691/824 [1:12:06<15:31,  7.01s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 692/824 [1:12:06<15:35,  7.09s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 692/824 [1:12:14<15:35,  7.09s/it, training_loss=0.247]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 693/824 [1:12:14<15:34,  7.13s/it, training_loss=0.247]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 693/824 [1:12:21<15:34,  7.13s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 694/824 [1:12:21<15:40,  7.23s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 694/824 [1:12:28<15:40,  7.23s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 695/824 [1:12:28<15:35,  7.26s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 695/824 [1:12:36<15:35,  7.26s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 696/824 [1:12:36<15:25,  7.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 696/824 [1:12:43<15:25,  7.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 697/824 [1:12:43<15:12,  7.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 697/824 [1:12:50<15:12,  7.19s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 698/824 [1:12:50<15:00,  7.15s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 698/824 [1:12:57<15:00,  7.15s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 699/824 [1:12:57<14:51,  7.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 699/824 [1:13:04<14:51,  7.13s/it, training_loss=0.050]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 700/824 [1:13:04<14:41,  7.11s/it, training_loss=0.050]\u001b[A\n",
      "Epoch 2:  85%|████████▍ | 700/824 [1:13:11<14:41,  7.11s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 701/824 [1:13:11<14:32,  7.09s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 701/824 [1:13:18<14:32,  7.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 702/824 [1:13:18<14:32,  7.15s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 702/824 [1:13:26<14:32,  7.15s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 703/824 [1:13:26<14:29,  7.18s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 703/824 [1:13:33<14:29,  7.18s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 704/824 [1:13:33<14:27,  7.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 704/824 [1:13:40<14:27,  7.23s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 705/824 [1:13:40<14:32,  7.33s/it, training_loss=0.351]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 705/824 [1:13:48<14:32,  7.33s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 706/824 [1:13:48<14:28,  7.36s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 706/824 [1:13:55<14:28,  7.36s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 707/824 [1:13:55<14:09,  7.26s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 707/824 [1:14:02<14:09,  7.26s/it, training_loss=0.133]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 708/824 [1:14:02<13:48,  7.14s/it, training_loss=0.133]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 708/824 [1:14:09<13:48,  7.14s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 709/824 [1:14:09<13:29,  7.04s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 709/824 [1:14:15<13:29,  7.04s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 710/824 [1:14:15<13:17,  6.99s/it, training_loss=0.246]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 710/824 [1:14:22<13:17,  6.99s/it, training_loss=0.087]\u001b[A\n",
      "Epoch 2:  86%|████████▋ | 711/824 [1:14:22<13:10,  7.00s/it, training_loss=0.087]\u001b[A\n",
      "Epoch 2:  86%|████████▋ | 711/824 [1:14:29<13:10,  7.00s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  86%|████████▋ | 712/824 [1:14:29<13:04,  7.00s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  86%|████████▋ | 712/824 [1:14:37<13:04,  7.00s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 713/824 [1:14:37<13:05,  7.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 713/824 [1:14:44<13:05,  7.07s/it, training_loss=0.179]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 714/824 [1:14:44<13:05,  7.14s/it, training_loss=0.179]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 714/824 [1:14:51<13:05,  7.14s/it, training_loss=0.143]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 715/824 [1:14:51<13:05,  7.21s/it, training_loss=0.143]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 715/824 [1:14:59<13:05,  7.21s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 716/824 [1:14:59<13:07,  7.29s/it, training_loss=0.076]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 716/824 [1:15:06<13:07,  7.29s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 717/824 [1:15:06<13:02,  7.31s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 717/824 [1:15:13<13:02,  7.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 718/824 [1:15:13<12:54,  7.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 718/824 [1:15:21<12:54,  7.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 719/824 [1:15:21<12:47,  7.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 719/824 [1:15:28<12:47,  7.31s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 720/824 [1:15:28<12:46,  7.37s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 720/824 [1:15:36<12:46,  7.37s/it, training_loss=0.034]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 721/824 [1:15:36<12:47,  7.45s/it, training_loss=0.034]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 721/824 [1:15:44<12:47,  7.45s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 722/824 [1:15:44<12:44,  7.50s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 722/824 [1:15:52<12:44,  7.50s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 723/824 [1:15:52<13:08,  7.81s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 723/824 [1:16:00<13:08,  7.81s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 724/824 [1:16:01<13:18,  7.99s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 724/824 [1:16:09<13:18,  7.99s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 725/824 [1:16:09<13:18,  8.06s/it, training_loss=0.307]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 725/824 [1:16:17<13:18,  8.06s/it, training_loss=0.123]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 726/824 [1:16:17<13:21,  8.18s/it, training_loss=0.123]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 726/824 [1:16:25<13:21,  8.18s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 727/824 [1:16:25<13:07,  8.12s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 727/824 [1:16:33<13:07,  8.12s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 728/824 [1:16:33<12:43,  7.95s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 728/824 [1:16:40<12:43,  7.95s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 729/824 [1:16:40<12:09,  7.68s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 729/824 [1:16:47<12:09,  7.68s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  89%|████████▊ | 730/824 [1:16:47<11:40,  7.45s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  89%|████████▊ | 730/824 [1:16:53<11:40,  7.45s/it, training_loss=0.063]\u001b[A\n",
      "Epoch 2:  89%|████████▊ | 731/824 [1:16:53<11:08,  7.19s/it, training_loss=0.063]\u001b[A\n",
      "Epoch 2:  89%|████████▊ | 731/824 [1:17:00<11:08,  7.19s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 732/824 [1:17:00<10:41,  6.97s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 732/824 [1:17:06<10:41,  6.97s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 733/824 [1:17:06<10:21,  6.83s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 733/824 [1:17:13<10:21,  6.83s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 734/824 [1:17:13<10:01,  6.69s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 734/824 [1:17:19<10:01,  6.69s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 735/824 [1:17:19<09:53,  6.67s/it, training_loss=0.049]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 735/824 [1:17:26<09:53,  6.67s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 736/824 [1:17:26<09:48,  6.69s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 736/824 [1:17:33<09:48,  6.69s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 737/824 [1:17:33<09:52,  6.81s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 737/824 [1:17:40<09:52,  6.81s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 738/824 [1:17:40<10:01,  6.99s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 738/824 [1:17:48<10:01,  6.99s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 739/824 [1:17:48<10:04,  7.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 739/824 [1:17:56<10:04,  7.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 740/824 [1:17:56<10:11,  7.28s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 740/824 [1:18:03<10:11,  7.28s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 741/824 [1:18:03<10:01,  7.25s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 741/824 [1:18:10<10:01,  7.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 742/824 [1:18:10<09:45,  7.14s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 742/824 [1:18:16<09:45,  7.14s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 743/824 [1:18:16<09:28,  7.02s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 743/824 [1:18:23<09:28,  7.02s/it, training_loss=0.372]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 744/824 [1:18:23<09:13,  6.92s/it, training_loss=0.372]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 744/824 [1:18:30<09:13,  6.92s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 745/824 [1:18:30<09:02,  6.87s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  90%|█████████ | 745/824 [1:18:37<09:02,  6.87s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 746/824 [1:18:37<08:58,  6.90s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 746/824 [1:18:44<08:58,  6.90s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 747/824 [1:18:44<08:59,  7.00s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 747/824 [1:18:51<08:59,  7.00s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 748/824 [1:18:51<09:03,  7.15s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 748/824 [1:18:59<09:03,  7.15s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 749/824 [1:18:59<09:02,  7.24s/it, training_loss=0.318]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 749/824 [1:19:07<09:02,  7.24s/it, training_loss=0.559]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 750/824 [1:19:07<09:14,  7.49s/it, training_loss=0.559]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 750/824 [1:19:15<09:14,  7.49s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 751/824 [1:19:15<09:10,  7.55s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 751/824 [1:19:23<09:10,  7.55s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  91%|█████████▏| 752/824 [1:19:23<09:11,  7.66s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 2:  91%|█████████▏| 752/824 [1:19:31<09:11,  7.66s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 2:  91%|█████████▏| 753/824 [1:19:31<09:18,  7.87s/it, training_loss=0.204]\u001b[A\n",
      "Epoch 2:  91%|█████████▏| 753/824 [1:19:41<09:18,  7.87s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 754/824 [1:19:41<10:00,  8.58s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 754/824 [1:19:49<10:00,  8.58s/it, training_loss=0.148]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 755/824 [1:19:49<09:44,  8.47s/it, training_loss=0.148]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 755/824 [1:19:57<09:44,  8.47s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 756/824 [1:19:57<09:08,  8.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 756/824 [1:20:03<09:08,  8.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 757/824 [1:20:03<08:31,  7.63s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 757/824 [1:20:09<08:31,  7.63s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 758/824 [1:20:09<07:56,  7.23s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 758/824 [1:20:15<07:56,  7.23s/it, training_loss=0.028]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 759/824 [1:20:15<07:19,  6.76s/it, training_loss=0.028]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 759/824 [1:20:21<07:19,  6.76s/it, training_loss=0.415]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 760/824 [1:20:21<06:58,  6.54s/it, training_loss=0.415]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 760/824 [1:20:27<06:58,  6.54s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 761/824 [1:20:27<06:48,  6.48s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 761/824 [1:20:34<06:48,  6.48s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 762/824 [1:20:34<06:37,  6.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 762/824 [1:20:40<06:37,  6.42s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 763/824 [1:20:40<06:20,  6.24s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 763/824 [1:20:46<06:20,  6.24s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 764/824 [1:20:46<06:09,  6.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 764/824 [1:20:52<06:09,  6.16s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 765/824 [1:20:52<06:03,  6.16s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 765/824 [1:20:58<06:03,  6.16s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 766/824 [1:20:58<06:02,  6.25s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 766/824 [1:21:04<06:02,  6.25s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 767/824 [1:21:04<05:53,  6.20s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 767/824 [1:21:10<05:53,  6.20s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 768/824 [1:21:10<05:38,  6.05s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 768/824 [1:21:15<05:38,  6.05s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 769/824 [1:21:16<05:24,  5.90s/it, training_loss=0.327]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 769/824 [1:21:22<05:24,  5.90s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 770/824 [1:21:22<05:22,  5.97s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 770/824 [1:21:28<05:22,  5.97s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 2:  94%|█████████▎| 771/824 [1:21:28<05:15,  5.96s/it, training_loss=0.272]\u001b[A\n",
      "Epoch 2:  94%|█████████▎| 771/824 [1:21:33<05:15,  5.96s/it, training_loss=0.050]\u001b[A\n",
      "Epoch 2:  94%|█████████▎| 772/824 [1:21:33<05:03,  5.83s/it, training_loss=0.050]\u001b[A\n",
      "Epoch 2:  94%|█████████▎| 772/824 [1:21:39<05:03,  5.83s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 773/824 [1:21:39<04:54,  5.78s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 773/824 [1:21:44<04:54,  5.78s/it, training_loss=0.218]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 774/824 [1:21:44<04:47,  5.75s/it, training_loss=0.218]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 774/824 [1:21:50<04:47,  5.75s/it, training_loss=0.056]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 775/824 [1:21:50<04:42,  5.77s/it, training_loss=0.056]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 775/824 [1:21:56<04:42,  5.77s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 776/824 [1:21:56<04:40,  5.84s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 776/824 [1:22:02<04:40,  5.84s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 777/824 [1:22:02<04:32,  5.79s/it, training_loss=0.330]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  94%|█████████▍| 777/824 [1:22:07<04:32,  5.79s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 778/824 [1:22:07<04:23,  5.72s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 778/824 [1:22:13<04:23,  5.72s/it, training_loss=0.407]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 779/824 [1:22:13<04:17,  5.71s/it, training_loss=0.407]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 779/824 [1:22:19<04:17,  5.71s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 780/824 [1:22:19<04:10,  5.70s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 780/824 [1:22:24<04:10,  5.70s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 781/824 [1:22:25<04:04,  5.69s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 781/824 [1:22:30<04:04,  5.69s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 782/824 [1:22:30<03:58,  5.69s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 782/824 [1:22:36<03:58,  5.69s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 783/824 [1:22:36<03:52,  5.66s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 783/824 [1:22:41<03:52,  5.66s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 784/824 [1:22:41<03:46,  5.66s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 784/824 [1:22:48<03:46,  5.66s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 785/824 [1:22:48<03:49,  5.90s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 785/824 [1:22:54<03:49,  5.90s/it, training_loss=0.080]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 786/824 [1:22:54<03:44,  5.92s/it, training_loss=0.080]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 786/824 [1:23:00<03:44,  5.92s/it, training_loss=0.390]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 787/824 [1:23:00<03:37,  5.87s/it, training_loss=0.390]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 787/824 [1:23:05<03:37,  5.87s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 788/824 [1:23:05<03:27,  5.76s/it, training_loss=0.064]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 788/824 [1:23:11<03:27,  5.76s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 789/824 [1:23:11<03:23,  5.82s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 789/824 [1:23:17<03:23,  5.82s/it, training_loss=0.089]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 790/824 [1:23:17<03:16,  5.77s/it, training_loss=0.089]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 790/824 [1:23:22<03:16,  5.77s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 791/824 [1:23:22<03:08,  5.70s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 791/824 [1:23:28<03:08,  5.70s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 792/824 [1:23:28<03:00,  5.63s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 792/824 [1:23:33<03:00,  5.63s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 793/824 [1:23:33<02:53,  5.59s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 793/824 [1:23:39<02:53,  5.59s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  96%|█████████▋| 794/824 [1:23:39<02:47,  5.59s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 2:  96%|█████████▋| 794/824 [1:23:45<02:47,  5.59s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|█████████▋| 795/824 [1:23:45<02:47,  5.76s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  96%|█████████▋| 795/824 [1:23:51<02:47,  5.76s/it, training_loss=0.029]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 796/824 [1:23:51<02:44,  5.88s/it, training_loss=0.029]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 796/824 [1:23:57<02:44,  5.88s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 797/824 [1:23:57<02:39,  5.89s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 797/824 [1:24:03<02:39,  5.89s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 798/824 [1:24:03<02:31,  5.83s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 798/824 [1:24:08<02:31,  5.83s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 799/824 [1:24:08<02:24,  5.78s/it, training_loss=0.289]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 799/824 [1:24:14<02:24,  5.78s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 800/824 [1:24:14<02:17,  5.74s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 800/824 [1:24:20<02:17,  5.74s/it, training_loss=0.112]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 801/824 [1:24:20<02:11,  5.70s/it, training_loss=0.112]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 801/824 [1:24:25<02:11,  5.70s/it, training_loss=0.172]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 802/824 [1:24:25<02:05,  5.70s/it, training_loss=0.172]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 802/824 [1:24:31<02:05,  5.70s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 803/824 [1:24:31<01:59,  5.69s/it, training_loss=0.360]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 803/824 [1:24:37<01:59,  5.69s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 804/824 [1:24:37<01:54,  5.74s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 804/824 [1:24:43<01:54,  5.74s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 805/824 [1:24:43<01:49,  5.76s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 805/824 [1:24:48<01:49,  5.76s/it, training_loss=0.110]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 806/824 [1:24:48<01:42,  5.69s/it, training_loss=0.110]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 806/824 [1:24:54<01:42,  5.69s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 807/824 [1:24:54<01:38,  5.81s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 807/824 [1:25:00<01:38,  5.81s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 808/824 [1:25:00<01:33,  5.85s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 808/824 [1:25:06<01:33,  5.85s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 809/824 [1:25:06<01:25,  5.73s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 809/824 [1:25:12<01:25,  5.73s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 810/824 [1:25:12<01:20,  5.76s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 810/824 [1:25:17<01:20,  5.76s/it, training_loss=0.159]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 811/824 [1:25:17<01:14,  5.77s/it, training_loss=0.159]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 811/824 [1:25:23<01:14,  5.77s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|█████████▊| 812/824 [1:25:23<01:09,  5.79s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|█████████▊| 812/824 [1:25:29<01:09,  5.79s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|█████████▊| 813/824 [1:25:29<01:04,  5.88s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|█████████▊| 813/824 [1:25:35<01:04,  5.88s/it, training_loss=0.213]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 814/824 [1:25:35<00:57,  5.78s/it, training_loss=0.213]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 814/824 [1:25:40<00:57,  5.78s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 815/824 [1:25:40<00:51,  5.71s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 815/824 [1:25:46<00:51,  5.71s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 816/824 [1:25:46<00:45,  5.66s/it, training_loss=0.279]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 816/824 [1:25:51<00:45,  5.66s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 817/824 [1:25:51<00:38,  5.54s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 817/824 [1:25:56<00:38,  5.54s/it, training_loss=0.774]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 818/824 [1:25:56<00:32,  5.46s/it, training_loss=0.774]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 818/824 [1:26:02<00:32,  5.46s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 819/824 [1:26:02<00:26,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 819/824 [1:26:07<00:26,  5.39s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 820/824 [1:26:07<00:21,  5.34s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 820/824 [1:26:12<00:21,  5.34s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 821/824 [1:26:12<00:15,  5.31s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 821/824 [1:26:17<00:15,  5.31s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 822/824 [1:26:17<00:10,  5.29s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 822/824 [1:26:23<00:10,  5.29s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 823/824 [1:26:23<00:05,  5.27s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 2: 100%|█████████▉| 823/824 [1:26:27<00:05,  5.27s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 2: 100%|██████████| 824/824 [1:26:27<00:00,  5.07s/it, training_loss=0.001]\u001b[A\n",
      " 33%|███▎      | 1/3 [2:47:27<2:41:54, 4857.09s/it]                              \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Training loss: 0.2531573728297145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [2:50:51<1:26:13, 5173.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.48647358069078334\n",
      "F1 Score (Weighted): 0.8799487348929824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3:   0%|          | 0/824 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:   0%|          | 0/824 [00:05<?, ?it/s, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   0%|          | 1/824 [00:05<1:14:29,  5.43s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   0%|          | 1/824 [00:10<1:14:29,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   0%|          | 2/824 [00:10<1:13:33,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   0%|          | 2/824 [00:16<1:13:33,  5.37s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:   0%|          | 3/824 [00:16<1:12:44,  5.32s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:   0%|          | 3/824 [00:21<1:12:44,  5.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   0%|          | 4/824 [00:21<1:13:30,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   0%|          | 4/824 [00:27<1:13:30,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|          | 5/824 [00:27<1:14:28,  5.46s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|          | 5/824 [00:32<1:14:28,  5.46s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|          | 6/824 [00:32<1:14:09,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|          | 6/824 [00:37<1:14:09,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|          | 7/824 [00:37<1:14:13,  5.45s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|          | 7/824 [00:43<1:14:13,  5.45s/it, training_loss=0.101]\u001b[A\n",
      "Epoch 3:   1%|          | 8/824 [00:43<1:13:59,  5.44s/it, training_loss=0.101]\u001b[A\n",
      "Epoch 3:   1%|          | 8/824 [00:48<1:13:59,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|          | 9/824 [00:48<1:13:28,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|          | 9/824 [00:54<1:13:28,  5.41s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 3:   1%|          | 10/824 [00:54<1:13:46,  5.44s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 3:   1%|          | 10/824 [00:59<1:13:46,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|▏         | 11/824 [00:59<1:13:41,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|▏         | 11/824 [01:05<1:13:41,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|▏         | 12/824 [01:05<1:13:57,  5.46s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   1%|▏         | 12/824 [01:10<1:13:57,  5.46s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   2%|▏         | 13/824 [01:10<1:13:04,  5.41s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   2%|▏         | 13/824 [01:15<1:13:04,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   2%|▏         | 14/824 [01:15<1:13:07,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   2%|▏         | 14/824 [01:21<1:13:07,  5.42s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   2%|▏         | 15/824 [01:21<1:13:27,  5.45s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   2%|▏         | 15/824 [01:26<1:13:27,  5.45s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   2%|▏         | 16/824 [01:26<1:12:58,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   2%|▏         | 16/824 [01:32<1:12:58,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   2%|▏         | 17/824 [01:32<1:13:40,  5.48s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   2%|▏         | 17/824 [01:37<1:13:40,  5.48s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 3:   2%|▏         | 18/824 [01:37<1:13:21,  5.46s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 3:   2%|▏         | 18/824 [01:43<1:13:21,  5.46s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   2%|▏         | 19/824 [01:43<1:12:32,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   2%|▏         | 19/824 [01:48<1:12:32,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   2%|▏         | 20/824 [01:48<1:12:48,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   2%|▏         | 20/824 [01:54<1:12:48,  5.43s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:   3%|▎         | 21/824 [01:54<1:13:19,  5.48s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:   3%|▎         | 21/824 [01:59<1:13:19,  5.48s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   3%|▎         | 22/824 [01:59<1:12:46,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   3%|▎         | 22/824 [02:04<1:12:46,  5.44s/it, training_loss=0.198]\u001b[A\n",
      "Epoch 3:   3%|▎         | 23/824 [02:04<1:11:10,  5.33s/it, training_loss=0.198]\u001b[A\n",
      "Epoch 3:   3%|▎         | 23/824 [02:09<1:11:10,  5.33s/it, training_loss=0.056]\u001b[A\n",
      "Epoch 3:   3%|▎         | 24/824 [02:09<1:09:58,  5.25s/it, training_loss=0.056]\u001b[A\n",
      "Epoch 3:   3%|▎         | 24/824 [02:14<1:09:58,  5.25s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   3%|▎         | 25/824 [02:14<1:09:37,  5.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   3%|▎         | 25/824 [02:19<1:09:37,  5.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   3%|▎         | 26/824 [02:19<1:08:55,  5.18s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   3%|▎         | 26/824 [02:25<1:08:55,  5.18s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   3%|▎         | 27/824 [02:25<1:09:41,  5.25s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   3%|▎         | 27/824 [02:30<1:09:41,  5.25s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   3%|▎         | 28/824 [02:30<1:10:18,  5.30s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   3%|▎         | 28/824 [02:36<1:10:18,  5.30s/it, training_loss=0.028]\u001b[A\n",
      "Epoch 3:   4%|▎         | 29/824 [02:36<1:10:57,  5.36s/it, training_loss=0.028]\u001b[A\n",
      "Epoch 3:   4%|▎         | 29/824 [02:41<1:10:57,  5.36s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:   4%|▎         | 30/824 [02:41<1:11:33,  5.41s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:   4%|▎         | 30/824 [02:47<1:11:33,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   4%|▍         | 31/824 [02:47<1:12:21,  5.47s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   4%|▍         | 31/824 [02:52<1:12:21,  5.47s/it, training_loss=0.160]\u001b[A\n",
      "Epoch 3:   4%|▍         | 32/824 [02:52<1:12:08,  5.47s/it, training_loss=0.160]\u001b[A\n",
      "Epoch 3:   4%|▍         | 32/824 [02:58<1:12:08,  5.47s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   4%|▍         | 33/824 [02:58<1:11:03,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   4%|▍         | 33/824 [03:03<1:11:03,  5.39s/it, training_loss=0.127]\u001b[A\n",
      "Epoch 3:   4%|▍         | 34/824 [03:03<1:09:52,  5.31s/it, training_loss=0.127]\u001b[A\n",
      "Epoch 3:   4%|▍         | 34/824 [03:08<1:09:52,  5.31s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   4%|▍         | 35/824 [03:08<1:08:44,  5.23s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   4%|▍         | 35/824 [03:13<1:08:44,  5.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   4%|▍         | 36/824 [03:13<1:08:39,  5.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   4%|▍         | 36/824 [03:18<1:08:39,  5.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   4%|▍         | 37/824 [03:18<1:08:07,  5.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   4%|▍         | 37/824 [03:23<1:08:07,  5.19s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   5%|▍         | 38/824 [03:23<1:08:26,  5.22s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   5%|▍         | 38/824 [03:29<1:08:26,  5.22s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 3:   5%|▍         | 39/824 [03:29<1:08:41,  5.25s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 3:   5%|▍         | 39/824 [03:34<1:08:41,  5.25s/it, training_loss=0.392]\u001b[A\n",
      "Epoch 3:   5%|▍         | 40/824 [03:34<1:07:59,  5.20s/it, training_loss=0.392]\u001b[A\n",
      "Epoch 3:   5%|▍         | 40/824 [03:39<1:07:59,  5.20s/it, training_loss=0.418]\u001b[A\n",
      "Epoch 3:   5%|▍         | 41/824 [03:39<1:07:29,  5.17s/it, training_loss=0.418]\u001b[A\n",
      "Epoch 3:   5%|▍         | 41/824 [03:44<1:07:29,  5.17s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 3:   5%|▌         | 42/824 [03:44<1:08:50,  5.28s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 3:   5%|▌         | 42/824 [03:50<1:08:50,  5.28s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   5%|▌         | 43/824 [03:50<1:09:42,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   5%|▌         | 43/824 [03:56<1:09:42,  5.36s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 3:   5%|▌         | 44/824 [03:56<1:11:46,  5.52s/it, training_loss=0.242]\u001b[A\n",
      "Epoch 3:   5%|▌         | 44/824 [04:01<1:11:46,  5.52s/it, training_loss=0.042]\u001b[A\n",
      "Epoch 3:   5%|▌         | 45/824 [04:01<1:09:54,  5.38s/it, training_loss=0.042]\u001b[A\n",
      "Epoch 3:   5%|▌         | 45/824 [04:06<1:09:54,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   6%|▌         | 46/824 [04:06<1:10:14,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   6%|▌         | 46/824 [04:12<1:10:14,  5.42s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 3:   6%|▌         | 47/824 [04:12<1:09:19,  5.35s/it, training_loss=0.258]\u001b[A\n",
      "Epoch 3:   6%|▌         | 47/824 [04:17<1:09:19,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   6%|▌         | 48/824 [04:17<1:09:48,  5.40s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   6%|▌         | 48/824 [04:23<1:09:48,  5.40s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   6%|▌         | 49/824 [04:23<1:09:53,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   6%|▌         | 49/824 [04:28<1:09:53,  5.41s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 3:   6%|▌         | 50/824 [04:28<1:10:21,  5.45s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 3:   6%|▌         | 50/824 [04:34<1:10:21,  5.45s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   6%|▌         | 51/824 [04:34<1:10:38,  5.48s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   6%|▌         | 51/824 [04:39<1:10:38,  5.48s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   6%|▋         | 52/824 [04:39<1:11:04,  5.52s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   6%|▋         | 52/824 [04:45<1:11:04,  5.52s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 3:   6%|▋         | 53/824 [04:45<1:11:12,  5.54s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 3:   6%|▋         | 53/824 [04:50<1:11:12,  5.54s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   7%|▋         | 54/824 [04:50<1:11:24,  5.56s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   7%|▋         | 54/824 [04:56<1:11:24,  5.56s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   7%|▋         | 55/824 [04:56<1:12:11,  5.63s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   7%|▋         | 55/824 [05:02<1:12:11,  5.63s/it, training_loss=0.050]\u001b[A\n",
      "Epoch 3:   7%|▋         | 56/824 [05:02<1:12:44,  5.68s/it, training_loss=0.050]\u001b[A\n",
      "Epoch 3:   7%|▋         | 56/824 [05:07<1:12:44,  5.68s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   7%|▋         | 57/824 [05:07<1:11:07,  5.56s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   7%|▋         | 57/824 [05:13<1:11:07,  5.56s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:   7%|▋         | 58/824 [05:13<1:10:35,  5.53s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:   7%|▋         | 58/824 [05:19<1:10:35,  5.53s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 3:   7%|▋         | 59/824 [05:19<1:11:18,  5.59s/it, training_loss=0.017]\u001b[A\n",
      "Epoch 3:   7%|▋         | 59/824 [05:24<1:11:18,  5.59s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 3:   7%|▋         | 60/824 [05:24<1:11:45,  5.64s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 3:   7%|▋         | 60/824 [05:30<1:11:45,  5.64s/it, training_loss=0.518]\u001b[A\n",
      "Epoch 3:   7%|▋         | 61/824 [05:30<1:10:48,  5.57s/it, training_loss=0.518]\u001b[A\n",
      "Epoch 3:   7%|▋         | 61/824 [05:35<1:10:48,  5.57s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   8%|▊         | 62/824 [05:35<1:09:56,  5.51s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   8%|▊         | 62/824 [05:40<1:09:56,  5.51s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   8%|▊         | 63/824 [05:40<1:09:22,  5.47s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   8%|▊         | 63/824 [05:46<1:09:22,  5.47s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   8%|▊         | 64/824 [05:46<1:09:31,  5.49s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   8%|▊         | 64/824 [05:51<1:09:31,  5.49s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:   8%|▊         | 65/824 [05:51<1:09:16,  5.48s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:   8%|▊         | 65/824 [05:57<1:09:16,  5.48s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 3:   8%|▊         | 66/824 [05:57<1:08:25,  5.42s/it, training_loss=0.016]\u001b[A\n",
      "Epoch 3:   8%|▊         | 66/824 [06:02<1:08:25,  5.42s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   8%|▊         | 67/824 [06:02<1:08:17,  5.41s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   8%|▊         | 67/824 [06:08<1:08:17,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   8%|▊         | 68/824 [06:08<1:10:02,  5.56s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   8%|▊         | 68/824 [06:13<1:10:02,  5.56s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   8%|▊         | 69/824 [06:13<1:09:30,  5.52s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   8%|▊         | 69/824 [06:19<1:09:30,  5.52s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   8%|▊         | 70/824 [06:19<1:09:52,  5.56s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   8%|▊         | 70/824 [06:24<1:09:52,  5.56s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   9%|▊         | 71/824 [06:24<1:08:01,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   9%|▊         | 71/824 [06:29<1:08:01,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   9%|▊         | 72/824 [06:29<1:07:08,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   9%|▊         | 72/824 [06:34<1:07:08,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   9%|▉         | 73/824 [06:34<1:06:10,  5.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   9%|▉         | 73/824 [06:40<1:06:10,  5.29s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:   9%|▉         | 74/824 [06:40<1:05:12,  5.22s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:   9%|▉         | 74/824 [06:45<1:05:12,  5.22s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   9%|▉         | 75/824 [06:45<1:04:26,  5.16s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   9%|▉         | 75/824 [06:50<1:04:26,  5.16s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   9%|▉         | 76/824 [06:50<1:04:00,  5.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:   9%|▉         | 76/824 [06:55<1:04:00,  5.13s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   9%|▉         | 77/824 [06:55<1:03:36,  5.11s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:   9%|▉         | 77/824 [07:00<1:03:36,  5.11s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 3:   9%|▉         | 78/824 [07:00<1:03:18,  5.09s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 3:   9%|▉         | 78/824 [07:05<1:03:18,  5.09s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  10%|▉         | 79/824 [07:05<1:03:05,  5.08s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  10%|▉         | 79/824 [07:10<1:03:05,  5.08s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  10%|▉         | 80/824 [07:10<1:02:48,  5.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  10%|▉         | 80/824 [07:15<1:02:48,  5.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  10%|▉         | 81/824 [07:15<1:02:45,  5.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  10%|▉         | 81/824 [07:20<1:02:45,  5.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  10%|▉         | 82/824 [07:20<1:02:56,  5.09s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  10%|▉         | 82/824 [07:26<1:02:56,  5.09s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  10%|█         | 83/824 [07:26<1:06:55,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  10%|█         | 83/824 [07:32<1:06:55,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  10%|█         | 84/824 [07:32<1:06:44,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  10%|█         | 84/824 [07:37<1:06:44,  5.41s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  10%|█         | 85/824 [07:37<1:05:19,  5.30s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  10%|█         | 85/824 [07:42<1:05:19,  5.30s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  10%|█         | 86/824 [07:42<1:04:37,  5.25s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  10%|█         | 86/824 [07:47<1:04:37,  5.25s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  11%|█         | 87/824 [07:47<1:04:23,  5.24s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  11%|█         | 87/824 [07:52<1:04:23,  5.24s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 3:  11%|█         | 88/824 [07:52<1:03:38,  5.19s/it, training_loss=0.249]\u001b[A\n",
      "Epoch 3:  11%|█         | 88/824 [07:57<1:03:38,  5.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  11%|█         | 89/824 [07:57<1:02:55,  5.14s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  11%|█         | 89/824 [08:02<1:02:55,  5.14s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 3:  11%|█         | 90/824 [08:02<1:02:24,  5.10s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 3:  11%|█         | 90/824 [08:07<1:02:24,  5.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  11%|█         | 91/824 [08:07<1:02:06,  5.08s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  11%|█         | 91/824 [08:12<1:02:06,  5.08s/it, training_loss=0.365]\u001b[A\n",
      "Epoch 3:  11%|█         | 92/824 [08:12<1:01:50,  5.07s/it, training_loss=0.365]\u001b[A\n",
      "Epoch 3:  11%|█         | 92/824 [08:17<1:01:50,  5.07s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  11%|█▏        | 93/824 [08:17<1:01:36,  5.06s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  11%|█▏        | 93/824 [08:22<1:01:36,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  11%|█▏        | 94/824 [08:22<1:01:32,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  11%|█▏        | 94/824 [08:27<1:01:32,  5.06s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 95/824 [08:27<1:01:27,  5.06s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 95/824 [08:32<1:01:27,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 96/824 [08:32<1:01:20,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 96/824 [08:37<1:01:20,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 97/824 [08:37<1:01:21,  5.06s/it, training_loss=0.001]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  12%|█▏        | 97/824 [08:43<1:01:21,  5.06s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 98/824 [08:43<1:01:19,  5.07s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 98/824 [08:48<1:01:19,  5.07s/it, training_loss=0.415]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 99/824 [08:48<1:01:14,  5.07s/it, training_loss=0.415]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 99/824 [08:53<1:01:14,  5.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 100/824 [08:53<1:01:15,  5.08s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 100/824 [08:58<1:01:15,  5.08s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 101/824 [08:58<1:01:01,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 101/824 [09:03<1:01:01,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 102/824 [09:03<1:00:51,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 102/824 [09:08<1:00:51,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  12%|█▎        | 103/824 [09:08<1:00:41,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  12%|█▎        | 103/824 [09:13<1:00:41,  5.05s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 104/824 [09:13<1:00:32,  5.05s/it, training_loss=0.354]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 104/824 [09:18<1:00:32,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 105/824 [09:18<1:00:25,  5.04s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 105/824 [09:23<1:00:25,  5.04s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 106/824 [09:23<1:00:22,  5.05s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 106/824 [09:28<1:00:22,  5.05s/it, training_loss=0.123]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 107/824 [09:28<1:00:16,  5.04s/it, training_loss=0.123]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 107/824 [09:33<1:00:16,  5.04s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 108/824 [09:33<1:00:25,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 108/824 [09:38<1:00:25,  5.06s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 109/824 [09:38<1:00:17,  5.06s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 109/824 [09:43<1:00:17,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 110/824 [09:43<1:00:12,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 110/824 [09:48<1:00:12,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 111/824 [09:48<1:00:04,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 111/824 [09:53<1:00:04,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  14%|█▎        | 112/824 [09:53<1:00:05,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  14%|█▎        | 112/824 [09:58<1:00:05,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  14%|█▎        | 113/824 [09:58<59:55,  5.06s/it, training_loss=0.001]  \u001b[A\n",
      "Epoch 3:  14%|█▎        | 113/824 [10:03<59:55,  5.06s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 114/824 [10:03<59:50,  5.06s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 114/824 [10:08<59:50,  5.06s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 115/824 [10:08<59:41,  5.05s/it, training_loss=0.228]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 115/824 [10:14<59:41,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 116/824 [10:14<59:37,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 116/824 [10:19<59:37,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 117/824 [10:19<59:28,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 117/824 [10:24<59:28,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 118/824 [10:24<59:30,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 118/824 [10:29<59:30,  5.06s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 119/824 [10:29<59:23,  5.05s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 119/824 [10:34<59:23,  5.05s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 120/824 [10:34<59:19,  5.06s/it, training_loss=0.292]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 120/824 [10:39<59:19,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 121/824 [10:39<59:14,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 121/824 [10:44<59:14,  5.06s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 122/824 [10:44<59:11,  5.06s/it, training_loss=0.196]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 122/824 [10:49<59:11,  5.06s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 123/824 [10:49<59:08,  5.06s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 123/824 [10:54<59:08,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  15%|█▌        | 124/824 [10:54<59:06,  5.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  15%|█▌        | 124/824 [10:59<59:06,  5.07s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  15%|█▌        | 125/824 [10:59<58:55,  5.06s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  15%|█▌        | 125/824 [11:04<58:55,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  15%|█▌        | 126/824 [11:04<58:46,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  15%|█▌        | 126/824 [11:09<58:46,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  15%|█▌        | 127/824 [11:09<58:38,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  15%|█▌        | 127/824 [11:14<58:38,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 128/824 [11:14<58:33,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 128/824 [11:19<58:33,  5.05s/it, training_loss=0.086]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 129/824 [11:19<58:31,  5.05s/it, training_loss=0.086]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 129/824 [11:24<58:31,  5.05s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 130/824 [11:24<58:30,  5.06s/it, training_loss=0.019]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 130/824 [11:29<58:30,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 131/824 [11:29<58:25,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 131/824 [11:34<58:25,  5.06s/it, training_loss=0.399]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 132/824 [11:34<58:18,  5.05s/it, training_loss=0.399]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 132/824 [11:39<58:18,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 133/824 [11:39<58:13,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 133/824 [11:45<58:13,  5.06s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  16%|█▋        | 134/824 [11:45<58:07,  5.05s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  16%|█▋        | 134/824 [11:50<58:07,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  16%|█▋        | 135/824 [11:50<58:03,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  16%|█▋        | 135/824 [11:55<58:03,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 136/824 [11:55<57:59,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 136/824 [12:00<57:59,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 137/824 [12:00<57:52,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 137/824 [12:05<57:52,  5.05s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 138/824 [12:05<57:47,  5.05s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 138/824 [12:10<57:47,  5.05s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 139/824 [12:10<57:41,  5.05s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 139/824 [12:15<57:41,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 140/824 [12:15<57:34,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 140/824 [12:20<57:34,  5.05s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 141/824 [12:20<57:34,  5.06s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 141/824 [12:25<57:34,  5.06s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 142/824 [12:25<57:26,  5.05s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 142/824 [12:30<57:26,  5.05s/it, training_loss=0.424]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 143/824 [12:30<57:21,  5.05s/it, training_loss=0.424]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 143/824 [12:35<57:21,  5.05s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 144/824 [12:35<57:22,  5.06s/it, training_loss=0.337]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 144/824 [12:40<57:22,  5.06s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 145/824 [12:40<57:13,  5.06s/it, training_loss=0.298]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 145/824 [12:45<57:13,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 146/824 [12:45<57:11,  5.06s/it, training_loss=0.001]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  18%|█▊        | 146/824 [12:50<57:11,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 147/824 [12:50<57:11,  5.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 147/824 [12:55<57:11,  5.07s/it, training_loss=0.505]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 148/824 [12:55<57:08,  5.07s/it, training_loss=0.505]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 148/824 [13:00<57:08,  5.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 149/824 [13:00<57:01,  5.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 149/824 [13:05<57:01,  5.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 150/824 [13:05<56:51,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 150/824 [13:11<56:51,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 151/824 [13:11<56:44,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 151/824 [13:16<56:44,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 152/824 [13:16<56:35,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 152/824 [13:21<56:35,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  19%|█▊        | 153/824 [13:21<56:36,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  19%|█▊        | 153/824 [13:26<56:36,  5.06s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  19%|█▊        | 154/824 [13:26<56:28,  5.06s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  19%|█▊        | 154/824 [13:31<56:28,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 155/824 [13:31<56:22,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 155/824 [13:36<56:22,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 156/824 [13:36<56:15,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 156/824 [13:41<56:15,  5.05s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 157/824 [13:41<56:08,  5.05s/it, training_loss=0.014]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 157/824 [13:46<56:08,  5.05s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 158/824 [13:46<56:01,  5.05s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 158/824 [13:51<56:01,  5.05s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 159/824 [13:51<56:08,  5.07s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 159/824 [13:56<56:08,  5.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 160/824 [13:56<55:59,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 160/824 [14:01<55:59,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 161/824 [14:01<55:52,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 161/824 [14:06<55:52,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 162/824 [14:06<55:43,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 162/824 [14:11<55:43,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 163/824 [14:11<55:39,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 163/824 [14:16<55:39,  5.05s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 164/824 [14:16<55:32,  5.05s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 164/824 [14:21<55:32,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  20%|██        | 165/824 [14:21<55:32,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  20%|██        | 165/824 [14:26<55:32,  5.06s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 3:  20%|██        | 166/824 [14:26<55:32,  5.06s/it, training_loss=0.015]\u001b[A\n",
      "Epoch 3:  20%|██        | 166/824 [14:31<55:32,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  20%|██        | 167/824 [14:31<55:34,  5.08s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  20%|██        | 167/824 [14:37<55:34,  5.08s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 3:  20%|██        | 168/824 [14:37<55:34,  5.08s/it, training_loss=0.052]\u001b[A\n",
      "Epoch 3:  20%|██        | 168/824 [14:42<55:34,  5.08s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  21%|██        | 169/824 [14:42<55:23,  5.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  21%|██        | 169/824 [14:47<55:23,  5.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  21%|██        | 170/824 [14:47<55:13,  5.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  21%|██        | 170/824 [14:52<55:13,  5.07s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  21%|██        | 171/824 [14:52<55:09,  5.07s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  21%|██        | 171/824 [14:57<55:09,  5.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  21%|██        | 172/824 [14:57<55:02,  5.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  21%|██        | 172/824 [15:02<55:02,  5.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  21%|██        | 173/824 [15:02<54:56,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  21%|██        | 173/824 [15:07<54:56,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  21%|██        | 174/824 [15:07<54:53,  5.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  21%|██        | 174/824 [15:12<54:53,  5.07s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  21%|██        | 175/824 [15:12<54:44,  5.06s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  21%|██        | 175/824 [15:17<54:44,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  21%|██▏       | 176/824 [15:17<54:37,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  21%|██▏       | 176/824 [15:22<54:37,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  21%|██▏       | 177/824 [15:22<54:34,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  21%|██▏       | 177/824 [15:27<54:34,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 178/824 [15:27<54:27,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 178/824 [15:32<54:27,  5.06s/it, training_loss=0.521]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 179/824 [15:32<54:18,  5.05s/it, training_loss=0.521]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 179/824 [15:37<54:18,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 180/824 [15:37<54:14,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 180/824 [15:42<54:14,  5.05s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 181/824 [15:42<54:10,  5.05s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 181/824 [15:47<54:10,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 182/824 [15:47<54:00,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 182/824 [15:52<54:00,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 183/824 [15:52<54:03,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 183/824 [15:57<54:03,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 184/824 [15:58<53:57,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 184/824 [16:03<53:57,  5.06s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 185/824 [16:03<54:06,  5.08s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 185/824 [16:08<54:06,  5.08s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 186/824 [16:08<53:56,  5.07s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 186/824 [16:13<53:56,  5.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 187/824 [16:13<53:42,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 187/824 [16:18<53:42,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 188/824 [16:18<53:33,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 188/824 [16:23<53:33,  5.05s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 189/824 [16:23<53:29,  5.05s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 189/824 [16:28<53:29,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 190/824 [16:28<53:20,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 190/824 [16:33<53:20,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 191/824 [16:33<53:16,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 191/824 [16:38<53:16,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 192/824 [16:38<53:13,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 192/824 [16:43<53:13,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 193/824 [16:43<53:13,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 193/824 [16:48<53:13,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  24%|██▎       | 194/824 [16:48<53:02,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  24%|██▎       | 194/824 [16:53<53:02,  5.05s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  24%|██▎       | 195/824 [16:53<53:52,  5.14s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  24%|██▎       | 195/824 [16:58<53:52,  5.14s/it, training_loss=0.121]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 196/824 [16:58<53:32,  5.12s/it, training_loss=0.121]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 196/824 [17:04<53:32,  5.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 197/824 [17:04<53:16,  5.10s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 197/824 [17:09<53:16,  5.10s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 198/824 [17:09<53:02,  5.08s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 198/824 [17:14<53:02,  5.08s/it, training_loss=0.391]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 199/824 [17:14<52:52,  5.08s/it, training_loss=0.391]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 199/824 [17:19<52:52,  5.08s/it, training_loss=0.384]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 200/824 [17:19<52:40,  5.07s/it, training_loss=0.384]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 200/824 [17:24<52:40,  5.07s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 201/824 [17:24<52:39,  5.07s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 201/824 [17:29<52:39,  5.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  25%|██▍       | 202/824 [17:29<52:30,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  25%|██▍       | 202/824 [17:34<52:30,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  25%|██▍       | 203/824 [17:34<52:12,  5.04s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  25%|██▍       | 203/824 [17:39<52:12,  5.04s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  25%|██▍       | 204/824 [17:39<52:08,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  25%|██▍       | 204/824 [17:44<52:08,  5.05s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  25%|██▍       | 205/824 [17:44<52:05,  5.05s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  25%|██▍       | 205/824 [17:49<52:05,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 206/824 [17:49<51:59,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 206/824 [17:54<51:59,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 207/824 [17:54<52:01,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 207/824 [17:59<52:01,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 208/824 [17:59<51:53,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 208/824 [18:04<51:53,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 209/824 [18:04<51:48,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 209/824 [18:09<51:48,  5.05s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 210/824 [18:09<51:43,  5.05s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 210/824 [18:14<51:43,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 211/824 [18:14<51:39,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 211/824 [18:19<51:39,  5.06s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 212/824 [18:19<51:32,  5.05s/it, training_loss=0.040]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 212/824 [18:24<51:32,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 213/824 [18:24<51:33,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 213/824 [18:29<51:33,  5.06s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 214/824 [18:29<51:25,  5.06s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 214/824 [18:34<51:25,  5.06s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 215/824 [18:34<51:22,  5.06s/it, training_loss=0.070]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 215/824 [18:40<51:22,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 216/824 [18:40<51:16,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 216/824 [18:45<51:16,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  26%|██▋       | 217/824 [18:45<51:10,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  26%|██▋       | 217/824 [18:50<51:10,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  26%|██▋       | 218/824 [18:50<51:05,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  26%|██▋       | 218/824 [18:55<51:05,  5.06s/it, training_loss=0.142]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 219/824 [18:55<51:00,  5.06s/it, training_loss=0.142]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 219/824 [19:00<51:00,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 220/824 [19:00<50:52,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 220/824 [19:05<50:52,  5.05s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 221/824 [19:05<50:45,  5.05s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 221/824 [19:10<50:45,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 222/824 [19:10<50:39,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 222/824 [19:15<50:39,  5.05s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 223/824 [19:15<50:35,  5.05s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 223/824 [19:20<50:35,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 224/824 [19:20<50:34,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 224/824 [19:25<50:34,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 225/824 [19:25<50:26,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 225/824 [19:30<50:26,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 226/824 [19:30<50:21,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 226/824 [19:35<50:21,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 227/824 [19:35<50:15,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 227/824 [19:40<50:15,  5.05s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 228/824 [19:40<50:09,  5.05s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 228/824 [19:45<50:09,  5.05s/it, training_loss=0.046]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 229/824 [19:45<50:04,  5.05s/it, training_loss=0.046]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 229/824 [19:51<50:04,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 230/824 [19:51<50:50,  5.14s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 230/824 [19:56<50:50,  5.14s/it, training_loss=0.406]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 231/824 [19:56<50:42,  5.13s/it, training_loss=0.406]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 231/824 [20:01<50:42,  5.13s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 232/824 [20:01<50:24,  5.11s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 232/824 [20:06<50:24,  5.11s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 233/824 [20:06<50:08,  5.09s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 233/824 [20:11<50:08,  5.09s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 234/824 [20:11<49:55,  5.08s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 234/824 [20:16<49:55,  5.08s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  29%|██▊       | 235/824 [20:16<49:43,  5.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  29%|██▊       | 235/824 [20:21<49:43,  5.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  29%|██▊       | 236/824 [20:21<49:53,  5.09s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  29%|██▊       | 236/824 [20:26<49:53,  5.09s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 237/824 [20:26<50:33,  5.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 237/824 [20:32<50:33,  5.17s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 238/824 [20:32<51:05,  5.23s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 238/824 [20:37<51:05,  5.23s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 239/824 [20:37<51:30,  5.28s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 239/824 [20:43<51:30,  5.28s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 240/824 [20:43<52:38,  5.41s/it, training_loss=0.024]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 240/824 [20:49<52:38,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 241/824 [20:49<54:48,  5.64s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 241/824 [20:55<54:48,  5.64s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 242/824 [20:55<55:32,  5.73s/it, training_loss=0.018]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 242/824 [21:01<55:32,  5.73s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 243/824 [21:01<55:04,  5.69s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 243/824 [21:06<55:04,  5.69s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 244/824 [21:06<54:34,  5.65s/it, training_loss=0.001]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  30%|██▉       | 244/824 [21:12<54:34,  5.65s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 245/824 [21:12<54:11,  5.62s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 245/824 [21:17<54:11,  5.62s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 246/824 [21:17<53:23,  5.54s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 246/824 [21:22<53:23,  5.54s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 247/824 [21:22<52:58,  5.51s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 247/824 [21:36<52:58,  5.51s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  30%|███       | 248/824 [21:36<1:15:06,  7.82s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  30%|███       | 248/824 [21:43<1:15:06,  7.82s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  30%|███       | 249/824 [21:43<1:14:41,  7.79s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  30%|███       | 249/824 [21:51<1:14:41,  7.79s/it, training_loss=0.043]\u001b[A\n",
      "Epoch 3:  30%|███       | 250/824 [21:51<1:14:57,  7.84s/it, training_loss=0.043]\u001b[A\n",
      "Epoch 3:  30%|███       | 250/824 [21:57<1:14:57,  7.84s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  30%|███       | 251/824 [21:57<1:08:10,  7.14s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  30%|███       | 251/824 [22:03<1:08:10,  7.14s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  31%|███       | 252/824 [22:03<1:04:25,  6.76s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  31%|███       | 252/824 [22:08<1:04:25,  6.76s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  31%|███       | 253/824 [22:08<1:01:18,  6.44s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  31%|███       | 253/824 [22:14<1:01:18,  6.44s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  31%|███       | 254/824 [22:14<58:53,  6.20s/it, training_loss=0.000]  \u001b[A\n",
      "Epoch 3:  31%|███       | 254/824 [22:20<58:53,  6.20s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  31%|███       | 255/824 [22:20<57:12,  6.03s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  31%|███       | 255/824 [22:26<57:12,  6.03s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  31%|███       | 256/824 [22:26<58:45,  6.21s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  31%|███       | 256/824 [22:32<58:45,  6.21s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  31%|███       | 257/824 [22:32<56:11,  5.95s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  31%|███       | 257/824 [22:37<56:11,  5.95s/it, training_loss=0.115]\u001b[A\n",
      "Epoch 3:  31%|███▏      | 258/824 [22:37<54:52,  5.82s/it, training_loss=0.115]\u001b[A\n",
      "Epoch 3:  31%|███▏      | 258/824 [22:43<54:52,  5.82s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  31%|███▏      | 259/824 [22:43<53:30,  5.68s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  31%|███▏      | 259/824 [22:48<53:30,  5.68s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 260/824 [22:48<52:47,  5.62s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 260/824 [22:54<52:47,  5.62s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 261/824 [22:54<52:39,  5.61s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 261/824 [22:59<52:39,  5.61s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 262/824 [22:59<51:50,  5.53s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 262/824 [23:04<51:50,  5.53s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 263/824 [23:04<51:20,  5.49s/it, training_loss=0.331]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 263/824 [23:10<51:20,  5.49s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 264/824 [23:10<50:48,  5.44s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 264/824 [23:15<50:48,  5.44s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 265/824 [23:15<50:26,  5.41s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 265/824 [23:20<50:26,  5.41s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 266/824 [23:20<50:09,  5.39s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 266/824 [23:26<50:09,  5.39s/it, training_loss=0.480]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 267/824 [23:26<49:54,  5.38s/it, training_loss=0.480]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 267/824 [23:31<49:54,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 268/824 [23:31<49:40,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 268/824 [23:36<49:40,  5.36s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 269/824 [23:36<49:34,  5.36s/it, training_loss=0.081]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 269/824 [23:42<49:34,  5.36s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 270/824 [23:42<49:43,  5.39s/it, training_loss=0.023]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 270/824 [23:47<49:43,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 271/824 [23:47<49:34,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 271/824 [23:52<49:34,  5.38s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 272/824 [23:52<49:11,  5.35s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 272/824 [23:58<49:11,  5.35s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 273/824 [23:58<49:08,  5.35s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 273/824 [24:03<49:08,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 274/824 [24:03<49:00,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 274/824 [24:08<49:00,  5.35s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 275/824 [24:08<48:52,  5.34s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 275/824 [24:14<48:52,  5.34s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 276/824 [24:14<48:48,  5.34s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 276/824 [24:19<48:48,  5.34s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▎      | 277/824 [24:19<48:59,  5.37s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  34%|███▎      | 277/824 [24:25<48:59,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  34%|███▎      | 278/824 [24:25<48:51,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  34%|███▎      | 278/824 [24:30<48:51,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 279/824 [24:30<48:47,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 279/824 [24:35<48:47,  5.37s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 280/824 [24:35<48:44,  5.38s/it, training_loss=0.012]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 280/824 [24:41<48:44,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 281/824 [24:41<48:32,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 281/824 [24:46<48:32,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 282/824 [24:46<48:25,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 282/824 [24:51<48:25,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 283/824 [24:51<48:17,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 283/824 [24:57<48:17,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 284/824 [24:57<48:18,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 284/824 [25:02<48:18,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  35%|███▍      | 285/824 [25:02<48:07,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  35%|███▍      | 285/824 [25:07<48:07,  5.36s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  35%|███▍      | 286/824 [25:07<47:56,  5.35s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  35%|███▍      | 286/824 [25:13<47:56,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  35%|███▍      | 287/824 [25:13<47:45,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  35%|███▍      | 287/824 [25:18<47:45,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  35%|███▍      | 288/824 [25:18<47:38,  5.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  35%|███▍      | 288/824 [25:23<47:38,  5.33s/it, training_loss=0.031]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 289/824 [25:23<47:33,  5.33s/it, training_loss=0.031]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 289/824 [25:29<47:33,  5.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 290/824 [25:29<47:27,  5.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 290/824 [25:34<47:27,  5.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 291/824 [25:34<47:20,  5.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 291/824 [25:39<47:20,  5.33s/it, training_loss=0.437]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 292/824 [25:39<47:14,  5.33s/it, training_loss=0.437]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 292/824 [25:45<47:14,  5.33s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 293/824 [25:45<48:22,  5.47s/it, training_loss=0.047]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 293/824 [25:57<48:22,  5.47s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 294/824 [25:57<1:05:19,  7.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 294/824 [26:03<1:05:19,  7.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 295/824 [26:03<1:01:04,  6.93s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 295/824 [26:09<1:01:04,  6.93s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 296/824 [26:09<58:04,  6.60s/it, training_loss=0.001]  \u001b[A\n",
      "Epoch 3:  36%|███▌      | 296/824 [26:15<58:04,  6.60s/it, training_loss=0.074]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 297/824 [26:15<55:43,  6.34s/it, training_loss=0.074]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 297/824 [26:20<55:43,  6.34s/it, training_loss=0.114]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 298/824 [26:20<53:32,  6.11s/it, training_loss=0.114]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 298/824 [26:26<53:32,  6.11s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  36%|███▋      | 299/824 [26:26<51:50,  5.93s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  36%|███▋      | 299/824 [26:31<51:50,  5.93s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 3:  36%|███▋      | 300/824 [26:31<50:42,  5.81s/it, training_loss=0.302]\u001b[A\n",
      "Epoch 3:  36%|███▋      | 300/824 [26:37<50:42,  5.81s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 301/824 [26:37<51:07,  5.87s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 301/824 [26:43<51:07,  5.87s/it, training_loss=0.182]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 302/824 [26:43<50:17,  5.78s/it, training_loss=0.182]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 302/824 [26:48<50:17,  5.78s/it, training_loss=0.056]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 303/824 [26:48<49:28,  5.70s/it, training_loss=0.056]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 303/824 [26:54<49:28,  5.70s/it, training_loss=0.148]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 304/824 [26:54<48:58,  5.65s/it, training_loss=0.148]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 304/824 [26:59<48:58,  5.65s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 305/824 [26:59<48:06,  5.56s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 305/824 [27:04<48:06,  5.56s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 306/824 [27:04<47:30,  5.50s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 306/824 [27:10<47:30,  5.50s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 307/824 [27:10<47:01,  5.46s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 307/824 [27:15<47:01,  5.46s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 308/824 [27:15<46:37,  5.42s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 308/824 [27:21<46:37,  5.42s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 309/824 [27:21<46:28,  5.41s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 309/824 [27:26<46:28,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 310/824 [27:26<46:13,  5.40s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 310/824 [27:31<46:13,  5.40s/it, training_loss=0.317]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 311/824 [27:31<45:57,  5.38s/it, training_loss=0.317]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 311/824 [27:37<45:57,  5.38s/it, training_loss=0.333]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 312/824 [27:37<45:44,  5.36s/it, training_loss=0.333]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 312/824 [27:42<45:44,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 313/824 [27:42<45:34,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 313/824 [27:47<45:34,  5.35s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 314/824 [27:47<45:27,  5.35s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 314/824 [27:53<45:27,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 315/824 [27:53<45:31,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 315/824 [27:58<45:31,  5.37s/it, training_loss=0.445]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 316/824 [27:58<45:25,  5.37s/it, training_loss=0.445]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 316/824 [28:03<45:25,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 317/824 [28:03<45:14,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 317/824 [28:09<45:14,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  39%|███▊      | 318/824 [28:09<45:13,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  39%|███▊      | 318/824 [28:14<45:13,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  39%|███▊      | 319/824 [28:14<45:09,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  39%|███▊      | 319/824 [28:19<45:09,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 320/824 [28:19<44:57,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 320/824 [28:25<44:57,  5.35s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 321/824 [28:25<44:53,  5.35s/it, training_loss=0.025]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 321/824 [28:30<44:53,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 322/824 [28:30<44:44,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 322/824 [28:35<44:44,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 323/824 [28:35<44:42,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 323/824 [28:41<44:42,  5.36s/it, training_loss=0.391]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 324/824 [28:41<44:36,  5.35s/it, training_loss=0.391]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 324/824 [28:46<44:36,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 325/824 [28:46<44:31,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 325/824 [28:52<44:31,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 326/824 [28:52<44:26,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 326/824 [28:57<44:26,  5.35s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 327/824 [28:57<44:20,  5.35s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 327/824 [29:02<44:20,  5.35s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 328/824 [29:02<44:14,  5.35s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 328/824 [29:08<44:14,  5.35s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 329/824 [29:08<44:16,  5.37s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 329/824 [29:13<44:16,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  40%|████      | 330/824 [29:13<44:12,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  40%|████      | 330/824 [29:18<44:12,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  40%|████      | 331/824 [29:18<44:04,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  40%|████      | 331/824 [29:24<44:04,  5.36s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  40%|████      | 332/824 [29:24<44:01,  5.37s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  40%|████      | 332/824 [29:29<44:01,  5.37s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  40%|████      | 333/824 [29:29<43:52,  5.36s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  40%|████      | 333/824 [29:34<43:52,  5.36s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 3:  41%|████      | 334/824 [29:34<43:43,  5.35s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 3:  41%|████      | 334/824 [29:40<43:43,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  41%|████      | 335/824 [29:40<43:41,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  41%|████      | 335/824 [29:45<43:41,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  41%|████      | 336/824 [29:45<43:32,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  41%|████      | 336/824 [29:51<43:32,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  41%|████      | 337/824 [29:51<43:28,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  41%|████      | 337/824 [29:56<43:28,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  41%|████      | 338/824 [29:56<43:24,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  41%|████      | 338/824 [30:01<43:24,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  41%|████      | 339/824 [30:01<43:21,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  41%|████      | 339/824 [30:07<43:21,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  41%|████▏     | 340/824 [30:07<43:25,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  41%|████▏     | 340/824 [30:12<43:25,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  41%|████▏     | 341/824 [30:12<43:31,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  41%|████▏     | 341/824 [30:18<43:31,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 342/824 [30:18<43:57,  5.47s/it, training_loss=0.001]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  42%|████▏     | 342/824 [30:23<43:57,  5.47s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 343/824 [30:23<43:42,  5.45s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 343/824 [30:29<43:42,  5.45s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 344/824 [30:29<43:22,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 344/824 [30:34<43:22,  5.42s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 345/824 [30:34<43:09,  5.41s/it, training_loss=0.357]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 345/824 [30:39<43:09,  5.41s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 346/824 [30:39<42:57,  5.39s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 346/824 [30:45<42:57,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 347/824 [30:45<42:48,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 347/824 [30:50<42:48,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 348/824 [30:50<42:21,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 348/824 [30:55<42:21,  5.34s/it, training_loss=0.200]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 349/824 [30:55<42:21,  5.35s/it, training_loss=0.200]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 349/824 [31:01<42:21,  5.35s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 350/824 [31:01<42:19,  5.36s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 350/824 [31:06<42:19,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 351/824 [31:06<42:16,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 351/824 [31:11<42:16,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 352/824 [31:11<42:11,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 352/824 [31:17<42:11,  5.36s/it, training_loss=0.373]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 353/824 [31:17<42:07,  5.37s/it, training_loss=0.373]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 353/824 [31:22<42:07,  5.37s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 354/824 [31:22<42:02,  5.37s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 354/824 [31:27<42:02,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 355/824 [31:27<41:58,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 355/824 [31:33<41:58,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 356/824 [31:33<41:49,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 356/824 [31:38<41:49,  5.36s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 357/824 [31:38<41:47,  5.37s/it, training_loss=0.322]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 357/824 [31:44<41:47,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 358/824 [31:44<41:44,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 358/824 [31:49<41:44,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  44%|████▎     | 359/824 [31:49<41:37,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  44%|████▎     | 359/824 [31:54<41:37,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  44%|████▎     | 360/824 [31:54<41:35,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  44%|████▎     | 360/824 [32:00<41:35,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 361/824 [32:00<41:25,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 361/824 [32:05<41:25,  5.37s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 362/824 [32:05<41:19,  5.37s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 362/824 [32:10<41:19,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 363/824 [32:10<41:14,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 363/824 [32:16<41:14,  5.37s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 364/824 [32:16<41:10,  5.37s/it, training_loss=0.315]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 364/824 [32:21<41:10,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 365/824 [32:21<41:04,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 365/824 [32:27<41:04,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 366/824 [32:27<40:58,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 366/824 [32:32<40:58,  5.37s/it, training_loss=0.141]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 367/824 [32:32<40:49,  5.36s/it, training_loss=0.141]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 367/824 [32:37<40:49,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 368/824 [32:37<40:49,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 368/824 [32:43<40:49,  5.37s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 369/824 [32:43<40:42,  5.37s/it, training_loss=0.276]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 369/824 [32:48<40:42,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 370/824 [32:48<40:33,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 370/824 [32:53<40:33,  5.36s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 371/824 [32:53<40:36,  5.38s/it, training_loss=0.326]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 371/824 [32:59<40:36,  5.38s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 372/824 [32:59<40:29,  5.38s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 372/824 [33:04<40:29,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 373/824 [33:04<40:25,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 373/824 [33:09<40:25,  5.38s/it, training_loss=0.068]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 374/824 [33:09<40:15,  5.37s/it, training_loss=0.068]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 374/824 [33:15<40:15,  5.37s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 375/824 [33:15<40:10,  5.37s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 375/824 [33:20<40:10,  5.37s/it, training_loss=0.167]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 376/824 [33:20<40:07,  5.37s/it, training_loss=0.167]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 376/824 [33:26<40:07,  5.37s/it, training_loss=0.385]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 377/824 [33:26<40:01,  5.37s/it, training_loss=0.385]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 377/824 [33:31<40:01,  5.37s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 378/824 [33:31<39:55,  5.37s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 378/824 [33:36<39:55,  5.37s/it, training_loss=0.401]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 379/824 [33:36<39:51,  5.37s/it, training_loss=0.401]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 379/824 [33:42<39:51,  5.37s/it, training_loss=0.062]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 380/824 [33:42<39:42,  5.37s/it, training_loss=0.062]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 380/824 [33:47<39:42,  5.37s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 381/824 [33:47<39:40,  5.37s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 381/824 [33:52<39:40,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  46%|████▋     | 382/824 [33:52<39:37,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  46%|████▋     | 382/824 [33:58<39:37,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  46%|████▋     | 383/824 [33:58<39:30,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  46%|████▋     | 383/824 [34:03<39:30,  5.37s/it, training_loss=0.067]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 384/824 [34:03<39:21,  5.37s/it, training_loss=0.067]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 384/824 [34:09<39:21,  5.37s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 385/824 [34:09<39:14,  5.36s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 385/824 [34:14<39:14,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 386/824 [34:14<39:09,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 386/824 [34:19<39:09,  5.36s/it, training_loss=0.031]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 387/824 [34:19<39:09,  5.38s/it, training_loss=0.031]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 387/824 [34:25<39:09,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 388/824 [34:25<39:52,  5.49s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 388/824 [34:30<39:52,  5.49s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 389/824 [34:30<39:35,  5.46s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 389/824 [34:36<39:35,  5.46s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 390/824 [34:36<39:22,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 390/824 [34:41<39:22,  5.44s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 391/824 [34:41<39:08,  5.42s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 391/824 [34:47<39:08,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 392/824 [34:47<38:54,  5.40s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 392/824 [34:52<38:54,  5.40s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 393/824 [34:52<38:48,  5.40s/it, training_loss=0.280]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 393/824 [34:57<38:48,  5.40s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 394/824 [34:57<38:38,  5.39s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 394/824 [35:03<38:38,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 395/824 [35:03<38:31,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 395/824 [35:08<38:31,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 396/824 [35:08<38:23,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 396/824 [35:13<38:23,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 397/824 [35:13<38:12,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 397/824 [35:19<38:12,  5.37s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 398/824 [35:19<38:07,  5.37s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 398/824 [35:24<38:07,  5.37s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 399/824 [35:24<38:06,  5.38s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 399/824 [35:30<38:06,  5.38s/it, training_loss=0.463]\u001b[A\n",
      "Epoch 3:  49%|████▊     | 400/824 [35:30<37:57,  5.37s/it, training_loss=0.463]\u001b[A\n",
      "Epoch 3:  49%|████▊     | 400/824 [35:35<37:57,  5.37s/it, training_loss=0.096]\u001b[A\n",
      "Epoch 3:  49%|████▊     | 401/824 [35:35<37:54,  5.38s/it, training_loss=0.096]\u001b[A\n",
      "Epoch 3:  49%|████▊     | 401/824 [35:40<37:54,  5.38s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 402/824 [35:40<37:46,  5.37s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 402/824 [35:46<37:46,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 403/824 [35:46<37:56,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 403/824 [35:51<37:56,  5.41s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 404/824 [35:51<37:53,  5.41s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 404/824 [35:56<37:53,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 405/824 [35:56<37:23,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 405/824 [36:02<37:23,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 406/824 [36:02<37:19,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 406/824 [36:07<37:19,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 407/824 [36:07<37:18,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 407/824 [36:13<37:18,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  50%|████▉     | 408/824 [36:13<37:14,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  50%|████▉     | 408/824 [36:18<37:14,  5.37s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  50%|████▉     | 409/824 [36:18<37:11,  5.38s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  50%|████▉     | 409/824 [36:23<37:11,  5.38s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  50%|████▉     | 410/824 [36:23<37:09,  5.39s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  50%|████▉     | 410/824 [36:29<37:09,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  50%|████▉     | 411/824 [36:29<37:03,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  50%|████▉     | 411/824 [36:34<37:03,  5.38s/it, training_loss=0.053]\u001b[A\n",
      "Epoch 3:  50%|█████     | 412/824 [36:34<36:57,  5.38s/it, training_loss=0.053]\u001b[A\n",
      "Epoch 3:  50%|█████     | 412/824 [36:40<36:57,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  50%|█████     | 413/824 [36:40<36:55,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  50%|█████     | 413/824 [36:45<36:55,  5.39s/it, training_loss=0.213]\u001b[A\n",
      "Epoch 3:  50%|█████     | 414/824 [36:45<36:45,  5.38s/it, training_loss=0.213]\u001b[A\n",
      "Epoch 3:  50%|█████     | 414/824 [36:50<36:45,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  50%|█████     | 415/824 [36:50<36:38,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  50%|█████     | 415/824 [36:56<36:38,  5.38s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  50%|█████     | 416/824 [36:56<36:34,  5.38s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  50%|█████     | 416/824 [37:01<36:34,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  51%|█████     | 417/824 [37:01<36:28,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  51%|█████     | 417/824 [37:06<36:28,  5.38s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  51%|█████     | 418/824 [37:06<36:19,  5.37s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  51%|█████     | 418/824 [37:12<36:19,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  51%|█████     | 419/824 [37:12<36:18,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  51%|█████     | 419/824 [37:17<36:18,  5.38s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 3:  51%|█████     | 420/824 [37:17<36:36,  5.44s/it, training_loss=0.287]\u001b[A\n",
      "Epoch 3:  51%|█████     | 420/824 [37:23<36:36,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  51%|█████     | 421/824 [37:23<36:22,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  51%|█████     | 421/824 [37:28<36:22,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  51%|█████     | 422/824 [37:28<36:08,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  51%|█████     | 422/824 [37:33<36:08,  5.39s/it, training_loss=0.380]\u001b[A\n",
      "Epoch 3:  51%|█████▏    | 423/824 [37:33<35:56,  5.38s/it, training_loss=0.380]\u001b[A\n",
      "Epoch 3:  51%|█████▏    | 423/824 [37:39<35:56,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  51%|█████▏    | 424/824 [37:39<35:44,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  51%|█████▏    | 424/824 [37:44<35:44,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 425/824 [37:44<35:38,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 425/824 [37:49<35:38,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 426/824 [37:49<35:31,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 426/824 [37:55<35:31,  5.36s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 427/824 [37:55<35:27,  5.36s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 427/824 [38:00<35:27,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 428/824 [38:00<35:20,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 428/824 [38:06<35:20,  5.36s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 429/824 [38:06<35:16,  5.36s/it, training_loss=0.057]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 429/824 [38:11<35:16,  5.36s/it, training_loss=0.382]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 430/824 [38:11<35:10,  5.36s/it, training_loss=0.382]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 430/824 [38:16<35:10,  5.36s/it, training_loss=0.407]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 431/824 [38:16<35:04,  5.35s/it, training_loss=0.407]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 431/824 [38:22<35:04,  5.35s/it, training_loss=0.208]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 432/824 [38:22<34:59,  5.36s/it, training_loss=0.208]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 432/824 [38:27<34:59,  5.36s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 433/824 [38:27<34:48,  5.34s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 433/824 [38:32<34:48,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 434/824 [38:32<34:45,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 434/824 [38:38<34:45,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 435/824 [38:38<34:44,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 435/824 [38:43<34:44,  5.36s/it, training_loss=0.187]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 436/824 [38:43<34:38,  5.36s/it, training_loss=0.187]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 436/824 [38:48<34:38,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 437/824 [38:48<34:34,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 437/824 [38:54<34:34,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 438/824 [38:54<34:48,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 438/824 [38:59<34:48,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 439/824 [38:59<34:38,  5.40s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 439/824 [39:05<34:38,  5.40s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 440/824 [39:05<34:18,  5.36s/it, training_loss=0.001]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  53%|█████▎    | 440/824 [39:10<34:18,  5.36s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  54%|█████▎    | 441/824 [39:10<34:04,  5.34s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  54%|█████▎    | 441/824 [39:15<34:04,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  54%|█████▎    | 442/824 [39:15<34:00,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  54%|█████▎    | 442/824 [39:20<34:00,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 443/824 [39:20<33:54,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 443/824 [39:26<33:54,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 444/824 [39:26<33:48,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 444/824 [39:31<33:48,  5.34s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 445/824 [39:31<33:45,  5.34s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 445/824 [39:37<33:45,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 446/824 [39:37<33:39,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 446/824 [39:42<33:39,  5.34s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 447/824 [39:42<33:33,  5.34s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 447/824 [39:47<33:33,  5.34s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 448/824 [39:47<33:27,  5.34s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 448/824 [39:52<33:27,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 449/824 [39:52<33:11,  5.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 449/824 [39:58<33:11,  5.31s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 450/824 [39:58<33:13,  5.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 450/824 [40:03<33:13,  5.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 451/824 [40:03<33:15,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 451/824 [40:09<33:15,  5.35s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 452/824 [40:09<33:10,  5.35s/it, training_loss=0.061]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 452/824 [40:14<33:10,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 453/824 [40:14<33:03,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 453/824 [40:19<33:03,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 454/824 [40:19<32:57,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 454/824 [40:25<32:57,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 455/824 [40:25<32:58,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 455/824 [40:30<32:58,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 456/824 [40:30<32:53,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 456/824 [40:35<32:53,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 457/824 [40:35<32:51,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 457/824 [40:41<32:51,  5.37s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 458/824 [40:41<32:43,  5.36s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 458/824 [40:46<32:43,  5.36s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 459/824 [40:46<32:38,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 459/824 [40:51<32:38,  5.37s/it, training_loss=0.124]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 460/824 [40:51<32:33,  5.37s/it, training_loss=0.124]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 460/824 [40:57<32:33,  5.37s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 461/824 [40:57<32:29,  5.37s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 461/824 [41:02<32:29,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 462/824 [41:02<32:23,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 462/824 [41:08<32:23,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 463/824 [41:08<32:21,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 463/824 [41:13<32:21,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  56%|█████▋    | 464/824 [41:13<32:11,  5.37s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  56%|█████▋    | 464/824 [41:18<32:11,  5.37s/it, training_loss=0.183]\u001b[A\n",
      "Epoch 3:  56%|█████▋    | 465/824 [41:18<32:01,  5.35s/it, training_loss=0.183]\u001b[A\n",
      "Epoch 3:  56%|█████▋    | 465/824 [41:24<32:01,  5.35s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 466/824 [41:24<31:55,  5.35s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 466/824 [41:29<31:55,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 467/824 [41:29<31:47,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 467/824 [41:34<31:47,  5.34s/it, training_loss=0.501]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 468/824 [41:34<31:37,  5.33s/it, training_loss=0.501]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 468/824 [41:40<31:37,  5.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 469/824 [41:40<31:31,  5.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 469/824 [41:45<31:31,  5.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 470/824 [41:45<31:25,  5.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 470/824 [41:50<31:25,  5.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 471/824 [41:50<31:24,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 471/824 [41:56<31:24,  5.34s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 472/824 [41:56<31:17,  5.33s/it, training_loss=0.026]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 472/824 [42:01<31:17,  5.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 473/824 [42:01<31:11,  5.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 473/824 [42:06<31:11,  5.33s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 474/824 [42:06<31:05,  5.33s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 474/824 [42:12<31:05,  5.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 475/824 [42:12<31:02,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 475/824 [42:17<31:02,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 476/824 [42:17<30:57,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 476/824 [42:22<30:57,  5.34s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 477/824 [42:22<30:52,  5.34s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 477/824 [42:28<30:52,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 478/824 [42:28<30:46,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 478/824 [42:33<30:46,  5.34s/it, training_loss=0.041]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 479/824 [42:33<30:40,  5.34s/it, training_loss=0.041]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 479/824 [42:38<30:40,  5.34s/it, training_loss=0.516]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 480/824 [42:38<30:35,  5.34s/it, training_loss=0.516]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 480/824 [42:44<30:35,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 481/824 [42:44<30:32,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 481/824 [42:49<30:32,  5.34s/it, training_loss=0.170]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 482/824 [42:49<30:25,  5.34s/it, training_loss=0.170]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 482/824 [42:54<30:25,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  59%|█████▊    | 483/824 [42:54<30:22,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  59%|█████▊    | 483/824 [43:00<30:22,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  59%|█████▊    | 484/824 [43:00<30:14,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  59%|█████▊    | 484/824 [43:05<30:14,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 485/824 [43:05<30:09,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 485/824 [43:10<30:09,  5.34s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 486/824 [43:10<30:01,  5.33s/it, training_loss=0.293]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 486/824 [43:16<30:01,  5.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 487/824 [43:16<29:57,  5.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 487/824 [43:21<29:57,  5.33s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 488/824 [43:21<29:55,  5.34s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 488/824 [43:26<29:55,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 489/824 [43:26<29:48,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 489/824 [43:32<29:48,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 490/824 [43:32<29:42,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 490/824 [43:37<29:42,  5.34s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 491/824 [43:37<29:35,  5.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 491/824 [43:42<29:35,  5.33s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 492/824 [43:42<29:29,  5.33s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 492/824 [43:48<29:29,  5.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 493/824 [43:48<29:45,  5.40s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 493/824 [43:53<29:45,  5.40s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 494/824 [43:53<30:02,  5.46s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  60%|█████▉    | 494/824 [43:59<30:02,  5.46s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  60%|██████    | 495/824 [43:59<29:53,  5.45s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  60%|██████    | 495/824 [44:04<29:53,  5.45s/it, training_loss=0.097]\u001b[A\n",
      "Epoch 3:  60%|██████    | 496/824 [44:04<29:13,  5.35s/it, training_loss=0.097]\u001b[A\n",
      "Epoch 3:  60%|██████    | 496/824 [44:09<29:13,  5.35s/it, training_loss=0.460]\u001b[A\n",
      "Epoch 3:  60%|██████    | 497/824 [44:09<28:37,  5.25s/it, training_loss=0.460]\u001b[A\n",
      "Epoch 3:  60%|██████    | 497/824 [44:14<28:37,  5.25s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  60%|██████    | 498/824 [44:14<28:12,  5.19s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  60%|██████    | 498/824 [44:19<28:12,  5.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  61%|██████    | 499/824 [44:19<27:50,  5.14s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  61%|██████    | 499/824 [44:24<27:50,  5.14s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  61%|██████    | 500/824 [44:24<27:39,  5.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  61%|██████    | 500/824 [44:29<27:39,  5.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  61%|██████    | 501/824 [44:29<27:24,  5.09s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  61%|██████    | 501/824 [44:34<27:24,  5.09s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  61%|██████    | 502/824 [44:34<27:16,  5.08s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  61%|██████    | 502/824 [44:39<27:16,  5.08s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  61%|██████    | 503/824 [44:39<27:07,  5.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  61%|██████    | 503/824 [44:44<27:07,  5.07s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  61%|██████    | 504/824 [44:44<26:57,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  61%|██████    | 504/824 [44:49<26:57,  5.06s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  61%|██████▏   | 505/824 [44:49<26:51,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  61%|██████▏   | 505/824 [44:54<26:51,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  61%|██████▏   | 506/824 [44:54<26:44,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  61%|██████▏   | 506/824 [44:59<26:44,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 507/824 [44:59<26:38,  5.04s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 507/824 [45:04<26:38,  5.04s/it, training_loss=0.417]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 508/824 [45:04<26:31,  5.04s/it, training_loss=0.417]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 508/824 [45:09<26:31,  5.04s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 509/824 [45:10<26:25,  5.03s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 509/824 [45:15<26:25,  5.03s/it, training_loss=0.148]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 510/824 [45:15<26:23,  5.04s/it, training_loss=0.148]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 510/824 [45:20<26:23,  5.04s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 511/824 [45:20<26:16,  5.04s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 511/824 [45:25<26:16,  5.04s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 512/824 [45:25<26:11,  5.04s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 512/824 [45:30<26:11,  5.04s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 513/824 [45:30<26:06,  5.04s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 513/824 [45:35<26:06,  5.04s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 514/824 [45:35<25:59,  5.03s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 514/824 [45:40<25:59,  5.03s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  62%|██████▎   | 515/824 [45:40<25:56,  5.04s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  62%|██████▎   | 515/824 [45:45<25:56,  5.04s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 516/824 [45:45<25:51,  5.04s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 516/824 [45:50<25:51,  5.04s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 517/824 [45:50<25:47,  5.04s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 517/824 [45:55<25:47,  5.04s/it, training_loss=0.252]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 518/824 [45:55<25:42,  5.04s/it, training_loss=0.252]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 518/824 [46:00<25:42,  5.04s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 519/824 [46:00<25:36,  5.04s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 519/824 [46:05<25:36,  5.04s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 520/824 [46:05<25:29,  5.03s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 520/824 [46:10<25:29,  5.03s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 521/824 [46:10<25:23,  5.03s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 521/824 [46:15<25:23,  5.03s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 522/824 [46:15<25:21,  5.04s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 522/824 [46:20<25:21,  5.04s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 523/824 [46:20<25:16,  5.04s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 523/824 [46:25<25:16,  5.04s/it, training_loss=0.075]\u001b[A\n",
      "Epoch 3:  64%|██████▎   | 524/824 [46:25<25:08,  5.03s/it, training_loss=0.075]\u001b[A\n",
      "Epoch 3:  64%|██████▎   | 524/824 [46:30<25:08,  5.03s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  64%|██████▎   | 525/824 [46:30<25:02,  5.03s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  64%|██████▎   | 525/824 [46:35<25:02,  5.03s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 526/824 [46:35<25:00,  5.04s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 526/824 [46:40<25:00,  5.04s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 527/824 [46:40<24:54,  5.03s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 527/824 [46:45<24:54,  5.03s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 528/824 [46:45<24:47,  5.03s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 528/824 [46:50<24:47,  5.03s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 529/824 [46:50<24:44,  5.03s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 529/824 [46:55<24:44,  5.03s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 530/824 [46:55<24:38,  5.03s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 530/824 [47:00<24:38,  5.03s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 531/824 [47:00<24:37,  5.04s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 531/824 [47:05<24:37,  5.04s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 532/824 [47:05<24:30,  5.03s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 532/824 [47:10<24:30,  5.03s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 533/824 [47:10<24:24,  5.03s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 533/824 [47:15<24:24,  5.03s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 534/824 [47:15<24:19,  5.03s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 534/824 [47:20<24:19,  5.03s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 535/824 [47:20<24:16,  5.04s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 535/824 [47:25<24:16,  5.04s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  65%|██████▌   | 536/824 [47:25<24:09,  5.03s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  65%|██████▌   | 536/824 [47:30<24:09,  5.03s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  65%|██████▌   | 537/824 [47:30<24:02,  5.03s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  65%|██████▌   | 537/824 [47:35<24:02,  5.03s/it, training_loss=0.378]\u001b[A\n",
      "Epoch 3:  65%|██████▌   | 538/824 [47:35<23:56,  5.02s/it, training_loss=0.378]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  65%|██████▌   | 538/824 [47:40<23:56,  5.02s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  65%|██████▌   | 539/824 [47:40<23:52,  5.03s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  65%|██████▌   | 539/824 [47:46<23:52,  5.03s/it, training_loss=0.368]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 540/824 [47:46<23:47,  5.03s/it, training_loss=0.368]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 540/824 [47:51<23:47,  5.03s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 541/824 [47:51<23:45,  5.04s/it, training_loss=0.339]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 541/824 [47:56<23:45,  5.04s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 542/824 [47:56<23:40,  5.04s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 542/824 [48:01<23:40,  5.04s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 543/824 [48:01<23:36,  5.04s/it, training_loss=0.324]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 543/824 [48:06<23:36,  5.04s/it, training_loss=0.384]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 544/824 [48:06<23:31,  5.04s/it, training_loss=0.384]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 544/824 [48:11<23:31,  5.04s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 545/824 [48:11<23:24,  5.03s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 545/824 [48:16<23:24,  5.03s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  66%|██████▋   | 546/824 [48:16<23:18,  5.03s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  66%|██████▋   | 546/824 [48:21<23:18,  5.03s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  66%|██████▋   | 547/824 [48:21<23:19,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  66%|██████▋   | 547/824 [48:26<23:19,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 548/824 [48:26<23:14,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 548/824 [48:31<23:14,  5.05s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 549/824 [48:31<23:47,  5.19s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 549/824 [48:37<23:47,  5.19s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 550/824 [48:37<23:35,  5.17s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 550/824 [48:42<23:35,  5.17s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 551/824 [48:42<23:20,  5.13s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 551/824 [48:47<23:20,  5.13s/it, training_loss=0.443]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 552/824 [48:47<23:12,  5.12s/it, training_loss=0.443]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 552/824 [48:52<23:12,  5.12s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 553/824 [48:52<23:31,  5.21s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 553/824 [48:58<23:31,  5.21s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 554/824 [48:58<23:57,  5.32s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 554/824 [49:03<23:57,  5.32s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 555/824 [49:03<23:54,  5.33s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 555/824 [49:08<23:54,  5.33s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 556/824 [49:08<23:59,  5.37s/it, training_loss=0.021]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 556/824 [49:14<23:59,  5.37s/it, training_loss=0.060]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 557/824 [49:14<23:53,  5.37s/it, training_loss=0.060]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 557/824 [49:19<23:53,  5.37s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 558/824 [49:19<23:50,  5.38s/it, training_loss=0.030]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 558/824 [49:25<23:50,  5.38s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 559/824 [49:25<23:37,  5.35s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 559/824 [49:30<23:37,  5.35s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 560/824 [49:30<23:15,  5.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 560/824 [49:35<23:15,  5.29s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 561/824 [49:35<23:20,  5.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 561/824 [49:40<23:20,  5.32s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 562/824 [49:40<23:16,  5.33s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 562/824 [49:46<23:16,  5.33s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 563/824 [49:46<23:09,  5.32s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 563/824 [49:51<23:09,  5.32s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 564/824 [49:51<23:28,  5.42s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 564/824 [49:57<23:28,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  69%|██████▊   | 565/824 [49:57<24:12,  5.61s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  69%|██████▊   | 565/824 [50:03<24:12,  5.61s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  69%|██████▊   | 566/824 [50:03<23:57,  5.57s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  69%|██████▊   | 566/824 [50:08<23:57,  5.57s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 567/824 [50:08<23:43,  5.54s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 567/824 [50:14<23:43,  5.54s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 568/824 [50:14<23:22,  5.48s/it, training_loss=0.009]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 568/824 [50:19<23:22,  5.48s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 569/824 [50:19<22:56,  5.40s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 569/824 [50:24<22:56,  5.40s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 570/824 [50:24<22:50,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 570/824 [50:30<22:50,  5.39s/it, training_loss=0.075]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 571/824 [50:30<22:52,  5.42s/it, training_loss=0.075]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 571/824 [50:35<22:52,  5.42s/it, training_loss=0.386]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 572/824 [50:35<22:46,  5.42s/it, training_loss=0.386]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 572/824 [50:41<22:46,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 573/824 [50:41<23:27,  5.61s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 573/824 [50:47<23:27,  5.61s/it, training_loss=0.119]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 574/824 [50:47<23:04,  5.54s/it, training_loss=0.119]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 574/824 [50:52<23:04,  5.54s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 575/824 [50:52<22:42,  5.47s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 575/824 [50:57<22:42,  5.47s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 576/824 [50:57<22:28,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 576/824 [51:03<22:28,  5.44s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 3:  70%|███████   | 577/824 [51:03<22:40,  5.51s/it, training_loss=0.320]\u001b[A\n",
      "Epoch 3:  70%|███████   | 577/824 [51:08<22:40,  5.51s/it, training_loss=0.112]\u001b[A\n",
      "Epoch 3:  70%|███████   | 578/824 [51:08<22:08,  5.40s/it, training_loss=0.112]\u001b[A\n",
      "Epoch 3:  70%|███████   | 578/824 [51:13<22:08,  5.40s/it, training_loss=0.431]\u001b[A\n",
      "Epoch 3:  70%|███████   | 579/824 [51:13<21:56,  5.37s/it, training_loss=0.431]\u001b[A\n",
      "Epoch 3:  70%|███████   | 579/824 [51:19<21:56,  5.37s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  70%|███████   | 580/824 [51:19<22:10,  5.45s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  70%|███████   | 580/824 [51:25<22:10,  5.45s/it, training_loss=0.384]\u001b[A\n",
      "Epoch 3:  71%|███████   | 581/824 [51:25<22:08,  5.47s/it, training_loss=0.384]\u001b[A\n",
      "Epoch 3:  71%|███████   | 581/824 [51:30<22:08,  5.47s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  71%|███████   | 582/824 [51:30<21:56,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  71%|███████   | 582/824 [51:35<21:56,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  71%|███████   | 583/824 [51:35<21:46,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  71%|███████   | 583/824 [51:41<21:46,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  71%|███████   | 584/824 [51:41<21:38,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  71%|███████   | 584/824 [51:46<21:38,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  71%|███████   | 585/824 [51:46<21:27,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  71%|███████   | 585/824 [51:51<21:27,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  71%|███████   | 586/824 [51:51<21:23,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  71%|███████   | 586/824 [51:57<21:23,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  71%|███████   | 587/824 [51:57<21:26,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  71%|███████   | 587/824 [52:02<21:26,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  71%|███████▏  | 588/824 [52:02<21:19,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  71%|███████▏  | 588/824 [52:08<21:19,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  71%|███████▏  | 589/824 [52:08<21:09,  5.40s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  71%|███████▏  | 589/824 [52:13<21:09,  5.40s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 590/824 [52:13<21:01,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 590/824 [52:18<21:01,  5.39s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 591/824 [52:18<20:53,  5.38s/it, training_loss=0.316]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 591/824 [52:24<20:53,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 592/824 [52:24<20:49,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 592/824 [52:29<20:49,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 593/824 [52:29<20:43,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 593/824 [52:35<20:43,  5.38s/it, training_loss=0.188]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 594/824 [52:35<20:37,  5.38s/it, training_loss=0.188]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 594/824 [52:40<20:37,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 595/824 [52:40<20:33,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 595/824 [52:45<20:33,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 596/824 [52:45<20:28,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 596/824 [52:51<20:28,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 597/824 [52:51<20:24,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 597/824 [52:56<20:24,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 598/824 [52:56<20:17,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 598/824 [53:02<20:17,  5.39s/it, training_loss=0.045]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 599/824 [53:02<20:10,  5.38s/it, training_loss=0.045]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 599/824 [53:07<20:10,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 600/824 [53:07<20:06,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 600/824 [53:12<20:06,  5.39s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 601/824 [53:12<20:01,  5.39s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 601/824 [53:18<20:01,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 602/824 [53:18<19:54,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 602/824 [53:23<19:54,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 603/824 [53:23<19:51,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 603/824 [53:28<19:51,  5.39s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 604/824 [53:29<19:44,  5.38s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 604/824 [53:34<19:44,  5.38s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 605/824 [53:34<19:39,  5.38s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 605/824 [53:39<19:39,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  74%|███████▎  | 606/824 [53:39<19:35,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  74%|███████▎  | 606/824 [53:45<19:35,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  74%|███████▎  | 607/824 [53:45<19:29,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  74%|███████▎  | 607/824 [53:50<19:29,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 608/824 [53:50<19:24,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 608/824 [53:55<19:24,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 609/824 [53:55<19:20,  5.40s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 609/824 [54:01<19:20,  5.40s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 610/824 [54:01<19:13,  5.39s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 610/824 [54:06<19:13,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 611/824 [54:06<19:07,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 611/824 [54:12<19:07,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 612/824 [54:12<19:02,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 612/824 [54:17<19:02,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 613/824 [54:17<18:57,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 613/824 [54:23<18:57,  5.39s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 3:  75%|███████▍  | 614/824 [54:23<18:59,  5.42s/it, training_loss=0.265]\u001b[A\n",
      "Epoch 3:  75%|███████▍  | 614/824 [54:28<18:59,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  75%|███████▍  | 615/824 [54:28<18:52,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  75%|███████▍  | 615/824 [54:33<18:52,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  75%|███████▍  | 616/824 [54:33<18:45,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  75%|███████▍  | 616/824 [54:39<18:45,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  75%|███████▍  | 617/824 [54:39<18:38,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  75%|███████▍  | 617/824 [54:44<18:38,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 618/824 [54:44<18:33,  5.40s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 618/824 [54:50<18:33,  5.40s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 619/824 [54:50<18:29,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 619/824 [54:55<18:29,  5.41s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 620/824 [54:55<18:17,  5.38s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 620/824 [55:00<18:17,  5.38s/it, training_loss=0.083]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 621/824 [55:00<18:13,  5.39s/it, training_loss=0.083]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 621/824 [55:06<18:13,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 622/824 [55:06<18:08,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 622/824 [55:11<18:08,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 623/824 [55:11<18:03,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 623/824 [55:16<18:03,  5.39s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 624/824 [55:16<17:57,  5.39s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 624/824 [55:22<17:57,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 625/824 [55:22<17:53,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 625/824 [55:27<17:53,  5.39s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 626/824 [55:27<17:46,  5.39s/it, training_loss=0.013]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 626/824 [55:33<17:46,  5.39s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 627/824 [55:33<17:54,  5.45s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 627/824 [55:39<17:54,  5.45s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 628/824 [55:39<18:06,  5.55s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 628/824 [55:44<18:06,  5.55s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  76%|███████▋  | 629/824 [55:44<18:15,  5.62s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  76%|███████▋  | 629/824 [55:50<18:15,  5.62s/it, training_loss=0.419]\u001b[A\n",
      "Epoch 3:  76%|███████▋  | 630/824 [55:50<18:21,  5.68s/it, training_loss=0.419]\u001b[A\n",
      "Epoch 3:  76%|███████▋  | 630/824 [55:56<18:21,  5.68s/it, training_loss=0.398]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 631/824 [55:56<18:23,  5.72s/it, training_loss=0.398]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 631/824 [56:02<18:23,  5.72s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 632/824 [56:02<18:18,  5.72s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 632/824 [56:07<18:18,  5.72s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 633/824 [56:07<18:07,  5.69s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 633/824 [56:13<18:07,  5.69s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 634/824 [56:13<17:55,  5.66s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 634/824 [56:18<17:55,  5.66s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 635/824 [56:18<17:38,  5.60s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 635/824 [56:24<17:38,  5.60s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 636/824 [56:24<17:24,  5.55s/it, training_loss=0.001]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  77%|███████▋  | 636/824 [56:29<17:24,  5.55s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 637/824 [56:29<17:10,  5.51s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 637/824 [56:35<17:10,  5.51s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 638/824 [56:35<16:59,  5.48s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 638/824 [56:40<16:59,  5.48s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 639/824 [56:40<16:51,  5.47s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 639/824 [56:46<16:51,  5.47s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 640/824 [56:46<16:43,  5.45s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 640/824 [56:51<16:43,  5.45s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 641/824 [56:51<16:38,  5.45s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 641/824 [56:56<16:38,  5.45s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 642/824 [56:56<16:31,  5.45s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 642/824 [57:02<16:31,  5.45s/it, training_loss=0.054]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 643/824 [57:02<16:25,  5.44s/it, training_loss=0.054]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 643/824 [57:07<16:25,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 644/824 [57:07<16:19,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 644/824 [57:13<16:19,  5.44s/it, training_loss=0.154]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 645/824 [57:13<16:12,  5.43s/it, training_loss=0.154]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 645/824 [57:18<16:12,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 646/824 [57:18<16:07,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 646/824 [57:24<16:07,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  79%|███████▊  | 647/824 [57:24<16:03,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  79%|███████▊  | 647/824 [57:29<16:03,  5.44s/it, training_loss=0.602]\u001b[A\n",
      "Epoch 3:  79%|███████▊  | 648/824 [57:29<15:56,  5.43s/it, training_loss=0.602]\u001b[A\n",
      "Epoch 3:  79%|███████▊  | 648/824 [57:34<15:56,  5.43s/it, training_loss=0.051]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 649/824 [57:34<15:50,  5.43s/it, training_loss=0.051]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 649/824 [57:40<15:50,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 650/824 [57:40<15:45,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 650/824 [57:45<15:45,  5.43s/it, training_loss=0.093]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 651/824 [57:45<15:39,  5.43s/it, training_loss=0.093]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 651/824 [57:51<15:39,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 652/824 [57:51<15:35,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 652/824 [57:56<15:35,  5.44s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 653/824 [57:56<15:28,  5.43s/it, training_loss=0.330]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 653/824 [58:02<15:28,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 654/824 [58:02<15:22,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 654/824 [58:07<15:22,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 655/824 [58:07<15:18,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 655/824 [58:12<15:18,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 656/824 [58:12<15:13,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 656/824 [58:18<15:13,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 657/824 [58:18<15:08,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 657/824 [58:23<15:08,  5.44s/it, training_loss=0.079]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 658/824 [58:23<15:04,  5.45s/it, training_loss=0.079]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 658/824 [58:29<15:04,  5.45s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 659/824 [58:29<14:57,  5.44s/it, training_loss=0.085]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 659/824 [58:34<14:57,  5.44s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  80%|████████  | 660/824 [58:34<14:50,  5.43s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  80%|████████  | 660/824 [58:40<14:50,  5.43s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  80%|████████  | 661/824 [58:40<14:44,  5.43s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  80%|████████  | 661/824 [58:45<14:44,  5.43s/it, training_loss=0.042]\u001b[A\n",
      "Epoch 3:  80%|████████  | 662/824 [58:45<14:38,  5.42s/it, training_loss=0.042]\u001b[A\n",
      "Epoch 3:  80%|████████  | 662/824 [58:51<14:38,  5.42s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 3:  80%|████████  | 663/824 [58:51<14:34,  5.43s/it, training_loss=0.271]\u001b[A\n",
      "Epoch 3:  80%|████████  | 663/824 [58:56<14:34,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  81%|████████  | 664/824 [58:56<14:28,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  81%|████████  | 664/824 [59:01<14:28,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  81%|████████  | 665/824 [59:01<14:22,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  81%|████████  | 665/824 [59:07<14:22,  5.42s/it, training_loss=0.045]\u001b[A\n",
      "Epoch 3:  81%|████████  | 666/824 [59:07<14:18,  5.43s/it, training_loss=0.045]\u001b[A\n",
      "Epoch 3:  81%|████████  | 666/824 [59:12<14:18,  5.43s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  81%|████████  | 667/824 [59:12<14:12,  5.43s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  81%|████████  | 667/824 [59:18<14:12,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  81%|████████  | 668/824 [59:18<14:06,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  81%|████████  | 668/824 [59:23<14:06,  5.42s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 3:  81%|████████  | 669/824 [59:23<14:05,  5.45s/it, training_loss=0.044]\u001b[A\n",
      "Epoch 3:  81%|████████  | 669/824 [59:29<14:05,  5.45s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  81%|████████▏ | 670/824 [59:29<13:57,  5.44s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  81%|████████▏ | 670/824 [59:34<13:57,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  81%|████████▏ | 671/824 [59:34<13:50,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  81%|████████▏ | 671/824 [59:39<13:50,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 672/824 [59:39<13:40,  5.40s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 672/824 [59:45<13:40,  5.40s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 673/824 [59:45<13:36,  5.41s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 673/824 [59:50<13:36,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 674/824 [59:50<13:32,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 674/824 [59:56<13:32,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 675/824 [59:56<13:26,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 675/824 [1:00:01<13:26,  5.42s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 676/824 [1:00:01<13:24,  5.44s/it, training_loss=0.105]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 676/824 [1:00:06<13:24,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 677/824 [1:00:06<13:18,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 677/824 [1:00:12<13:18,  5.43s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 678/824 [1:00:12<13:10,  5.42s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 678/824 [1:00:17<13:10,  5.42s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 679/824 [1:00:17<13:04,  5.41s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 679/824 [1:00:23<13:04,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 680/824 [1:00:23<12:59,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 680/824 [1:00:28<12:59,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 681/824 [1:00:28<12:53,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 681/824 [1:00:33<12:53,  5.41s/it, training_loss=0.420]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 682/824 [1:00:33<12:47,  5.41s/it, training_loss=0.420]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 682/824 [1:00:39<12:47,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 683/824 [1:00:39<12:42,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 683/824 [1:00:44<12:42,  5.41s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 684/824 [1:00:44<12:36,  5.40s/it, training_loss=0.008]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 684/824 [1:00:50<12:36,  5.40s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 685/824 [1:00:50<12:32,  5.41s/it, training_loss=0.263]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 685/824 [1:00:55<12:32,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 686/824 [1:00:55<12:27,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 686/824 [1:01:01<12:27,  5.42s/it, training_loss=0.062]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 687/824 [1:01:01<12:22,  5.42s/it, training_loss=0.062]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 687/824 [1:01:06<12:22,  5.42s/it, training_loss=0.062]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 688/824 [1:01:06<12:17,  5.42s/it, training_loss=0.062]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 688/824 [1:01:11<12:17,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  84%|████████▎ | 689/824 [1:01:11<12:12,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  84%|████████▎ | 689/824 [1:01:17<12:12,  5.43s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  84%|████████▎ | 690/824 [1:01:17<12:04,  5.40s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  84%|████████▎ | 690/824 [1:01:22<12:04,  5.40s/it, training_loss=0.191]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 691/824 [1:01:22<11:59,  5.41s/it, training_loss=0.191]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 691/824 [1:01:28<11:59,  5.41s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 692/824 [1:01:28<11:55,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 692/824 [1:01:33<11:55,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 693/824 [1:01:33<11:50,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 693/824 [1:01:38<11:50,  5.42s/it, training_loss=0.156]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 694/824 [1:01:38<11:39,  5.38s/it, training_loss=0.156]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 694/824 [1:01:44<11:39,  5.38s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 695/824 [1:01:44<11:36,  5.40s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 695/824 [1:01:49<11:36,  5.40s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 696/824 [1:01:49<11:32,  5.41s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 696/824 [1:01:55<11:32,  5.41s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 697/824 [1:01:55<11:28,  5.42s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 697/824 [1:02:00<11:28,  5.42s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 698/824 [1:02:00<11:23,  5.43s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 698/824 [1:02:06<11:23,  5.43s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 699/824 [1:02:06<11:18,  5.43s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 699/824 [1:02:11<11:18,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 700/824 [1:02:11<11:13,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  85%|████████▍ | 700/824 [1:02:16<11:13,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 701/824 [1:02:16<11:07,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 701/824 [1:02:22<11:07,  5.43s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 702/824 [1:02:22<11:03,  5.44s/it, training_loss=0.305]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 702/824 [1:02:27<11:03,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 703/824 [1:02:27<10:57,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 703/824 [1:02:33<10:57,  5.44s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 704/824 [1:02:33<10:52,  5.43s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 704/824 [1:02:38<10:52,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 705/824 [1:02:38<10:46,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 705/824 [1:02:44<10:46,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 706/824 [1:02:44<10:41,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 706/824 [1:02:49<10:41,  5.44s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 707/824 [1:02:49<10:36,  5.44s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 707/824 [1:02:55<10:36,  5.44s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 708/824 [1:02:55<10:32,  5.45s/it, training_loss=0.005]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 708/824 [1:03:00<10:32,  5.45s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 709/824 [1:03:00<10:27,  5.46s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 709/824 [1:03:05<10:27,  5.46s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 710/824 [1:03:05<10:20,  5.45s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 710/824 [1:03:11<10:20,  5.45s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  86%|████████▋ | 711/824 [1:03:11<10:14,  5.44s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  86%|████████▋ | 711/824 [1:03:16<10:14,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  86%|████████▋ | 712/824 [1:03:16<10:09,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  86%|████████▋ | 712/824 [1:03:22<10:09,  5.44s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 713/824 [1:03:22<10:04,  5.45s/it, training_loss=0.336]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 713/824 [1:03:27<10:04,  5.45s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 714/824 [1:03:27<09:58,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 714/824 [1:03:33<09:58,  5.44s/it, training_loss=0.489]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 715/824 [1:03:33<09:52,  5.43s/it, training_loss=0.489]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 715/824 [1:03:38<09:52,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 716/824 [1:03:38<09:46,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 716/824 [1:03:43<09:46,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 717/824 [1:03:43<09:41,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 717/824 [1:03:49<09:41,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 718/824 [1:03:49<09:36,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 718/824 [1:03:54<09:36,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 719/824 [1:03:54<09:31,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 719/824 [1:04:00<09:31,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 720/824 [1:04:00<09:26,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 720/824 [1:04:05<09:26,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 721/824 [1:04:05<09:20,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 721/824 [1:04:11<09:20,  5.44s/it, training_loss=0.224]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 722/824 [1:04:11<09:14,  5.44s/it, training_loss=0.224]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 722/824 [1:04:16<09:14,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 723/824 [1:04:16<09:09,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 723/824 [1:04:22<09:09,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 724/824 [1:04:22<09:05,  5.46s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 724/824 [1:04:27<09:05,  5.46s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 725/824 [1:04:27<08:59,  5.45s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 725/824 [1:04:32<08:59,  5.45s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 726/824 [1:04:32<08:52,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 726/824 [1:04:38<08:52,  5.44s/it, training_loss=0.221]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 727/824 [1:04:38<08:46,  5.43s/it, training_loss=0.221]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 727/824 [1:04:43<08:46,  5.43s/it, training_loss=0.065]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 728/824 [1:04:43<08:40,  5.43s/it, training_loss=0.065]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 728/824 [1:04:49<08:40,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 729/824 [1:04:49<08:35,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 729/824 [1:04:54<08:35,  5.43s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  89%|████████▊ | 730/824 [1:04:54<08:31,  5.44s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  89%|████████▊ | 730/824 [1:05:00<08:31,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  89%|████████▊ | 731/824 [1:05:00<08:25,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  89%|████████▊ | 731/824 [1:05:05<08:25,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 732/824 [1:05:05<08:19,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 732/824 [1:05:10<08:19,  5.43s/it, training_loss=0.112]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 733/824 [1:05:10<08:14,  5.44s/it, training_loss=0.112]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  89%|████████▉ | 733/824 [1:05:16<08:14,  5.44s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 734/824 [1:05:16<08:09,  5.44s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 734/824 [1:05:21<08:09,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 735/824 [1:05:21<08:04,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 735/824 [1:05:27<08:04,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 736/824 [1:05:27<07:58,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 736/824 [1:05:32<07:58,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 737/824 [1:05:32<07:52,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 737/824 [1:05:38<07:52,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 738/824 [1:05:38<07:46,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 738/824 [1:05:43<07:46,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 739/824 [1:05:43<07:41,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 739/824 [1:05:48<07:41,  5.43s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 740/824 [1:05:48<07:36,  5.43s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 740/824 [1:05:54<07:36,  5.43s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 741/824 [1:05:54<07:31,  5.44s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 741/824 [1:05:59<07:31,  5.44s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 742/824 [1:05:59<07:26,  5.44s/it, training_loss=0.000]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 742/824 [1:06:05<07:26,  5.44s/it, training_loss=0.153]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 743/824 [1:06:05<07:20,  5.44s/it, training_loss=0.153]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 743/824 [1:06:10<07:20,  5.44s/it, training_loss=0.464]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 744/824 [1:06:10<07:14,  5.43s/it, training_loss=0.464]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 744/824 [1:06:16<07:14,  5.43s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 745/824 [1:06:16<07:08,  5.43s/it, training_loss=0.027]\u001b[A\n",
      "Epoch 3:  90%|█████████ | 745/824 [1:06:21<07:08,  5.43s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 746/824 [1:06:21<07:03,  5.44s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 746/824 [1:06:27<07:03,  5.44s/it, training_loss=0.413]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 747/824 [1:06:27<06:58,  5.43s/it, training_loss=0.413]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 747/824 [1:06:32<06:58,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 748/824 [1:06:32<06:53,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 748/824 [1:06:37<06:53,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 749/824 [1:06:37<06:48,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 749/824 [1:06:43<06:48,  5.44s/it, training_loss=0.189]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 750/824 [1:06:43<06:43,  5.46s/it, training_loss=0.189]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 750/824 [1:06:48<06:43,  5.46s/it, training_loss=0.402]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 751/824 [1:06:48<06:37,  5.45s/it, training_loss=0.402]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 751/824 [1:06:54<06:37,  5.45s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  91%|█████████▏| 752/824 [1:06:54<06:33,  5.46s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  91%|█████████▏| 752/824 [1:06:59<06:33,  5.46s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  91%|█████████▏| 753/824 [1:06:59<06:26,  5.45s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  91%|█████████▏| 753/824 [1:07:05<06:26,  5.45s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 754/824 [1:07:05<06:21,  5.45s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 754/824 [1:07:10<06:21,  5.45s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 755/824 [1:07:10<06:15,  5.44s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 755/824 [1:07:16<06:15,  5.44s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 756/824 [1:07:16<06:10,  5.44s/it, training_loss=0.338]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 756/824 [1:07:21<06:10,  5.44s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 757/824 [1:07:21<06:05,  5.45s/it, training_loss=0.088]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 757/824 [1:07:27<06:05,  5.45s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 758/824 [1:07:27<05:59,  5.45s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 758/824 [1:07:32<05:59,  5.45s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 759/824 [1:07:32<05:53,  5.44s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 759/824 [1:07:37<05:53,  5.44s/it, training_loss=0.400]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 760/824 [1:07:37<05:48,  5.44s/it, training_loss=0.400]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 760/824 [1:07:43<05:48,  5.44s/it, training_loss=0.405]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 761/824 [1:07:43<05:42,  5.43s/it, training_loss=0.405]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 761/824 [1:07:48<05:42,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 762/824 [1:07:48<05:36,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 762/824 [1:07:54<05:36,  5.44s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 763/824 [1:07:54<05:32,  5.44s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 763/824 [1:07:59<05:32,  5.44s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 764/824 [1:07:59<05:26,  5.44s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 764/824 [1:08:05<05:26,  5.44s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 765/824 [1:08:05<05:21,  5.45s/it, training_loss=0.010]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 765/824 [1:08:10<05:21,  5.45s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 766/824 [1:08:10<05:15,  5.45s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 766/824 [1:08:15<05:15,  5.45s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 767/824 [1:08:15<05:09,  5.43s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 767/824 [1:08:21<05:09,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 768/824 [1:08:21<05:03,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 768/824 [1:08:26<05:03,  5.42s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 769/824 [1:08:26<04:58,  5.42s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 769/824 [1:08:32<04:58,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 770/824 [1:08:32<04:53,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 770/824 [1:08:37<04:53,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  94%|█████████▎| 771/824 [1:08:37<04:47,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  94%|█████████▎| 771/824 [1:08:43<04:47,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  94%|█████████▎| 772/824 [1:08:43<04:42,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  94%|█████████▎| 772/824 [1:08:48<04:42,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 773/824 [1:08:48<04:37,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 773/824 [1:08:53<04:37,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 774/824 [1:08:53<04:32,  5.45s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 774/824 [1:08:59<04:32,  5.45s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 775/824 [1:08:59<04:27,  5.45s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 775/824 [1:09:04<04:27,  5.45s/it, training_loss=0.128]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 776/824 [1:09:04<04:21,  5.45s/it, training_loss=0.128]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 776/824 [1:09:10<04:21,  5.45s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 777/824 [1:09:10<04:15,  5.44s/it, training_loss=0.270]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 777/824 [1:09:15<04:15,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 778/824 [1:09:15<04:09,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 778/824 [1:09:21<04:09,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 779/824 [1:09:21<04:04,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 779/824 [1:09:26<04:04,  5.44s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 780/824 [1:09:26<03:58,  5.43s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 780/824 [1:09:32<03:58,  5.43s/it, training_loss=0.396]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 781/824 [1:09:32<03:53,  5.43s/it, training_loss=0.396]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 781/824 [1:09:37<03:53,  5.43s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 782/824 [1:09:37<03:48,  5.43s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 782/824 [1:09:42<03:48,  5.43s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 783/824 [1:09:42<03:42,  5.44s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 783/824 [1:09:48<03:42,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 784/824 [1:09:48<03:37,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 784/824 [1:09:53<03:37,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 785/824 [1:09:53<03:31,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 785/824 [1:09:59<03:31,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 786/824 [1:09:59<03:26,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 786/824 [1:10:04<03:26,  5.43s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 787/824 [1:10:04<03:20,  5.43s/it, training_loss=0.011]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 787/824 [1:10:09<03:20,  5.43s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 788/824 [1:10:09<03:15,  5.42s/it, training_loss=0.039]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 788/824 [1:10:15<03:15,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 789/824 [1:10:15<03:09,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 789/824 [1:10:20<03:09,  5.43s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 790/824 [1:10:20<03:04,  5.43s/it, training_loss=0.004]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 790/824 [1:10:26<03:04,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 791/824 [1:10:26<02:59,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 791/824 [1:10:31<02:59,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 792/824 [1:10:31<02:54,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 792/824 [1:10:37<02:54,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 793/824 [1:10:37<02:49,  5.45s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 793/824 [1:10:42<02:49,  5.45s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  96%|█████████▋| 794/824 [1:10:42<02:43,  5.45s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  96%|█████████▋| 794/824 [1:10:48<02:43,  5.45s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  96%|█████████▋| 795/824 [1:10:48<02:37,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  96%|█████████▋| 795/824 [1:10:53<02:37,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 796/824 [1:10:53<02:32,  5.45s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 796/824 [1:10:59<02:32,  5.45s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 797/824 [1:10:59<02:26,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 797/824 [1:11:04<02:26,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 798/824 [1:11:04<02:21,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 798/824 [1:11:09<02:21,  5.44s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 799/824 [1:11:09<02:15,  5.44s/it, training_loss=0.267]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 799/824 [1:11:15<02:15,  5.44s/it, training_loss=0.400]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 800/824 [1:11:15<02:10,  5.43s/it, training_loss=0.400]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 800/824 [1:11:20<02:10,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 801/824 [1:11:20<02:05,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 801/824 [1:11:26<02:05,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 802/824 [1:11:26<01:59,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 802/824 [1:11:31<01:59,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 803/824 [1:11:31<01:53,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 803/824 [1:11:37<01:53,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 804/824 [1:11:37<01:48,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 804/824 [1:11:42<01:48,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 805/824 [1:11:42<01:43,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 805/824 [1:11:47<01:43,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 806/824 [1:11:47<01:37,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 806/824 [1:11:53<01:37,  5.42s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 807/824 [1:11:53<01:32,  5.43s/it, training_loss=0.007]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 807/824 [1:11:58<01:32,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 808/824 [1:11:58<01:26,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 808/824 [1:12:04<01:26,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 809/824 [1:12:04<01:21,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 809/824 [1:12:09<01:21,  5.43s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 810/824 [1:12:09<01:16,  5.43s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 810/824 [1:12:15<01:16,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 811/824 [1:12:15<01:10,  5.42s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 811/824 [1:12:20<01:10,  5.42s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  99%|█████████▊| 812/824 [1:12:20<01:05,  5.43s/it, training_loss=0.003]\u001b[A\n",
      "Epoch 3:  99%|█████████▊| 812/824 [1:12:25<01:05,  5.43s/it, training_loss=0.400]\u001b[A\n",
      "Epoch 3:  99%|█████████▊| 813/824 [1:12:25<00:59,  5.43s/it, training_loss=0.400]\u001b[A\n",
      "Epoch 3:  99%|█████████▊| 813/824 [1:12:31<00:59,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 814/824 [1:12:31<00:54,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 814/824 [1:12:36<00:54,  5.43s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 815/824 [1:12:36<00:48,  5.43s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 815/824 [1:12:42<00:48,  5.43s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 816/824 [1:12:42<00:43,  5.43s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 816/824 [1:12:47<00:43,  5.43s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 817/824 [1:12:47<00:37,  5.43s/it, training_loss=0.033]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 817/824 [1:12:53<00:37,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 818/824 [1:12:53<00:32,  5.44s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 818/824 [1:12:58<00:32,  5.44s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 819/824 [1:12:58<00:27,  5.43s/it, training_loss=0.002]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 819/824 [1:13:03<00:27,  5.43s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 820/824 [1:13:03<00:21,  5.43s/it, training_loss=0.006]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 820/824 [1:13:09<00:21,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 821/824 [1:13:09<00:16,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 821/824 [1:13:14<00:16,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 822/824 [1:13:14<00:10,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 822/824 [1:13:20<00:10,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 823/824 [1:13:20<00:05,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3: 100%|█████████▉| 823/824 [1:13:24<00:05,  5.43s/it, training_loss=0.001]\u001b[A\n",
      "Epoch 3: 100%|██████████| 824/824 [1:13:24<00:00,  5.15s/it, training_loss=0.001]\u001b[A\n",
      " 67%|██████▋   | 2/3 [4:04:18<1:26:13, 5173.33s/it]                              \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n",
      "Training loss: 0.15099292005145543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [4:07:48<00:00, 4956.30s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.5383680921386009\n",
      "F1 Score (Weighted): 0.871166775606992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "seed_val = 2022\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "         \n",
    "        \n",
    "    torch.save(model.state_dict(), f'finetuned_finBERT_epoch_{epoch}.model')\n",
    "        \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)            \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "involved-member",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: neutral\n",
      "Accuracy: 395/432\n",
      "\n",
      "Class: negative\n",
      "Accuracy: 73/91\n",
      "\n",
      "Class: positive\n",
      "Accuracy: 160/204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the best model & Make Predictions\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\",\n",
    "                                                          num_labels=len(sentiment_dict),\n",
    "                                                          output_attentions=False,\n",
    "                                                          output_hidden_states=False)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('finetuned_finBERT_epoch_1.model', \n",
    "                                 map_location=torch.device('cpu')))\n",
    "\n",
    "_, predictions, true_vals = evaluate(dataloader_validation)\n",
    "\n",
    "accuracy_per_class(predictions, true_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-embassy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_datatable_env",
   "language": "python",
   "name": "my_datatable_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
